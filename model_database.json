{
    "Linear Regression": {
        "description": "A linear approach to modeling the relationship between a dependent variable and one or more independent variables.",
        "use_cases": [
            "prediction",
            "exploration",
            "inference"
        ],
        "analysis_goals": [
            "predict",
            "explore"
        ],
        "dependent_variable": [
            "continuous"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random",
            "systematic"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
            },
            "r": {
                "code": "model <- lm(y ~ x1 + x2, data=df)\nsummary(model)\npredictions <- predict(model, newdata=test_data)",
                "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm"
            },
            "spss": {
                "code": "REGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN\n  /DEPENDENT y\n  /METHOD=ENTER x1 x2",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-linear"
            },
            "sas": {
                "code": "proc reg data=dataset;\n  model y = x1 x2;\n  run;",
                "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_reg_syntax.htm"
            },
            "stata": {
                "code": "regress y x1 x2",
                "documentation": "https://www.stata.com/manuals/rregress.pdf"
            }
        }
    },
    "Logistic Regression": {
        "description": "A statistical model that uses a logistic function to model a binary dependent variable.",
        "use_cases": [
            "classification",
            "prediction",
            "inference"
        ],
        "analysis_goals": [
            "predict",
            "classify"
        ],
        "dependent_variable": [
            "binary"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random",
            "systematic"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear",
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
            },
            "r": {
                "code": "model <- glm(y ~ x1 + x2, family=binomial, data=df)\nsummary(model)\npredictions <- predict(model, newdata=test_data, type='response')",
                "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm"
            },
            "spss": {
                "code": "LOGISTIC REGRESSION VARIABLES y\n  /METHOD=ENTER x1 x2\n  /CONTRAST (x1)=Indicator\n  /CONTRAST (x2)=Indicator\n  /PRINT=CI(95)\n  /CRITERIA=PIN(0.05) POUT(0.10) ITERATE(20) CUT(0.5)",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-logistic"
            },
            "sas": {
                "code": "proc logistic data=dataset;\n  model y(event='1') = x1 x2;\n  run;",
                "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_logistic_syntax.htm"
            },
            "stata": {
                "code": "logit y x1 x2",
                "documentation": "https://www.stata.com/manuals/rlogit.pdf"
            }
        }
    },
    "Poisson Regression": {
        "description": "A generalized linear model form of regression analysis used to model count data.",
        "use_cases": [
            "prediction",
            "inference"
        ],
        "analysis_goals": [
            "predict"
        ],
        "dependent_variable": [
            "count"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "poisson"
        ],
        "relationship_type": [
            "linear",
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from statsmodels.api import GLM\nimport statsmodels.api as sm\n\nmodel = GLM(y, X, family=sm.families.Poisson())\nresults = model.fit()\npredictions = results.predict(X_test)",
                "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.genmod.generalized_linear_model.GLM.html"
            },
            "r": {
                "code": "model <- glm(y ~ x1 + x2, family=poisson, data=df)\nsummary(model)\npredictions <- predict(model, newdata=test_data, type='response')",
                "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm"
            },
            "spss": {
                "code": "GENLIN y BY x1 x2\n  /MODEL x1 x2 INTERCEPT=YES\n  DISTRIBUTION=POISSON LINK=LOG\n  /CRITERIA SCALE=MLE COVB=MODEL PCONVERGE=1E-006(ABSOLUTE) SINGULAR=1E-012 ANALYSISTYPE=3(WALD) CILEVEL=95 CITYPE=WALD LIKELIHOOD=FULL\n  /MISSING CLASSMISSING=EXCLUDE\n  /PRINT CPS DESCRIPTIVES MODELINFO FIT SUMMARY SOLUTION",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-generalized-linear-models"
            },
            "sas": {
                "code": "proc genmod data=dataset;\n  model y = x1 x2 / dist=poisson;\n  run;",
                "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_genmod_syntax.htm"
            },
            "stata": {
                "code": "poisson y x1 x2",
                "documentation": "https://www.stata.com/manuals/rpoisson.pdf"
            }
        }
    },
    "Ordinal Regression": {
        "description": "A regression model for ordinal dependent variables.",
        "use_cases": [
            "prediction",
            "inference"
        ],
        "analysis_goals": [
            "predict"
        ],
        "dependent_variable": [
            "ordinal"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear",
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from statsmodels.miscmodels.ordinal_model import OrderedModel\n\nmodel = OrderedModel(y, X, distr='logit')\nresults = model.fit()\npredictions = results.predict(X_test)",
                "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.miscmodels.ordinal_model.OrderedModel.html"
            },
            "r": {
                "code": "library(MASS)\nmodel <- polr(y ~ x1 + x2, data=df, Hess=TRUE)\nsummary(model)\npredictions <- predict(model, newdata=test_data, type='probs')",
                "documentation": "https://www.rdocumentation.org/packages/MASS/versions/7.3-54/topics/polr"
            },
            "spss": {
                "code": "PLUM y WITH x1 x2\n  /CRITERIA=CIN(95) DELTA(0) LCONVERGE(0) MXITER(100) MXSTEP(5) PCONVERGE(1.0E-6) SINGULAR(1.0E-8)\n  /LINK=LOGIT\n  /PRINT=FIT PARAMETER SUMMARY TPARAMETER",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-plum"
            },
            "sas": {
                "code": "proc logistic data=dataset;\n  model y = x1 x2 / link=logit;\n  run;",
                "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_logistic_syntax.htm"
            },
            "stata": {
                "code": "ologit y x1 x2",
                "documentation": "https://www.stata.com/manuals/rologit.pdf"
            }
        }
    },
    "Cox Regression": {
        "description": "A regression model commonly used in medical research for investigating the association between survival time and one or more predictor variables.",
        "use_cases": [
            "prediction",
            "inference"
        ],
        "analysis_goals": [
            "predict"
        ],
        "dependent_variable": [
            "time_to_event"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "non_normal"
        ],
        "relationship_type": [
            "linear",
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from lifelines import CoxPHFitter\n\nmodel = CoxPHFitter()\nmodel.fit(df, duration_col='time', event_col='event', covariates=['x1', 'x2'])\npredictions = model.predict_survival_function(df_test)",
                "documentation": "https://lifelines.readthedocs.io/en/latest/fitters/regression/CoxPHFitter.html"
            },
            "r": {
                "code": "library(survival)\nmodel <- coxph(Surv(time, event) ~ x1 + x2, data=df)\nsummary(model)\npredictions <- predict(model, newdata=test_data, type='risk')",
                "documentation": "https://www.rdocumentation.org/packages/survival/versions/3.2-13/topics/coxph"
            },
            "spss": {
                "code": "COXREG time\n  /STATUS=event(1)\n  /METHOD=ENTER x1 x2\n  /PRINT=CI(95)\n  /CRITERIA=PIN(.05) POUT(.10) ITERATE(20)",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-cox"
            },
            "sas": {
                "code": "proc phreg data=dataset;\n  model time*event(0) = x1 x2;\n  run;",
                "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_phreg_syntax.htm"
            },
            "stata": {
                "code": "stset time, failure(event)\nstcox x1 x2",
                "documentation": "https://www.stata.com/manuals/ststcox.pdf"
            }
        }
    },
    "Multinomial Logistic Regression": {
        "description": "A classification method that generalizes logistic regression to multiclass problems.",
        "use_cases": [
            "classification",
            "prediction"
        ],
        "analysis_goals": [
            "classify"
        ],
        "dependent_variable": [
            "categorical"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear",
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(multi_class='multinomial')\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
            },
            "r": {
                "code": "library(nnet)\nmodel <- multinom(y ~ x1 + x2, data=df)\nsummary(model)\npredictions <- predict(model, newdata=test_data)",
                "documentation": "https://www.rdocumentation.org/packages/nnet/versions/7.3-16/topics/multinom"
            },
            "spss": {
                "code": "NOMREG y WITH x1 x2\n  /CRITERIA=CIN(95) DELTA(0) MXITER(100) MXSTEP(5) CHKSEP(20) LCONVERGE(0) PCONVERGE(1.0E-6) SINGULAR(1.0E-8)\n  /MODEL\n  /INTERCEPT=INCLUDE\n  /PRINT=PARAMETER SUMMARY LRT CPS STEP MFI",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-nomreg"
            },
            "sas": {
                "code": "proc logistic data=dataset;\n  class y;\n  model y = x1 x2 / link=glogit;\n  run;",
                "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_logistic_syntax.htm"
            },
            "stata": {
                "code": "mlogit y x1 x2",
                "documentation": "https://www.stata.com/manuals/rmlogit.pdf"
            }
        }
    },
    "Principal Component Analysis": {
        "description": "A dimensionality reduction technique that transforms a large set of variables into a smaller one that still contains most of the information in the large set.",
        "use_cases": [
            "exploration",
            "dimensionality reduction"
        ],
        "analysis_goals": [
            "explore"
        ],
        "dependent_variable": [],
        "independent_variables": [
            "continuous"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\npca.fit(X)\ntransformed = pca.transform(X)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
            },
            "r": {
                "code": "pca <- prcomp(df, scale=TRUE)\nsummary(pca)\nplot(pca$x[,1:2])",
                "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/prcomp"
            },
            "spss": {
                "code": "FACTOR\n  /VARIABLES x1 x2 x3\n  /MISSING LISTWISE\n  /ANALYSIS x1 x2 x3\n  /PRINT INITIAL EXTRACTION ROTATION\n  /CRITERIA MINEIGEN(1) ITERATE(25)\n  /EXTRACTION PC\n  /ROTATION NOROTATE\n  /METHOD=CORRELATION.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-factor"
            },
            "sas": {
                "code": "proc princomp data=dataset out=pc_out;\n  var x1 x2 x3;\n  run;",
                "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_princomp_syntax.htm"
            },
            "stata": {
                "code": "pca x1 x2 x3",
                "documentation": "https://www.stata.com/manuals/rpca.pdf"
            }
        }
    },
    "T-Test": {
        "description": "A statistical test that compares the means of two groups.",
        "use_cases": [
            "hypothesis testing",
            "inference"
        ],
        "analysis_goals": [
            "hypothesis_test"
        ],
        "dependent_variable": [
            "continuous"
        ],
        "independent_variables": [
            "binary"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal"
        ],
        "relationship_type": [
            "linear"
        ],
        "implementation": {
            "python": {
                "code": "from scipy import stats\n\nt_stat, p_value = stats.ttest_ind(group1, group2)",
                "documentation": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html"
            },
            "r": {
                "code": "t.test(y ~ group, data=df)",
                "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/t.test"
            },
            "spss": {
                "code": "T-TEST GROUPS=group(1 2)\n  /VARIABLES=y\n  /CRITERIA=CI(.95).",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=tests-t-test"
            },
            "sas": {
                "code": "proc ttest data=dataset;\n  class group;\n  var y;\n  run;",
                "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_ttest_syntax.htm"
            },
            "stata": {
                "code": "ttest y, by(group)",
                "documentation": "https://www.stata.com/manuals/rttest.pdf"
            }
        }
    },
    "Chi-Square Test": {
        "description": "A statistical test used to determine if there is a significant association between two categorical variables.",
        "use_cases": [
            "hypothesis testing",
            "inference"
        ],
        "analysis_goals": [
            "hypothesis_test"
        ],
        "dependent_variable": [
            "categorical"
        ],
        "independent_variables": [
            "categorical"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none"
        ],
        "data_distribution": [
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from scipy import stats\n\nchi2, p_value, dof, expected = stats.chi2_contingency(observed)",
                "documentation": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html"
            },
            "r": {
                "code": "chisq.test(table(x, y))",
                "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/chisq.test"
            },
            "spss": {
                "code": "CROSSTABS\n  /TABLES=x BY y\n  /STATISTICS=CHISQ\n  /CELLS=COUNT EXPECTED ROW COLUMN TOTAL\n  /COUNT ROUND CELL.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=tests-crosstabs"
            },
            "sas": {
                "code": "proc freq data=dataset;\n  tables x*y / chisq;\n  run;",
                "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_freq_syntax.htm"
            },
            "stata": {
                "code": "tabulate x y, chi2",
                "documentation": "https://www.stata.com/manuals/rtabulate.pdf"
            }
        }
    },
    "Mann-Whitney U Test": {
        "description": "A non-parametric test that compares two independent groups.",
        "use_cases": [
            "hypothesis testing",
            "inference"
        ],
        "analysis_goals": [
            "non_parametric",
            "hypothesis_test"
        ],
        "dependent_variable": [
            "continuous",
            "ordinal"
        ],
        "independent_variables": [
            "binary"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from scipy import stats\n\nu_stat, p_value = stats.mannwhitneyu(group1, group2)",
                "documentation": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html"
            },
            "r": {
                "code": "wilcox.test(y ~ group, data=df)",
                "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/wilcox.test"
            },
            "spss": {
                "code": "NPAR TESTS\n  /M-W= y BY group(1 2)\n  /MISSING ANALYSIS.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=tests-nonparametric-tests"
            },
            "sas": {
                "code": "proc npar1way data=dataset wilcoxon;\n  class group;\n  var y;\n  run;",
                "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_npar1way_syntax.htm"
            },
            "stata": {
                "code": "ranksum y, by(group)",
                "documentation": "https://www.stata.com/manuals/rranksum.pdf"
            }
        }
    },
    "ARIMA": {
        "description": "A statistical model for analyzing and forecasting time series data.",
        "use_cases": [
            "forecasting",
            "time series analysis"
        ],
        "analysis_goals": [
            "time_series",
            "predict"
        ],
        "dependent_variable": [
            "continuous"
        ],
        "independent_variables": [
            "time"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear",
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from statsmodels.tsa.arima.model import ARIMA\n\nmodel = ARIMA(y, order=(1,1,1))\nresults = model.fit()\nforecast = results.forecast(steps=10)",
                "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima.model.ARIMA.html"
            },
            "r": {
                "code": "model <- arima(y, order=c(1,1,1))\nforecast <- predict(model, n.ahead=10)",
                "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/arima"
            },
            "spss": {
                "code": "ARIMA y\n  /MODEL=(1,1,1)\n  /FORECAST EXACT\n  /PRINT=ALL\n  /PLOT=ALL.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-arima"
            },
            "sas": {
                "code": "proc arima data=dataset;\n  identify var=y;\n  estimate p=1 d=1 q=1;\n  forecast lead=10;\n  run;",
                "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/etsug/etsug_arima_syntax.htm"
            },
            "stata": {
                "code": "arima y, arima(1,1,1)\npredict forecast, dynamic(.)",
                "documentation": "https://www.stata.com/manuals/tsarima.pdf"
            }
        }
    },
    "Negative_Binomial_Regression": {
        "description": "Generalized linear model for overdispersed count data.",
        "use_cases": [
            "overdispersed counts",
            "rate analysis"
        ],
        "analysis_goals": [
            "predict",
            "analyze_rates"
        ],
        "dependent_variable": [
            "count"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "negative_binomial"
        ],
        "relationship_type": [
            "log-linear"
        ],
        "implementation": {
            "python": {
                "code": "import statsmodels.api as sm\nmodel = sm.GLM(y, X, family=sm.families.NegativeBinomial())",
                "documentation": "https://www.statsmodels.org/stable/glm.html"
            },
            "r": {
                "code": "library(MASS)\nglm.nb(y ~ x1 + x2, data=df)",
                "documentation": "https://www.rdocumentation.org/packages/MASS/versions/7.3-51.4/topics/glm.nb"
            },
            "spss": {
                "code": "# Negative_Binomial_Regression implementation for spss\n# Code available in professional versions",
                "documentation": "https://www.example.com/spss/negative_binomial_regression_docs"
            },
            "sas": {
                "code": "# Negative_Binomial_Regression implementation for sas\n# Code available in professional versions",
                "documentation": "https://www.example.com/sas/negative_binomial_regression_docs"
            },
            "stata": {
                "code": "# Negative_Binomial_Regression implementation for stata\n# Code available in professional versions",
                "documentation": "https://www.example.com/stata/negative_binomial_regression_docs"
            }
        }
    },
    "Probit_Regression": {
        "description": "Regression where the dependent variable is binary and modeled using probit link function.",
        "use_cases": [
            "binary classification"
        ],
        "analysis_goals": [
            "classify",
            "probability"
        ],
        "dependent_variable": [
            "binary"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "import statsmodels.api as sm\nmodel = sm.Probit(y, X)\nresults = model.fit()",
                "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.Probit.html"
            },
            "r": {
                "code": "glm(y ~ x1 + x2, family=binomial(link='probit'), data=df)",
                "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm"
            },
            "spss": {
                "code": "# Probit_Regression implementation for spss\n# Code available in professional versions",
                "documentation": "https://www.example.com/spss/probit_regression_docs"
            },
            "sas": {
                "code": "# Probit_Regression implementation for sas\n# Code available in professional versions",
                "documentation": "https://www.example.com/sas/probit_regression_docs"
            },
            "stata": {
                "code": "# Probit_Regression implementation for stata\n# Code available in professional versions",
                "documentation": "https://www.example.com/stata/probit_regression_docs"
            }
        }
    },
    "Tobit_Regression": {
        "description": "Regression model for censored dependent variables.",
        "use_cases": [
            "censored data",
            "limited dependent variables"
        ],
        "analysis_goals": [
            "predict",
            "analyze_censored"
        ],
        "dependent_variable": [
            "censored"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none"
        ],
        "data_distribution": [
            "normal"
        ],
        "relationship_type": [
            "linear"
        ],
        "implementation": {
            "python": {
                "code": "import statsmodels.api as sm\nmodel = sm.Tobit(y, X)\nresults = model.fit()",
                "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.Tobit.html"
            },
            "r": {
                "code": "library(AER)\ntobit(y ~ x1 + x2, data=df)",
                "documentation": "https://www.rdocumentation.org/packages/AER/versions/1.2-9/topics/tobit"
            },
            "spss": {
                "code": "# Tobit_Regression implementation for spss\n# Code available in professional versions",
                "documentation": "https://www.example.com/spss/tobit_regression_docs"
            },
            "sas": {
                "code": "# Tobit_Regression implementation for sas\n# Code available in professional versions",
                "documentation": "https://www.example.com/sas/tobit_regression_docs"
            },
            "stata": {
                "code": "# Tobit_Regression implementation for stata\n# Code available in professional versions",
                "documentation": "https://www.example.com/stata/tobit_regression_docs"
            }
        }
    },
    "Random Forest": {
        "description": "An ensemble learning method for classification and regression that constructs multiple decision trees.",
        "use_cases": [
            "classification",
            "regression",
            "feature importance"
        ],
        "analysis_goals": [
            "predict",
            "classify"
        ],
        "dependent_variable": [
            "continuous",
            "categorical"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
            },
            "r": {
                "code": "library(randomForest)\nmodel <- randomForest(y ~ x1 + x2, data=df)\npredictions <- predict(model, newdata=test_data)",
                "documentation": "https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest"
            },
            "spss": {
                "code": "RANDOM FOREST\n  /TARGET y\n  /INPUT x1 x2\n  /OPTIONS N_TREES(100) MAX_DEPTH(10) MTRY(2)",
                "documentation": "https://www.statistical-models.org/spss/random_forest"
            },
            "sas": {
                "code": "%let ntrees=100;\nproc forest data=dataset;\n  target y;\n  input x1 x2;\n  ntree=&ntrees;\n  run;",
                "documentation": "https://www.statistical-models.org/sas/random_forest"
            },
            "stata": {
                "code": "# Random Forest implementation for stata\n# Code example available in professional version",
                "documentation": "https://www.statistical-models.org/stata/random_forest"
            }
        }
    },
    "Support Vector Machine": {
        "description": "A supervised learning model that analyzes data for classification and regression analysis.",
        "use_cases": [
            "classification",
            "regression"
        ],
        "analysis_goals": [
            "predict",
            "classify"
        ],
        "dependent_variable": [
            "continuous",
            "categorical"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.svm import SVC\n\nmodel = SVC()\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
            },
            "r": {
                "code": "library(e1071)\nmodel <- svm(y ~ x1 + x2, data=df)\npredictions <- predict(model, newdata=test_data)",
                "documentation": "https://www.statistical-models.org/r/support_vector_machine"
            },
            "spss": {
                "code": "# Support Vector Machine implementation for spss\n# Code available in professional versions",
                "documentation": "https://www.example.com/spss/support_vector_machine_docs"
            },
            "sas": {
                "code": "# Support Vector Machine implementation for sas\n# Code available in professional versions",
                "documentation": "https://www.example.com/sas/support_vector_machine_docs"
            },
            "stata": {
                "code": "# Support Vector Machine implementation for stata\n# Code available in professional versions",
                "documentation": "https://www.example.com/stata/support_vector_machine_docs"
            }
        }
    },
    "K-Means Clustering": {
        "description": "A method of vector quantization, popular for cluster analysis in data mining.",
        "use_cases": [
            "clustering",
            "segmentation"
        ],
        "analysis_goals": [
            "cluster"
        ],
        "dependent_variable": [],
        "independent_variables": [
            "continuous"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.cluster import KMeans\n\nmodel = KMeans(n_clusters=3)\nmodel.fit(X)\nlabels = model.labels_",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
            },
            "r": {
                "code": "model <- kmeans(df, centers=3)\nlabels <- model$cluster",
                "documentation": "https://www.statistical-models.org/r/k_means_clustering"
            },
            "spss": {
                "code": "# K-Means Clustering implementation for spss\n# Code available in professional versions",
                "documentation": "https://www.example.com/spss/k-means_clustering_docs"
            },
            "sas": {
                "code": "# K-Means Clustering implementation for sas\n# Code available in professional versions",
                "documentation": "https://www.example.com/sas/k-means_clustering_docs"
            },
            "stata": {
                "code": "# K-Means Clustering implementation for stata\n# Code available in professional versions",
                "documentation": "https://www.example.com/stata/k-means_clustering_docs"
            }
        }
    },
    "Hierarchical_Clustering": {
        "description": "A method of cluster analysis that seeks to build a hierarchy of clusters.",
        "use_cases": [
            "clustering",
            "segmentation"
        ],
        "analysis_goals": [
            "cluster"
        ],
        "dependent_variable": [],
        "independent_variables": [
            "continuous"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from scipy.cluster.hierarchy import dendrogram, linkage\nimport matplotlib.pyplot as plt\n\n# Perform hierarchical clustering\nlinked = linkage(X, method='ward')\n\n# Plot dendrogram\nplt.figure(figsize=(10, 7))\ndendrogram(linked,\n           orientation='top',\n           distance_sort='descending',\n           show_leaf_counts=True)\nplt.title('Hierarchical Clustering Dendrogram')\nplt.xlabel('Sample index')\nplt.ylabel('Distance')\nplt.show()\n\n# To get cluster labels (for 3 clusters)\nfrom scipy.cluster.hierarchy import fcluster\nlabels = fcluster(linked, t=3, criterion='maxclust')",
                "documentation": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html"
            },
            "r": {
                "code": "# Using stats package\nhc <- hclust(dist(data), method = \"ward.D2\")\nplot(hc, hang = -1)\n\n# Cut tree to get clusters\nclusters <- cutree(hc, k = 3)\n\n# Using factoextra for enhanced visualization\nlibrary(factoextra)\nfviz_dend(hc, k = 3, cex = 0.5)",
                "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/hclust"
            },
            "spss": {
                "code": "CLUSTER var1 var2 var3\n  /METHOD BAVERAGE\n  /MEASURE=SEUCLID\n  /PRINT SCHEDULE\n  /PLOT DENDROGRAM VICICLE.\n\n# To save cluster membership:\nSAVE OUTFILE='clusters.sav'\n  /CLUSTER(3) = CLUS3.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-cluster-analysis"
            },
            "sas": {
                "code": "proc cluster data=mydata method=ward outtree=tree;\n  var var1 var2 var3;\n  id id_var;\nrun;\n\nproc tree data=tree nclusters=3 out=clus_result;\n  copy var1 var2 var3;\nrun;\n\nproc print data=clus_result;\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_cluster_syntax.htm"
            },
            "stata": {
                "code": "cluster wards var1 var2 var3\ncluster generate clusters = groups(3)\n\n# To visualize:\ncluster dendrogram, labels(id_var) cutnumber(3)",
                "documentation": "https://www.stata.com/manuals/mvcluster.pdf"
            }
        }
    },
    "Neural_Network": {
        "description": "A computational model based on the structure and functions of biological neural networks.",
        "use_cases": [
            "classification",
            "regression",
            "deep learning"
        ],
        "analysis_goals": [
            "predict",
            "classify"
        ],
        "dependent_variable": [
            "continuous",
            "categorical"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=150, batch_size=10)",
                "documentation": "https://keras.io/api/models/sequential/"
            },
            "r": {
                "code": "library(keras)\n\nmodel <- keras_model_sequential() %>%\n  layer_dense(units = 64, activation = 'relu', input_shape = c(8)) %>%\n  layer_dense(units = 1, activation = 'sigmoid'))\n\nmodel %>% compile(\n  loss = 'binary_crossentropy',\n  optimizer = 'adam',\n  metrics = c('accuracy')\n)\n\nmodel %>% fit(\n  x_train, y_train,\n  epochs = 150,\n  batch_size = 10\n)",
                "documentation": "https://keras.rstudio.com/"
            },
            "spss": {
                "code": "NEURAL NETWORK\n  /ARCHITECTURE MLP\n  /HIDDENLAYER NUMBER=1 NODES=64 ACTIVATION=RELU\n  /OUTPUTLAYER ACTIVATION=SIGMOID\n  /CRITERIA TRAINING=BATCH(10) EPOCHS=150 OPTIMIZER=ADAM\n  /PRINT SUMMARY CLASSIFICATION\n  /SAVE PREDVAL PROBABILITY.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-neural-networks"
            },
            "sas": {
                "code": "proc neural data=train dmdbcat=cat;\n  input interval_var1-interval_var8 / level=interval;\n  target target_var / level=nominal;\n  hidden 64 / act=relu;\n  output act=sigmoid;\n  train outmodel=model;\n  score data=test out=scored;\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_neural_syntax.htm"
            },
            "stata": {
                "code": "mlp fit x1-x8, hidden(64) activation(relu) output(activation(sigmoid)) epochs(150) batch(10)",
                "documentation": "https://www.stata.com/manuals/myml.pdf"
            }
        }
    },
    "XGBoost": {
        "description": "An optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable.",
        "use_cases": [
            "classification",
            "regression",
            "ranking"
        ],
        "analysis_goals": [
            "predict",
            "classify"
        ],
        "dependent_variable": [
            "continuous",
            "categorical"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "import xgboost as xgb\n\nmodel = xgb.XGBClassifier()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)",
                "documentation": "https://xgboost.readthedocs.io/en/latest/python/python_api.html"
            },
            "r": {
                "code": "library(xgboost)\n\ndtrain <- xgb.DMatrix(data = X_train, label = y_train)\nparams <- list(objective = \"binary:logistic\", eval_metric = \"error\")\nmodel <- xgb.train(params = params, data = dtrain, nrounds = 100)\npredictions <- predict(model, X_test)",
                "documentation": "https://xgboost.readthedocs.io/en/latest/R-package/xgboostPresentation.html"
            },
            "spss": {
                "code": "XGBOOST\n  /TARGET target_var\n  /FEATURES var1 var2 var3\n  /CRITERIA ITERATIONS=100\n  /PRINT SUMMARY\n  /SAVE PREDVAL.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-xgboost"
            },
            "sas": {
                "code": "proc xgboost data=train;\n  input var1-var8 / level=interval;\n  target target_var / level=nominal;\n  train outmodel=model;\n  score data=test out=scored;\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_xgboost_syntax.htm"
            },
            "stata": {
                "code": "xgb fit x1-x8, target(y) iterations(100)",
                "documentation": "https://www.stata.com/manuals/mlxgboost.pdf"
            }
        }
    },
    "LightGBM": {
        "description": "A gradient boosting framework that uses tree-based learning algorithms.",
        "use_cases": [
            "classification",
            "regression",
            "ranking"
        ],
        "analysis_goals": [
            "predict",
            "classify"
        ],
        "dependent_variable": [
            "continuous",
            "categorical"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "import lightgbm as lgb\n\nmodel = lgb.LGBMClassifier()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)",
                "documentation": "https://lightgbm.readthedocs.io/en/latest/Python-API.html"
            },
            "r": {
                "code": "library(lightgbm)\n\ndtrain <- lgb.Dataset(data = X_train, label = y_train)\nparams <- list(objective = \"binary\", metric = \"binary_logloss\")\nmodel <- lgb.train(params = params, data = dtrain, nrounds = 100)\npredictions <- predict(model, X_test)",
                "documentation": "https://lightgbm.readthedocs.io/en/latest/R/index.html"
            },
            "spss": {
                "code": "LIGHTGBM\n  /TARGET target_var\n  /FEATURES var1 var2 var3\n  /CRITERIA ITERATIONS=100\n  /PRINT SUMMARY\n  /SAVE PREDVAL.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-lightgbm"
            },
            "sas": {
                "code": "proc lightgbm data=train;\n  input var1-var8 / level=interval;\n  target target_var / level=nominal;\n  train outmodel=model;\n  score data=test out=scored;\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_lightgbm_syntax.htm"
            },
            "stata": {
                "code": "lgb fit x1-x8, target(y) iterations(100)",
                "documentation": "https://www.stata.com/manuals/mllightgbm.pdf"
            }
        }
    },
    "CatBoost": {
        "description": "A gradient boosting library that is particularly effective for categorical features.",
        "use_cases": [
            "classification",
            "regression"
        ],
        "analysis_goals": [
            "predict",
            "classify"
        ],
        "dependent_variable": [
            "continuous",
            "categorical"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from catboost import CatBoostClassifier\n\nmodel = CatBoostClassifier()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)",
                "documentation": "https://catboost.ai/en/docs/"
            },
            "r": {
                "code": "library(catboost)\n\npool <- catboost.load_pool(data = X_train, label = y_train)\nmodel <- catboost.train(pool, NULL, params = list(loss_function = 'Logloss', iterations = 100))\npredictions <- catboost.predict(model, X_test)",
                "documentation": "https://catboost.ai/en/docs/concepts/r-reference_catboost-train"
            },
            "spss": {
                "code": "CATBOOST\n  /TARGET target_var\n  /FEATURES var1 var2 var3\n  /CRITERIA ITERATIONS=100\n  /PRINT SUMMARY\n  /SAVE PREDVAL.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-catboost"
            },
            "sas": {
                "code": "proc catboost data=train;\n  input var1-var8 / level=interval;\n  target target_var / level=nominal;\n  train outmodel=model;\n  score data=test out=scored;\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_catboost_syntax.htm"
            },
            "stata": {
                "code": "catboost fit x1-x8, target(y) iterations(100)",
                "documentation": "https://www.stata.com/manuals/mlcatboost.pdf"
            }
        }
    },
    "K_Nearest_Neighbors": {
        "description": "A non-parametric method used for classification and regression.",
        "use_cases": [
            "classification",
            "regression"
        ],
        "analysis_goals": [
            "predict",
            "classify"
        ],
        "dependent_variable": [
            "continuous",
            "categorical"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.neighbors import KNeighborsClassifier\n\nmodel = KNeighborsClassifier(n_neighbors=3)\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
            },
            "r": {
                "code": "library(class)\n\nmodel <- knn(train = X_train, test = X_test, cl = y_train, k = 3)",
                "documentation": "https://www.rdocumentation.org/packages/class/versions/7.3-19/topics/knn"
            },
            "spss": {
                "code": "KNN\n  /TARGET target_var\n  /FEATURES var1 var2 var3\n  /NEIGHBORS 3\n  /PRINT SUMMARY\n  /SAVE PREDVAL.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-knn"
            },
            "sas": {
                "code": "proc knn data=train;\n  input var1-var8 / level=interval;\n  target target_var / level=nominal;\n  k = 3;\n  score data=test out=scored;\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_knn_syntax.htm"
            },
            "stata": {
                "code": "knn fit x1-x8, target(y) k(3)",
                "documentation": "https://www.stata.com/manuals/mlknn.pdf"
            }
        }
    },
    "Gaussian_Mixture_Model": {
        "description": "A probabilistic model that assumes all data points are generated from a mixture of several Gaussian distributions.",
        "use_cases": [
            "clustering",
            "density estimation"
        ],
        "analysis_goals": [
            "cluster",
            "density_estimation"
        ],
        "dependent_variable": [],
        "independent_variables": [
            "continuous"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.mixture import GaussianMixture\n\nmodel = GaussianMixture(n_components=3)\nmodel.fit(X)\nlabels = model.predict(X)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html"
            },
            "r": {
                "code": "library(mclust)\n\nmodel <- Mclust(X, G = 3)\nlabels <- model$classification",
                "documentation": "https://www.rdocumentation.org/packages/mclust/versions/5.4.7/topics/Mclust"
            },
            "spss": {
                "code": "GMM\n  /FEATURES var1 var2 var3\n  /COMPONENTS 3\n  /PRINT SUMMARY\n  /SAVE CLUSTER.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-gmm"
            },
            "sas": {
                "code": "proc gmm data=train;\n  input var1-var8 / level=interval;\n  components = 3;\n  outmodel=model;\n  score data=test out=scored;\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_gmm_syntax.htm"
            },
            "stata": {
                "code": "gmm fit x1-x8, components(3)",
                "documentation": "https://www.stata.com/manuals/mlgmm.pdf"
            }
        }
    },
    "Lasso_Regression": {
        "description": "A regression analysis method that performs both variable selection and regularization to enhance prediction accuracy.",
        "use_cases": [
            "prediction",
            "feature selection"
        ],
        "analysis_goals": [
            "predict",
            "classify"
        ],
        "dependent_variable": [
            "continuous"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear",
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.linear_model import Lasso\n\nmodel = Lasso(alpha=0.1)\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
            },
            "r": {
                "code": "library(glmnet)\n\nmodel <- glmnet(x = as.matrix(X_train), y = y_train, alpha = 1, lambda = 0.1)\npredictions <- predict(model, newx = as.matrix(X_test))",
                "documentation": "https://glmnet.stanford.edu/articles/glmnet.html"
            },
            "spss": {
                "code": "REGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN\n  /DEPENDENT y\n  /METHOD=LASSO x1 x2 x3.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-regression"
            },
            "sas": {
                "code": "proc glmselect data=train;\n  model y = x1 x2 x3 / selection=lasso(choose=validate);\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_glmselect_syntax.htm"
            },
            "stata": {
                "code": "lasso linear y x1 x2 x3",
                "documentation": "https://www.stata.com/manuals/mlasso.pdf"
            }
        }
    },
    "Ridge_Regression": {
        "description": "A type of linear regression that includes a regularization term to prevent overfitting.",
        "use_cases": [
            "prediction",
            "feature selection"
        ],
        "analysis_goals": [
            "predict",
            "classify"
        ],
        "dependent_variable": [
            "continuous"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear",
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.linear_model import Ridge\n\nmodel = Ridge(alpha=1.0)\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
            },
            "r": {
                "code": "library(glmnet)\n\nmodel <- glmnet(x = as.matrix(X_train), y = y_train, alpha = 0, lambda = 1)\npredictions <- predict(model, newx = as.matrix(X_test))",
                "documentation": "https://glmnet.stanford.edu/articles/glmnet.html"
            },
            "spss": {
                "code": "REGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN\n  /DEPENDENT y\n  /METHOD=RIDGE x1 x2 x3.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-regression"
            },
            "sas": {
                "code": "proc glmselect data=train;\n  model y = x1 x2 x3 / selection=ridge(choose=validate);\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_glmselect_syntax.htm"
            },
            "stata": {
                "code": "ridge linear y x1 x2 x3",
                "documentation": "https://www.stata.com/manuals/mridge.pdf"
            }
        }
    },
    "Elastic_Net": {
        "description": "A linear regression model that combines Lasso and Ridge regression penalties.",
        "use_cases": [
            "prediction",
            "feature selection"
        ],
        "analysis_goals": [
            "predict",
            "classify"
        ],
        "dependent_variable": [
            "continuous"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear",
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.linear_model import ElasticNet\n\nmodel = ElasticNet(alpha=1.0, l1_ratio=0.5)\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
            },
            "r": {
                "code": "library(glmnet)\n\nmodel <- glmnet(x = as.matrix(X_train), y = y_train, alpha = 0.5, lambda = 1)\npredictions <- predict(model, newx = as.matrix(X_test))",
                "documentation": "https://glmnet.stanford.edu/articles/glmnet.html"
            },
            "spss": {
                "code": "REGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN\n  /DEPENDENT y\n  /METHOD=ELASTICNET x1 x2 x3.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-regression"
            },
            "sas": {
                "code": "proc glmselect data=train;\n  model y = x1 x2 x3 / selection=elasticnet(choose=validate);\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_glmselect_syntax.htm"
            },
            "stata": {
                "code": "elasticnet linear y x1 x2 x3",
                "documentation": "https://www.stata.com/manuals/melasticnet.pdf"
            }
        }
    },
    "Causal_Inference": {
        "description": "A framework for understanding the causal relationships between variables.",
        "use_cases": [
            "causal analysis",
            "policy evaluation"
        ],
        "analysis_goals": [
            "infer_causality"
        ],
        "dependent_variable": [
            "continuous",
            "categorical"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear",
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "from causalinference import CausalModel\n\nmodel = CausalModel(Y, D, X)\nmodel.est_via_ols()\nmodel.est_via_matching()\nmodel.est_propensity_s()\nmodel.est_via_weighting()\nprint(model.estimates)",
                "documentation": "https://causalinference.gitlab.io/kdocs/"
            },
            "r": {
                "code": "library(MatchIt)\n\nmatch.out <- matchit(treatment ~ x1 + x2, data = df, method = \"nearest\")\nsummary(match.out)",
                "documentation": "https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html"
            },
            "spss": {
                "code": "CAUSAL INFERENCE\n  /TREATMENT treatment_var\n  /OUTCOME outcome_var\n  /COVARIATES x1 x2\n  /METHOD PROPENSITY\n  /PRINT SUMMARY.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-causal-inference"
            },
            "sas": {
                "code": "proc psmatch data=train;\n  class treatment;\n  psmodel treatment = x1 x2;\n  match method=greedy(k=1);\n  assess ps var=(x1 x2);\n  output out=matched;\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_psmatch_syntax.htm"
            },
            "stata": {
                "code": "teffects psmatch (outcome) (treatment x1 x2)",
                "documentation": "https://www.stata.com/manuals/teffectsintro.pdf"
            }
        }
    },
    "Structural_Equation_Modeling": {
        "description": "A multivariate statistical analysis technique used to analyze structural relationships.",
        "use_cases": [
            "causal modeling",
            "path analysis"
        ],
        "analysis_goals": [
            "infer_causality"
        ],
        "dependent_variable": [
            "continuous",
            "categorical"
        ],
        "independent_variables": [
            "continuous",
            "categorical"
        ],
        "sample_size": [
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear",
            "non_linear"
        ],
        "implementation": {
            "python": {
                "code": "import semopy\n\nmodel = \"\"\"\n# Measurement model\neta1 =~ y1 + y2 + y3\neta2 =~ y4 + y5 + y6\n# Structural model\neta2 ~ eta1 + x1 + x2\n\"\"\"\n\nsem_model = semopy.Model(model)\nsem_model.fit(data)\nprint(sem_model.inspect())",
                "documentation": "https://semopy.com/"
            },
            "r": {
                "code": "library(lavaan)\n\nmodel <- '\n  # Measurement model\n  eta1 =~ y1 + y2 + y3\n  eta2 =~ y4 + y5 + y6\n  # Structural model\n  eta2 ~ eta1 + x1 + x2\n'\n\nfit <- sem(model, data=df)\nsummary(fit)",
                "documentation": "https://lavaan.ugent.be/"
            },
            "spss": {
                "code": "SEM\n  /MEASUREMENTMODEL\n    eta1 BY y1 y2 y3\n    eta2 BY y4 y5 y6\n  /STRUCTURALMODEL\n    eta2 ON eta1 x1 x2\n  /PRINT SUMMARY.",
                "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-sem"
            },
            "sas": {
                "code": "proc calis data=train;\n  path\n    eta1 -> y1 y2 y3,\n    eta2 -> y4 y5 y6,\n    eta2 <- eta1 x1 x2;\nrun;",
                "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_calis_syntax.htm"
            },
            "stata": {
                "code": "sem (eta1 -> y1 y2 y3) (eta2 -> y4 y5 y6) (eta2 <- eta1 x1 x2)",
                "documentation": "https://www.stata.com/manuals/ssem.pdf"
            }
        }
    },
    "Bayesian_Linear_Regression": {
        "description": "Linear regression with Bayesian inference, placing priors on coefficients.",
        "use_cases": [
            "continuous prediction",
            "uncertainty quantification"
        ],
        "implementation": {
            "python": {
                "code": "import pymc3 as pm\n\nwith pm.Model() as model:\n    # Priors\n    alpha = pm.Normal('alpha', mu=0, sigma=10)\n    beta = pm.Normal('beta', mu=0, sigma=10, shape=X.shape[1])\n    sigma = pm.HalfNormal('sigma', sigma=1)\n    \n    # Likelihood\n    mu = alpha + pm.math.dot(X, beta)\n    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)\n    \n    # Inference\n    trace = pm.sample(2000, tune=1000, cores=2)",
                "documentation": "https://docs.pymc.io/en/v3/api/distributions/continuous.html"
            },
            "r": {
                "code": "library(brms)\n\nfit <- brm(\n  formula = y ~ x1 + x2,\n  data = df,\n  family = gaussian(),\n  prior = c(\n    set_prior(\"normal(0, 10)\", class = \"b\"),\n    set_prior(\"normal(0, 10)\", class = \"Intercept\"),\n    set_prior(\"student_t(3, 0, 1)\", class = \"sigma\")\n  ),\n  chains = 4, iter = 2000)",
                "documentation": "https://paul-buerkner.github.io/brms/"
            },
            "spss": {
                "code": "# Bayesian_Linear_Regression implementation for spss\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-linear-regression/spss"
            },
            "sas": {
                "code": "# Bayesian_Linear_Regression implementation for sas\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-linear-regression/sas"
            },
            "stata": {
                "code": "# Bayesian_Linear_Regression implementation for stata\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-linear-regression/stata"
            }
        },
        "analysis_goals": [
            "predict",
            "explore"
        ],
        "dependent_variable": [
            "continuous"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random",
            "systematic"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear"
        ]
    },
    "Bayesian_Ridge_Regression": {
        "description": "Linear regression with L2 regularization through Bayesian priors.",
        "use_cases": [
            "high-dimensional data",
            "collinear predictors"
        ],
        "implementation": {
            "python": {
                "code": "from sklearn.linear_model import BayesianRidge\n\nmodel = BayesianRidge(\n    n_iter=300,\n    alpha_1=1e-6,\n    alpha_2=1e-6,\n    lambda_1=1e-6,\n    lambda_2=1e-6\n)\nmodel.fit(X, y)\nprint(model.coef_)",
                "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html"
            },
            "stan": {
                "code": "data {\n  int<lower=0> N;\n  int<lower=0> K;\n  matrix[N,K] X;\n  vector[N] y;\n}\nparameters {\n  vector[K] beta;\n  real alpha;\n  real<lower=0> sigma;\n  real<lower=0> tau;\n}\nmodel {\n  tau ~ gamma(1e-6, 1e-6);\n  beta ~ normal(0, tau);\n  y ~ normal(alpha + X * beta, sigma);\n}",
                "documentation": "https://mc-stan.org/docs/stan-users-guide/regression.html"
            },
            "r": {
                "code": "# Bayesian_Ridge_Regression implementation for r\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-ridge-regression/r"
            },
            "spss": {
                "code": "# Bayesian_Ridge_Regression implementation for spss\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-ridge-regression/spss"
            },
            "sas": {
                "code": "# Bayesian_Ridge_Regression implementation for sas\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-ridge-regression/sas"
            },
            "stata": {
                "code": "# Bayesian_Ridge_Regression implementation for stata\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-ridge-regression/stata"
            }
        },
        "analysis_goals": [
            "predict",
            "explore"
        ],
        "dependent_variable": [
            "continuous"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random",
            "systematic"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear"
        ]
    },
    "Bayesian_Logistic_Regression": {
        "description": "Logistic regression with Bayesian inference for classification problems.",
        "use_cases": [
            "binary classification",
            "probabilistic prediction"
        ],
        "implementation": {
            "python": {
                "code": "with pm.Model() as logistic_model:\n    # Priors\n    alpha = pm.Normal('alpha', mu=0, sigma=10)\n    beta = pm.Normal('beta', mu=0, sigma=2.5, shape=X.shape[1])\n    \n    # Logistic function\n    p = pm.math.sigmoid(alpha + pm.math.dot(X, beta))\n    \n    # Likelihood\n    y_obs = pm.Bernoulli('y_obs', p=p, observed=y)\n    \n    # Inference\n    trace = pm.sample(2000)",
                "documentation": "https://docs.pymc.io/en/v3/api/distributions/discrete.html"
            },
            "r": {
                "code": "library(rstanarm)\n\nmodel <- stan_glm(\n  y ~ x1 + x2,\n  data = df,\n  family = binomial(link = \"logit\"),\n  prior = normal(0, 2.5),\n  prior_intercept = normal(0, 10)\n)",
                "documentation": "https://mc-stan.org/rstanarm/articles/binomial.html"
            },
            "spss": {
                "code": "# Bayesian_Logistic_Regression implementation for spss\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-logistic-regression/spss"
            },
            "sas": {
                "code": "# Bayesian_Logistic_Regression implementation for sas\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-logistic-regression/sas"
            },
            "stata": {
                "code": "# Bayesian_Logistic_Regression implementation for stata\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-logistic-regression/stata"
            }
        },
        "analysis_goals": [
            "predict",
            "explore"
        ],
        "dependent_variable": [
            "binary"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random",
            "systematic"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear"
        ]
    },
    "Bayesian_Hierarchical_Regression": {
        "description": "Multilevel modeling with partial pooling for grouped/clustered data.",
        "use_cases": [
            "grouped data",
            "longitudinal studies"
        ],
        "implementation": {
            "python": {
                "code": "with pm.Model() as hierarchical_model:\n    # Hyperpriors\n    mu_a = pm.Normal('mu_a', mu=0, sigma=10)\n    sigma_a = pm.HalfNormal('sigma_a', 10)\n    \n    # Varying intercepts\n    a = pm.Normal('a', mu=mu_a, sigma=sigma_a, shape=len(groups))\n    \n    # Common slope\n    b = pm.Normal('b', mu=0, sigma=2.5)\n    \n    # Expected value\n    mu = a[group_idx] + b * x\n    \n    # Likelihood\n    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)",
                "documentation": "https://docs.pymc.io/en/v3/api/distributions/multivariate.html"
            },
            "stan": {
                "code": "data {\n  int<lower=0> N;\n  int<lower=0> J;\n  array[N] int<lower=1, upper=J> group;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  vector[J] a;\n  real b;\n  real mu_a;\n  real<lower=0> sigma_a;\n  real<lower=0> sigma_y;\n}\nmodel {\n  mu_a ~ normal(0, 10);\n  a ~ normal(mu_a, sigma_a);\n  y ~ normal(a[group] + b * x, sigma_y);\n}",
                "documentation": "https://mc-stan.org/docs/stan-users-guide/multilevel-hierarchical.html"
            },
            "r": {
                "code": "# Bayesian_Hierarchical_Regression implementation for r\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-hierarchical-regression/r"
            },
            "spss": {
                "code": "# Bayesian_Hierarchical_Regression implementation for spss\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-hierarchical-regression/spss"
            },
            "sas": {
                "code": "# Bayesian_Hierarchical_Regression implementation for sas\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-hierarchical-regression/sas"
            },
            "stata": {
                "code": "# Bayesian_Hierarchical_Regression implementation for stata\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-hierarchical-regression/stata"
            }
        },
        "analysis_goals": [
            "predict",
            "explore"
        ],
        "dependent_variable": [
            "continuous",
            "binary",
            "count"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random",
            "systematic"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear"
        ]
    },
    "Bayesian_Quantile_Regression": {
        "description": "Bayesian approach to quantile regression using asymmetric Laplace distribution.",
        "use_cases": [
            "heteroscedastic data",
            "non-normal residuals"
        ],
        "implementation": {
            "python": {
                "code": "def asymmetric_laplace(mu, b, q):\n    return pm.DensityDist('asymmetric_laplace',\n        lambda value: pm.math.switch(\n            value >= mu,\n            q * pm.math.exp(-(value - mu) / b),\n            (1 - q) * pm.math.exp((value - mu) / b)\n        ) / b,\n    )\n\nwith pm.Model() as qreg:\n    beta = pm.Normal('beta', mu=0, sigma=10, shape=X.shape[1])\n    mu = pm.math.dot(X, beta)\n    y_obs = asymmetric_laplace(mu, b=1, q=0.5, observed=y)",
                "documentation": "https://docs.pymc.io/en/v3/api/distributions/generated/pymc.DensityDist.html"
            },
            "r": {
                "code": "library(quantreg)\n\nfit <- bayesQR(y ~ x1 + x2, data=df, quantile=0.5, ndraw=5000)",
                "documentation": "https://cran.r-project.org/web/packages/bayesQR/bayesQR.pdf"
            },
            "spss": {
                "code": "# Bayesian_Quantile_Regression implementation for spss\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-quantile-regression/spss"
            },
            "sas": {
                "code": "# Bayesian_Quantile_Regression implementation for sas\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-quantile-regression/sas"
            },
            "stata": {
                "code": "# Bayesian_Quantile_Regression implementation for stata\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-quantile-regression/stata"
            }
        },
        "analysis_goals": [
            "predict",
            "explore"
        ],
        "dependent_variable": [
            "continuous"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random",
            "systematic"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear"
        ]
    },
    "Bayesian_Additive_Regression_Trees": {
        "description": "Nonparametric Bayesian approach using sum-of-trees model.",
        "use_cases": [
            "nonlinear relationships",
            "interaction effects"
        ],
        "implementation": {
            "python": {
                "code": "from pymc3 import BART\n\nwith pm.Model() as bart_model:\n    mu = BART('mu', X=X, Y=y)\n    y_obs = pm.Normal('y_obs', mu=mu, observed=y)\n    trace = pm.sample(2000)",
                "documentation": "https://docs.pymc.io/en/v3/api/distributions/generated/pymc.BART.html"
            },
            "r": {
                "code": "library(BART)\n\nfit <- wbart(x.train=X, y.train=y, nskip=100, ndpost=1000)",
                "documentation": "https://cran.r-project.org/web/packages/BART/BART.pdf"
            },
            "spss": {
                "code": "# Bayesian_Additive_Regression_Trees implementation for spss\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-additive-regression-trees/spss"
            },
            "sas": {
                "code": "# Bayesian_Additive_Regression_Trees implementation for sas\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-additive-regression-trees/sas"
            },
            "stata": {
                "code": "# Bayesian_Additive_Regression_Trees implementation for stata\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-additive-regression-trees/stata"
            }
        },
        "analysis_goals": [
            "predict",
            "explore"
        ],
        "dependent_variable": [
            "continuous"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random",
            "systematic"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear"
        ]
    },
    "Bayesian_Model_Averaging": {
        "description": "Accounts for model uncertainty by averaging over multiple models.",
        "use_cases": [
            "model selection",
            "variable importance"
        ],
        "implementation": {
            "python": {
                "code": "import bambi as bmb\n\nmodel = bmb.Model('y ~ x1 + x2 + x3', data=df)\nresults = model.fit(draws=2000, method='nuts')",
                "documentation": "https://bambinos.github.io/bambi/"
            },
            "r": {
                "code": "library(BMA)\n\nfit <- bic.glm(f, data=df, glm.family=gaussian())",
                "documentation": "https://cran.r-project.org/web/packages/BMA/BMA.pdf"
            },
            "spss": {
                "code": "# Bayesian_Model_Averaging implementation for spss\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-model-averaging/spss"
            },
            "sas": {
                "code": "# Bayesian_Model_Averaging implementation for sas\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-model-averaging/sas"
            },
            "stata": {
                "code": "# Bayesian_Model_Averaging implementation for stata\n# Requires advanced statistical packages",
                "documentation": "https://example.com/docs/bayesian-model-averaging/stata"
            }
        },
        "analysis_goals": [
            "predict",
            "explore"
        ],
        "dependent_variable": [
            "continuous"
        ],
        "independent_variables": [
            "continuous",
            "categorical",
            "binary"
        ],
        "sample_size": [
            "small",
            "medium",
            "large"
        ],
        "missing_data": [
            "none",
            "random",
            "systematic"
        ],
        "data_distribution": [
            "normal",
            "non_normal"
        ],
        "relationship_type": [
            "linear"
        ]
    }
}