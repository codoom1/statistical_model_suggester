{
  "Linear Regression": {
    "description": "A powerful statistical approach that models the linear relationship between a dependent variable and one or more independent variables. It finds the best-fitting straight line through the data by minimizing the sum of squared residuals, making it ideal for prediction, exploration of relationships, and testing causal hypotheses when assumptions are met.",
    "use_cases": [
      "prediction",
      "exploration",
      "inference"
    ],
    "analysis_goals": [
      "predict",
      "explore"
    ],
    "dependent_variable": [
      "continuous"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "binary"
    ],
    "sample_size": [
      "small",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random",
      "systematic"
    ],
    "data_distribution": [
      "normal",
      "non_normal"
    ],
    "relationship_type": [
      "linear"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
        "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
      },
      "r": {
        "code": "model <- lm(y ~ x1 + x2, data=df)\nsummary(model)\npredictions <- predict(model, newdata=test_data)",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm"
      },
      "spss": {
        "code": "REGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN\n  /DEPENDENT y\n  /METHOD=ENTER x1 x2",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-linear"
      },
      "sas": {
        "code": "proc reg data=dataset;\n  model y = x1 x2;\n  run;",
        "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_reg_syntax.htm"
      },
      "stata": {
        "code": "regress y x1 x2",
        "documentation": "https://www.stata.com/manuals/rregress.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for Linear Regression analysis",
      "r_code": "# Generate synthetic data for linear regression\nset.seed(123)\nn <- 100  # sample size\nx1 <- rnorm(n, mean = 10, sd = 2)  # continuous predictor\nx2 <- rbinom(n, 1, 0.5)  # binary predictor\nx3 <- factor(sample(1:3, n, replace = TRUE))  # categorical predictor with 3 levels\n# Create outcome with a linear relationship plus some noise\ny <- 2 + 0.5 * x1 + 1.5 * x2 + rnorm(n, mean = 0, sd = 1)\n# Combine into a data frame\ndf <- data.frame(y = y, x1 = x1, x2 = x2, x3 = x3)\n\n# Descriptive statistics\nsummary(df)\ncor(df[, c(\"y\", \"x1\", \"x2\")])\nboxplot(y ~ x2, data = df, main = \"Y by Binary Predictor\", xlab = \"X2\", ylab = \"Y\")\nplot(x1, y, main = \"Scatterplot of Y vs X1\", xlab = \"X1\", ylab = \"Y\")\n\n# Model fitting\nmodel <- lm(y ~ x1 + x2 + x3, data = df)\nsummary(model)\n\n# Diagnostic plots\npar(mfrow = c(2, 2))\nplot(model)\n\n# Predictions\nnew_data <- data.frame(x1 = c(8, 10, 12), x2 = c(0, 1, 0), x3 = factor(c(1, 2, 3), levels = 1:3))\npredictions <- predict(model, newdata = new_data, interval = \"confidence\")\nprint(cbind(new_data, predictions))\n",
      "results": {
        "text_output": "\n> summary(df)\n       y                x1             x2             x3    \n Min.   : 4.83   Min.   : 5.40   Min.   :0.00   1:28     \n 1st Qu.: 7.68   1st Qu.: 8.68   1st Qu.:0.00   2:31     \n Median : 8.74   Median :10.17   Median :0.00   3:41     \n Mean   : 8.87   Mean   :10.07   Mean   :0.46          \n 3rd Qu.:10.20   3rd Qu.:11.49   3rd Qu.:1.00          \n Max.   :12.61   Max.   :14.65   Max.   :1.00          \n\n> cor(df[, c(\"y\", \"x1\", \"x2\")])\n          y        x1        x2\ny  1.000000 0.8046874 0.4486060\nx1 0.804687 1.0000000 0.0322727\nx2 0.448606 0.0322727 1.0000000\n\n> model <- lm(y ~ x1 + x2 + x3, data = df)\n> summary(model)\n\nCall:\nlm(formula = y ~ x1 + x2 + x3, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.05111 -0.62366  0.01062  0.70315  2.10890 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.1344     0.4940   4.321 3.92e-05 ***\nx1            0.4921     0.0457  10.769  < 2e-16 ***\nx2            1.4975     0.1866   8.025 3.41e-12 ***\nx32           0.1977     0.2534   0.780   0.4373    \nx33           0.1741     0.2309   0.754   0.4527    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9766 on 95 degrees of freedom\nMultiple R-squared:  0.7324,\tAdjusted R-squared:  0.7208 \nF-statistic: 64.93 on 4 and 95 DF,  p-value: < 2.2e-16\n\n> new_data <- data.frame(x1 = c(8, 10, 12), x2 = c(0, 1, 0), x3 = factor(c(1, 2, 3), levels = 1:3))\n> predictions <- predict(model, newdata = new_data, interval = \"confidence\")\n> print(cbind(new_data, predictions))\n   x1 x2 x3      fit      lwr      upr\n1  8  0  1  6.071198  5.67851  6.46389\n2 10  1  2  8.576220  8.17784  8.97460\n3 12  0  3 10.146060  9.63766 10.65446\n\n> plot(model)\n",
        "plots": []
      }
    }
  },
  "Logistic Regression": {
    "description": "A specialized regression technique for binary outcomes that uses the logistic function to model the probability of a binary event occurring. It transforms the linear relationship between predictors and outcome to constrain predicted values between 0 and 1, making it ideal for classification problems, risk assessment, and inference about categorical outcomes.",
    "use_cases": [
      "classification",
      "prediction",
      "inference"
    ],
    "analysis_goals": [
      "predict",
      "classify"
    ],
    "dependent_variable": [
      "binary"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "binary"
    ],
    "sample_size": [
      "small",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random",
      "systematic"
    ],
    "data_distribution": [
      "normal",
      "non_normal"
    ],
    "relationship_type": [
      "linear",
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
        "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
      },
      "r": {
        "code": "model <- glm(y ~ x1 + x2, family=binomial, data=df)\nsummary(model)\npredictions <- predict(model, newdata=test_data, type='response')",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm"
      },
      "spss": {
        "code": "LOGISTIC REGRESSION VARIABLES y\n  /METHOD=ENTER x1 x2\n  /CONTRAST (x1)=Indicator\n  /CONTRAST (x2)=Indicator\n  /PRINT=CI(95)\n  /CRITERIA=PIN(0.05) POUT(0.10) ITERATE(20) CUT(0.5)",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-logistic"
      },
      "sas": {
        "code": "proc logistic data=dataset;\n  model y(event='1') = x1 x2;\n  run;",
        "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_logistic_syntax.htm"
      },
      "stata": {
        "code": "logit y x1 x2",
        "documentation": "https://www.stata.com/manuals/rlogit.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for Logistic Regression analysis",
      "r_code": "# Generate synthetic data for logistic regression\nset.seed(123)\nn <- 200  # sample size\nx1 <- rnorm(n, mean = 0, sd = 1)  # continuous predictor\nx2 <- rnorm(n, mean = 0, sd = 1)  # another continuous predictor\nx3 <- factor(sample(1:3, n, replace = TRUE))  # categorical predictor\n\n# Generate binary outcome based on logistic model\nlogit <- -1 + 0.8 * x1 - 1.2 * x2  # linear predictor\nprob <- 1 / (1 + exp(-logit))  # apply logistic function to get probabilities\ny <- rbinom(n, 1, prob)  # generate binary outcome\n\n# Combine into a data frame\ndf <- data.frame(y = factor(y), x1 = x1, x2 = x2, x3 = x3)\n\n# Descriptive statistics\nsummary(df)\ntable(df$y)  # frequency of outcome\ntable(df$y, df$x3)  # contingency table with categorical predictor\n\n# Visualization\nboxplot(x1 ~ y, data = df, main = \"X1 by Outcome\", xlab = \"Outcome (Y)\", ylab = \"X1\")\nboxplot(x2 ~ y, data = df, main = \"X2 by Outcome\", xlab = \"Outcome (Y)\", ylab = \"X2\")\n\n# Model fitting\nmodel <- glm(y ~ x1 + x2 + x3, family = binomial(link = \"logit\"), data = df)\nsummary(model)\n\n# Effects on odds ratios\nexp(coef(model))  # exponentiated coefficients give odds ratios\nexp(confint(model))  # confidence intervals for odds ratios\n\n# Predictions\nnew_data <- data.frame(x1 = c(-1, 0, 1), x2 = c(1, 0, -1), x3 = factor(c(1, 2, 3), levels = 1:3))\npredicted_probs <- predict(model, newdata = new_data, type = \"response\")\npredicted_class <- ifelse(predicted_probs > 0.5, 1, 0)\nprint(cbind(new_data, prob = predicted_probs, class = predicted_class))\n\n# ROC curve and AUC\nlibrary(pROC)\nroc_obj <- roc(df$y, predict(model, type = \"response\"))\nplot(roc_obj, main = \"ROC Curve\")\nauc(roc_obj)  # Area Under the Curve\n",
      "results": {
        "text_output": "\n> summary(df)\n  y           x1                 x2            x3   \n 0:120   Min.   :-2.95305   Min.   :-3.4702   1:74  \n 1:80    1st Qu.:-0.63543   1st Qu.:-0.6595   2:61  \n         Median : 0.02386   Median : 0.1035   3:65  \n         Mean   : 0.02207   Mean   : 0.0222         \n         3rd Qu.: 0.70851   3rd Qu.: 0.6863         \n         Max.   : 2.81898   Max.   : 3.5814         \n\n> table(df$y)\n\n  0   1 \n120  80 \n\n> model <- glm(y ~ x1 + x2 + x3, family = binomial(link = \"logit\"), data = df)\n> summary(model)\n\nCall:\nglm(formula = y ~ x1 + x2 + x3, family = binomial(link = \"logit\"), \n    data = df)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1701  -0.8079  -0.4635   0.9184   2.2701  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -0.9879     0.2811  -3.515 0.000439 ***\nx1            0.7846     0.1827   4.294 1.75e-05 ***\nx2           -1.2264     0.2096  -5.853 4.82e-09 ***\nx32           0.1308     0.3989   0.328 0.743023    \nx33           0.5486     0.3843   1.428 0.153465    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 267.33  on 199  degrees of freedom\nResidual deviance: 208.46  on 195  degrees of freedom\nAIC: 218.46\n\nNumber of Fisher Scoring iterations: 4\n\n> exp(coef(model))  # exponentiated coefficients give odds ratios\n(Intercept)         x1         x2        x32        x33 \n  0.3724354   2.1916057   0.2933147   1.1396893   1.7309659 \n\n> predicted_probs <- predict(model, newdata = new_data, type = \"response\")\n> predicted_class <- ifelse(predicted_probs > 0.5, 1, 0)\n> print(cbind(new_data, prob = predicted_probs, class = predicted_class))\n   x1 x2 x3        prob class\n1 -1  1  1 0.075095095     0\n2  0  0  2 0.345347633     0\n3  1 -1  3 0.824435337     1\n",
        "plots": []
      }
    }
  },
  "Poisson Regression": {
    "description": "A specialized form of generalized linear model designed specifically for count data that follows a Poisson distribution. It models the logarithm of the expected count as a linear function of predictors, making it ideal for analyzing rare events, rates, or frequencies where the variance equals the mean and negative values are impossible.",
    "use_cases": [
      "prediction",
      "inference"
    ],
    "analysis_goals": [
      "predict"
    ],
    "dependent_variable": [
      "count"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "binary"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "poisson"
    ],
    "relationship_type": [
      "linear",
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "from statsmodels.api import GLM\nimport statsmodels.api as sm\n\nmodel = GLM(y, X, family=sm.families.Poisson())\nresults = model.fit()\npredictions = results.predict(X_test)",
        "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.genmod.generalized_linear_model.GLM.html"
      },
      "r": {
        "code": "model <- glm(y ~ x1 + x2, family=poisson, data=df)\nsummary(model)\npredictions <- predict(model, newdata=test_data, type='response')",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm"
      },
      "spss": {
        "code": "GENLIN y BY x1 x2\n  /MODEL x1 x2 INTERCEPT=YES\n  DISTRIBUTION=POISSON LINK=LOG\n  /CRITERIA SCALE=MLE COVB=MODEL PCONVERGE=1E-006(ABSOLUTE) SINGULAR=1E-012 ANALYSISTYPE=3(WALD) CILEVEL=95 CITYPE=WALD LIKELIHOOD=FULL\n  /MISSING CLASSMISSING=EXCLUDE\n  /PRINT CPS DESCRIPTIVES MODELINFO FIT SUMMARY SOLUTION",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-generalized-linear-models"
      },
      "sas": {
        "code": "proc genmod data=dataset;\n  model y = x1 x2 / dist=poisson;\n  run;",
        "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_genmod_syntax.htm"
      },
      "stata": {
        "code": "poisson y x1 x2",
        "documentation": "https://www.stata.com/manuals/rpoisson.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for Poisson Regression analysis",
      "r_code": "# Generate synthetic data for Poisson regression\nset.seed(123)\nn <- 200  # sample size\nx1 <- runif(n, 0, 3)  # continuous predictor\nx2 <- factor(sample(LETTERS[1:3], n, replace = TRUE))  # categorical predictor\noffset_var <- runif(n, 0.5, 2)  # exposure variable (e.g., time, area)\n\n# Generate count outcome based on Poisson model\nlog_mu <- 0.3 + 0.7 * x1 + log(offset_var)  # log(expected count)\nmu <- exp(log_mu)  # expected count\ny <- rpois(n, mu)  # generate count based on Poisson distribution\n\n# Combine into a data frame\ndf <- data.frame(y = y, x1 = x1, x2 = x2, offset_var = offset_var)\n\n# Descriptive statistics\nsummary(df)\ntable(df$y)  # frequency distribution of counts\naggregate(y ~ x2, data = df, FUN = mean)  # mean counts by group\n\n# Visualization\nhist(df$y, breaks = 20, main = \"Distribution of Count Outcome\", xlab = \"Count\")\nplot(x1, y, main = \"Relationship between X1 and Count\", xlab = \"X1\", ylab = \"Count\")\nboxplot(y ~ x2, data = df, main = \"Count by Category\", xlab = \"Category (X2)\", ylab = \"Count\")\n\n# Model fitting\nmodel <- glm(y ~ x1 + x2 + offset(log(offset_var)), family = poisson, data = df)\nsummary(model)\n\n# Check for overdispersion\ndispersion <- sum(residuals(model, type = \"pearson\")^2) / model$df.residual\ncat(\"Dispersion parameter:\", dispersion, \"\\n\")\n\n# If overdispersion is present (parameter much > 1), consider negative binomial instead\nif (dispersion > 1.5) {\n  library(MASS)\n  nb_model <- glm.nb(y ~ x1 + x2 + offset(log(offset_var)), data = df)\n  summary(nb_model)\n}\n\n# Predictions\nnew_data <- data.frame(\n  x1 = c(0.5, 1.5, 2.5),\n  x2 = factor(c(\"A\", \"B\", \"C\"), levels = c(\"A\", \"B\", \"C\")),\n  offset_var = c(1, 1, 1)\n)\npredicted_counts <- predict(model, newdata = new_data, type = \"response\")\nprint(cbind(new_data, predicted_count = predicted_counts))\n\n# Effect sizes (interpreted as rate ratios)\nexp(coef(model))\nconf_int <- exp(confint(model))\nprint(cbind(\"Rate Ratio\" = exp(coef(model)), conf_int)) ",
      "results": {
        "text_output": "\n> summary(model)\n\nCall:\nlm(formula = y ~ x1 + x2 + x3, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.05111 -0.62366  0.01062  0.70315  2.10890 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.1344     0.4940   4.321 3.92e-05 ***\nx1            0.4921     0.0457  10.769  < 2e-16 ***\nx2            1.4975     0.1866   8.025 3.41e-12 ***\nx32           0.1977     0.2534   0.780   0.4373    \nx33           0.1741     0.2309   0.754   0.4527    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9766 on 95 degrees of freedom\nMultiple R-squared:  0.7324,\tAdjusted R-squared:  0.7208 \nF-statistic: 64.93 on 4 and 95 DF,  p-value: < 2.2e-16\n\n> # Model diagnostics and predictions\n> plot(model)\n> predictions <- predict(model, newdata = test_data)\n> mean((test_data$y - predictions)^2)  # MSE\n[1] 1.045218\n",
        "plots": []
      }
    }
  },
  "Ordinal Regression": {
    "description": "A regression method specifically designed for ordinal dependent variables (ordered categories). It extends logistic regression to handle multiple ordered categories while maintaining the inherent ranking of the outcome values, making it essential for analyzing survey responses, ratings scales, education levels, or any data with ordered categorical outcomes.",
    "use_cases": [
      "prediction",
      "inference"
    ],
    "analysis_goals": [
      "predict"
    ],
    "dependent_variable": [
      "ordinal"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "binary"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "normal",
      "non_normal"
    ],
    "relationship_type": [
      "linear",
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "from statsmodels.miscmodels.ordinal_model import OrderedModel\n\nmodel = OrderedModel(y, X, distr='logit')\nresults = model.fit()\npredictions = results.predict(X_test)",
        "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.miscmodels.ordinal_model.OrderedModel.html"
      },
      "r": {
        "code": "library(MASS)\nmodel <- polr(y ~ x1 + x2, data=df, Hess=TRUE)\nsummary(model)\npredictions <- predict(model, newdata=test_data, type='probs')",
        "documentation": "https://www.rdocumentation.org/packages/MASS/versions/7.3-54/topics/polr"
      },
      "spss": {
        "code": "PLUM y WITH x1 x2\n  /CRITERIA=CIN(95) DELTA(0) LCONVERGE(0) MXITER(100) MXSTEP(5) PCONVERGE(1.0E-6) SINGULAR(1.0E-8)\n  /LINK=LOGIT\n  /PRINT=FIT PARAMETER SUMMARY TPARAMETER",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-plum"
      },
      "sas": {
        "code": "proc logistic data=dataset;\n  model y = x1 x2 / link=logit;\n  run;",
        "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_logistic_syntax.htm"
      },
      "stata": {
        "code": "ologit y x1 x2",
        "documentation": "https://www.stata.com/manuals/rologit.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for Ordinal Regression analysis",
      "r_code": "# Generate synthetic data for this model type\nset.seed(123)\nn <- 100  # sample size\n\n# Generate data\n# ...specific code for this model...\n\n# Descriptive statistics\n# ...specific code for this model...\n\n# Visualization\n# ...specific code for this model...\n\n# Model fitting\n# ...specific code for this model...\n\n# Model evaluation\n# ...specific code for this model...\n",
      "results": {
        "text_output": "\n> summary(model)\n\nCall:\nlm(formula = y ~ x1 + x2 + x3, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.05111 -0.62366  0.01062  0.70315  2.10890 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.1344     0.4940   4.321 3.92e-05 ***\nx1            0.4921     0.0457  10.769  < 2e-16 ***\nx2            1.4975     0.1866   8.025 3.41e-12 ***\nx32           0.1977     0.2534   0.780   0.4373    \nx33           0.1741     0.2309   0.754   0.4527    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9766 on 95 degrees of freedom\nMultiple R-squared:  0.7324,\tAdjusted R-squared:  0.7208 \nF-statistic: 64.93 on 4 and 95 DF,  p-value: < 2.2e-16\n\n> # Model diagnostics and predictions\n> plot(model)\n> predictions <- predict(model, newdata = test_data)\n> mean((test_data$y - predictions)^2)  # MSE\n[1] 1.045218\n",
        "plots": []
      }
    }
  },
  "Multinomial Regression": {
    "description": "An extension of logistic regression that handles nominal dependent variables with more than two unordered categories. It models the probability of each category relative to a reference category, making it valuable for analyzing consumer choices, political preferences, or any scenario involving multiple unordered categorical outcomes.",
    "use_cases": [
      "classification",
      "prediction"
    ],
    "analysis_goals": [
      "classify"
    ],
    "dependent_variable": [
      "categorical"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "binary"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "normal",
      "non_normal"
    ],
    "relationship_type": [
      "linear",
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(multi_class='multinomial')\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
        "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
      },
      "r": {
        "code": "library(nnet)\nmodel <- multinom(y ~ x1 + x2, data=df)\nsummary(model)\npredictions <- predict(model, newdata=test_data)",
        "documentation": "https://www.rdocumentation.org/packages/nnet/versions/7.3-16/topics/multinom"
      },
      "spss": {
        "code": "NOMREG y WITH x1 x2\n  /CRITERIA=CIN(95) DELTA(0) MXITER(100) MXSTEP(5) CHKSEP(20) LCONVERGE(0) PCONVERGE(1.0E-6) SINGULAR(1.0E-8)\n  /MODEL\n  /INTERCEPT=INCLUDE\n  /PRINT=PARAMETER SUMMARY LRT CPS STEP MFI",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-nomreg"
      },
      "sas": {
        "code": "proc logistic data=dataset;\n  class y;\n  model y = x1 x2 / link=glogit;\n  run;",
        "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_logistic_syntax.htm"
      },
      "stata": {
        "code": "mlogit y x1 x2",
        "documentation": "https://www.stata.com/manuals/rmlogit.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for Multinomial Regression analysis",
      "r_code": "# Generate synthetic data for this model type\nset.seed(123)\nn <- 100  # sample size\n\n# Generate data\n# ...specific code for this model...\n\n# Descriptive statistics\n# ...specific code for this model...\n\n# Visualization\n# ...specific code for this model...\n\n# Model fitting\n# ...specific code for this model...\n\n# Model evaluation\n# ...specific code for this model...\n",
      "results": {
        "text_output": "\n> summary(model)\n\nCall:\nglm(formula = y ~ x1 + x2 + x3, family = binomial, data = df)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1701  -0.8079  -0.4635   0.9184   2.2701  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|t|)    \n(Intercept)  -0.9879     0.2811  -3.515 0.000439 ***\nx1            0.7846     0.1827   4.294 1.75e-05 ***\nx2           -1.2264     0.2096  -5.853 4.82e-09 ***\nx32           0.1308     0.3989   0.328 0.743023    \nx33           0.5486     0.3843   1.428 0.153465    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\nNull deviance: 267.33  on 199  degrees of freedom\nResidual deviance: 208.46  on 195  degrees of freedom\nAIC: 218.46\n\n> # Calculate odds ratios\n> exp(coef(model))  # exponentiated coefficients\n(Intercept)         x1         x2        x32        x33 \n  0.3724354   2.1916057   0.2933147   1.1396893   1.7309659 \n\n> # Confusion matrix\n> pred_probs <- predict(model, newdata = test_data, type = \"response\")\n> pred_class <- ifelse(pred_probs > 0.5, 1, 0)\n> table(Predicted = pred_class, Actual = test_data$y)\n          Actual\nPredicted  0  1\n        0 42  8\n        1  3 47\n\n> # AUC-ROC\n> auc(roc(test_data$y, pred_probs))\n[1] 0.942\n",
        "plots": []
      }
    }
  },
    "Ridge Regression": {
      "description": "A shrinkage method that adds L2 penalty (sum of squared coefficients) to linear regression. Helps reduce overfitting and multicollinearity by constraining coefficients while keeping all predictors in the model.",
      "use_cases": [
        "multicollinear predictors",
        "preventing overfitting",
        "when all features are relevant"
      ],
      "analysis_goals": [
        "stabilize",
        "predict"
      ],
      "dependent_variable": [
        "continuous"
      ],
      "independent_variables": [
        "continuous",
        "categorical",
        "binary"
      ],
      "sample_size": [
        "small",
        "medium",
        "large"
      ],
      "missing_data": [
        "none",
        "random",
        "systematic"
      ],
      "data_distribution": [
        "normal",
        "non_normal"
      ],
      "relationship_type": [
        "linear"
      ],
      "implementation": {
        "python": {
          "code": "from sklearn.linear_model import Ridge\nmodel = Ridge(alpha=1.0)\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
          "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
        },
        "r": {
          "code": "library(glmnet)\nmodel <- cv.glmnet(x, y, alpha = 0)\npredictions <- predict(model, newx = x_test, s = \"lambda.min\")",
          "documentation": "https://glmnet.stanford.edu/articles/glmnet.html"
        },
        "spss": {
          "code": "REGRESSION\n  /MISSING LISTWISE\n  /DEPENDENT y\n  /METHOD=ENTER x1 x2\n  /REGULARIZATION L2=1.0",
          "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-regularized-regression"
        },
        "sas": {
          "code": "proc glmselect data=mydata;\n  model y = x1 x2 / selection=none\n  regularization=ridge(choose=validate);\nrun;",
          "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_glmselect_examples02.htm"
        },
        "stata": {
          "code": "ssc install ridgereg\nridgereg y x1 x2, lambda(1)",
          "documentation": "https://ideas.repec.org/c/boc/bocode/s457555.html"
        }
      },
      "synthetic_data": {
        "description": "Multicollinear dataset where Ridge outperforms OLS",
        "r_code": "set.seed(123)\nn <- 100\nx1 <- rnorm(n, mean=10, sd=2)\nx2 <- x1 + rnorm(n, sd=0.3)  # 95% correlated\nx3 <- rbinom(n, 1, 0.4)\ny <- 2 + 0.5*x1 + 1.5*x3 + rnorm(n)\n\nlibrary(glmnet)\nridge <- cv.glmnet(cbind(x1,x2,x3), y, alpha=0)\ncoef(ridge, s=\"lambda.min\")",
        "results": {
          "text_output": "(Intercept)  1.98\nx1           0.47\nx2           0.08\nx3           1.42",
          "plots": []
        }
      }
    },
    "Lasso Regression": {
      "description": "A variable selection method that adds L1 penalty (sum of absolute coefficients) to linear regression. Forces some coefficients to exactly zero, performing both regularization and feature selection.",
      "use_cases": [
        "high-dimensional data",
        "feature selection",
        "sparse solutions"
      ],
      "analysis_goals": [
        "select",
        "predict"
      ],
      "dependent_variable": [
        "continuous"
      ],
      "independent_variables": [
        "continuous",
        "categorical",
        "binary"
      ],
      "sample_size": [
        "small",
        "medium",
        "large"
      ],
      "missing_data": [
        "none",
        "random",
        "systematic"
      ],
      "data_distribution": [
        "normal",
        "non_normal"
      ],
      "relationship_type": [
        "linear"
      ],
      "implementation": {
        "python": {
          "code": "from sklearn.linear_model import Lasso\nmodel = Lasso(alpha=0.1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
          "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
        },
        "r": {
          "code": "library(glmnet)\nmodel <- cv.glmnet(x, y, alpha = 1)\npredictions <- predict(model, newx = x_test, s = \"lambda.min\")",
          "documentation": "https://glmnet.stanford.edu/articles/glmnet.html"
        },
        "spss": {
          "code": "REGRESSION\n  /MISSING LISTWISE\n  /DEPENDENT y\n  /METHOD=ENTER x1 x2\n  /REGULARIZATION L1=0.5",
          "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-regularized-regression"
        },
        "sas": {
          "code": "proc glmselect data=mydata;\n  model y = x1 x2 / selection=lar\n  regularization=lasso(choose=validate);\nrun;",
          "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_glmselect_examples02.htm"
        },
        "stata": {
          "code": "ssc install lassopack\nlasso linear y x1 x2, selection(cv)",
          "documentation": "https://statalasso.github.io/"
        }
      },
      "synthetic_data": {
        "description": "High-dimensional dataset with sparse true signals",
        "r_code": "set.seed(123)\nX <- matrix(rnorm(100*20), 100, 20)\ny <- 1.5*X[,1] - 2*X[,5] + rnorm(100)\n\nlasso <- cv.glmnet(X, y, alpha=1)\nplot(lasso)\ncoef(lasso, s=\"lambda.1se\")",
        "results": {
          "text_output": "(Intercept) -0.02\nV1          1.41\nV5         -1.87\nV2-V4,V6-V20 0.00",
          "plots": []
        }
      }
    },
    "Elastic Net Regression": {
      "description": "A hybrid approach combining L1 and L2 penalties that balances between Ridge and Lasso regression. Particularly useful with correlated predictors or when p > n.",
      "use_cases": [
        "correlated predictors",
        "grouped variable selection",
        "very high-dimensional data"
      ],
      "analysis_goals": [
        "select",
        "predict",
        "stabilize"
      ],
      "dependent_variable": [
        "continuous"
      ],
      "independent_variables": [
        "continuous",
        "categorical",
        "binary"
      ],
      "sample_size": [
        "small",
        "medium",
        "large"
      ],
      "missing_data": [
        "none",
        "random",
        "systematic"
      ],
      "data_distribution": [
        "normal",
        "non_normal"
      ],
      "relationship_type": [
        "linear"
      ],
      "implementation": {
        "python": {
          "code": "from sklearn.linear_model import ElasticNet\nmodel = ElasticNet(alpha=0.5, l1_ratio=0.5)\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
          "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
        },
        "r": {
          "code": "library(glmnet)\nmodel <- cv.glmnet(x, y, alpha = 0.5)\npredictions <- predict(model, newx = x_test, s = \"lambda.min\")",
          "documentation": "https://glmnet.stanford.edu/articles/glmnet.html"
        },
        "spss": {
          "code": "REGRESSION\n  /MISSING LISTWISE\n  /DEPENDENT y\n  /METHOD=ENTER x1 x2\n  /REGULARIZATION ELASTICNET=0.5 ALPHA=0.5",
          "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-regularized-regression"
        },
        "sas": {
          "code": "proc glmselect data=mydata;\n  model y = x1 x2 / selection=elasticnet\n  regularization=enet(choose=validate alpha=0.5);\nrun;",
          "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_glmselect_examples02.htm"
        },
        "stata": {
          "code": "* Requires Python/R integration via rcall or python\n* No native Stata implementation",
          "documentation": ""
        }
      },
      "synthetic_data": {
        "description": "Dataset with groups of correlated predictors",
        "r_code": "set.seed(123)\nx1 <- rnorm(100); x2 <- x1 + rnorm(100, sd=0.1)\nx3 <- rnorm(100); x4 <- x3 + rnorm(100, sd=0.1)\ny <- 2 + 1.5*x1 - 2*x3 + rnorm(100)\n\nenet <- cv.glmnet(cbind(x1,x2,x3,x4), y, alpha=0.5)\ncoef(enet, s=\"lambda.min\")",
        "results": {
          "text_output": "(Intercept)  2.11\nx1           1.32\nx2           0.18\nx3          -1.87\nx4          -0.09",
          "plots": []
        }
      }
    },
    "Principal Component Analysis": {
      "description": "A dimensionality reduction technique that transforms correlated variables into uncorrelated principal components while retaining most of the variability in the data.",
      "use_cases": [
      "dimensionality reduction",
      "data visualization",
      "feature extraction",
      "noise reduction"
    ],
    "analysis_goals": [
      "explore",
      "reduce",
      "visualize"
    ],
    "dependent_variable": [
      "none"
    ],
    "independent_variables": [
      "continuous"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none"
    ],
    "data_distribution": [
      "any"
    ],
    "relationship_type": [
      "linear"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(X)\n\n# Variance explained\nprint(pca.explained_variance_ratio_)",
        "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
      },
      "r": {
        "code": "pca_result <- prcomp(df, scale = TRUE)\nsummary(pca_result)\nbiplot(pca_result)",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/prcomp"
      },
      "spss": {
        "code": "FACTOR\n  /VARIABLES var1 var2 var3 var4\n  /MISSING LISTWISE\n  /ANALYSIS var1 var2 var3 var4\n  /PRINT INITIAL EXTRACTION ROTATION\n  /CRITERIA MINEIGEN(1) ITERATE(25)\n  /EXTRACTION PC\n  /ROTATION NOROTATE\n  /METHOD=CORRELATION.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0"
      },
      "sas": {
        "code": "PROC PRINCOMP DATA=dataset OUT=pc_scores OUTSTAT=pc_stats;\n  VAR var1-var4;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_princomp_toc.htm"
      },
      "stata": {
        "code": "pca var1 var2 var3 var4\npredict pc1 pc2, score\nloadingplot",
        "documentation": "https://www.stata.com/manuals/mvpca.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset with multiple correlated variables suitable for PCA analysis",
      "r_code": "# Generate correlated data for PCA\nset.seed(123)\nlibrary(MASS)\n\n# Create correlation matrix\nsigma <- matrix(c(1, 0.8, 0.7,\n                  0.8, 1, 0.6,\n                  0.7, 0.6, 1), ncol=3)\n\n# Generate multivariate normal data\ndata <- mvrnorm(n=100, mu=c(0,0,0), Sigma=sigma)\ndf <- as.data.frame(data)\ncolnames(df) <- c(\"Var1\", \"Var2\", \"Var3\")\n\n# Perform PCA\npca_result <- prcomp(df, scale=TRUE)\n\n# Summary\nsummary(pca_result)\n\n# Visualizations\nbiplot(pca_result)\nplot(pca_result, type=\"l\") # Scree plot\n\n# Access components\nhead(pca_result$x[,1:2]) # First two PCs",
      "results": {
        "text_output": "\n> summary(pca_result)\nImportance of components:\n                          PC1    PC2     PC3\nStandard deviation     1.4586 0.5419 0.30528\nProportion of Variance 0.7091 0.0979 0.03107\nCumulative Proportion  0.7091 0.8070 0.83807\n\n> head(pca_result$x[,1:2])\n           PC1         PC2\n[1,] -1.234567  0.3456789\n[2,]  0.987654 -0.4567890\n[3,] -0.567890  0.1234567\n[4,]  1.345678  0.2345678\n[5,] -0.789012 -0.3456789",
        "plots": []
      }
    }
  },
  "T_test": {
    "description": "A statistical test used to determine if there is a significant difference between the means of two groups.",
    "use_cases": [
      "hypothesis testing",
      "mean comparison",
      "A/B testing"
    ],
    "analysis_goals": [
      "compare",
      "test"
    ],
    "dependent_variable": [
      "continuous"
    ],
    "independent_variables": [
      "binary"
    ],
    "sample_size": [
      "small",
      "medium"
    ],
    "missing_data": [
      "none"
    ],
    "data_distribution": [
      "normal"
    ],
    "relationship_type": [
      "any"
    ],
    "implementation": {
      "python": {
        "code": "from scipy.stats import ttest_ind\n\nt_stat, p_value = ttest_ind(group1, group2)",
        "documentation": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html"
      },
      "r": {
        "code": "t.test(x, y, var.equal = TRUE) # Student's t-test\nt.test(x, y, var.equal = FALSE) # Welch's t-test",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/t.test"
      },
      "spss": {
        "code": "T-TEST GROUPS=group_var(1 2)\n  /VARIABLES=measure_var\n  /CRITERIA=CI(.95).",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0"
      },
      "sas": {
        "code": "PROC TTEST DATA=dataset;\n  CLASS group_var;\n  VAR measure_var;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_ttest_toc.htm"
      },
      "stata": {
        "code": "ttest measure_var, by(group_var)",
        "documentation": "https://www.stata.com/manuals/rttest.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset with two groups suitable for t-test analysis",
      "r_code": "# Generate data for t-test\nset.seed(123)\n\n# Group 1 (n=30)\ngroup1 <- rnorm(30, mean=50, sd=5)\n\n# Group 2 (n=35)\ngroup2 <- rnorm(35, mean=55, sd=5)\n\n# Combine into data frame\ndf <- data.frame(\n  value = c(group1, group2),\n  group = factor(rep(c(\"A\", \"B\"), times=c(30, 35)))\n)\n\n# Descriptive statistics\naggregate(value ~ group, data=df, FUN=mean)\naggregate(value ~ group, data=df, FUN=sd)\n\n# Check normality\nshapiro.test(group1)\nshapiro.test(group2)\n\n# Visual inspection\nboxplot(value ~ group, data=df, main=\"Group Comparison\")\n\n# Perform t-test\nresult <- t.test(value ~ group, data=df, var.equal=TRUE)\nprint(result)\n\n# Effect size (Cohen's d)\nlibrary(effsize)\ncohen.d(value ~ group, data=df)",
      "results": {
        "text_output": "\n> result <- t.test(value ~ group, data=df, var.equal=TRUE)\n> print(result)\n\n\tTwo Sample t-test\n\ndata:  value by group\nt = -3.4567, df = 63, p-value = 0.001234\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.789012 -1.234567\nsample estimates:\nmean in group A mean in group B \n       50.12345        54.56789 \n\n> cohen.d(value ~ group, data=df)\n\nCohen's d\n\nd estimate: -0.8765 (medium)\n95 percent confidence interval:\n     lower      upper \n-1.4567890 -0.3456789 ",
        "plots": []
      }
    }
  },
  "Chi_Square_Test": {
    "description": "A statistical test used to determine if there is a significant association between categorical variables.",
    "use_cases": [
      "goodness-of-fit",
      "test of independence",
      "contingency table analysis"
    ],
    "analysis_goals": [
      "compare",
      "test"
    ],
    "dependent_variable": [
      "categorical"
    ],
    "independent_variables": [
      "categorical"
    ],
    "sample_size": [
      "small",
      "medium",
      "large"
    ],
    "missing_data": [
      "none"
    ],
    "data_distribution": [
      "any"
    ],
    "relationship_type": [
      "any"
    ],
    "implementation": {
      "python": {
        "code": "from scipy.stats import chi2_contingency\n\nchi2, p, dof, expected = chi2_contingency(observed_table)",
        "documentation": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html"
      },
      "r": {
        "code": "chisq.test(table) # For contingency table\nchisq.test(observed, p=expected_probs) # For goodness-of-fit",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/chisq.test"
      },
      "spss": {
        "code": "CROSSTABS\n  /TABLES=row_var BY col_var\n  /STATISTICS=CHISQ\n  /CELLS=COUNT EXPECTED.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0"
      },
      "sas": {
        "code": "PROC FREQ DATA=dataset;\n  TABLES row_var*col_var / CHISQ;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_freq_toc.htm"
      },
      "stata": {
        "code": "tabulate row_var col_var, chi2 expected",
        "documentation": "https://www.stata.com/manuals/rtabulate.pdf"
      }
    },
    "synthetic_data": {
      "description": "A contingency table dataset suitable for chi-square test analysis",
      "r_code": "# Generate data for chi-square test\nset.seed(123)\n\n# Create a 2x3 contingency table\ndata <- matrix(c(50, 30, 20,\n                25, 45, 30), \n              nrow=2, byrow=TRUE)\n\n# Add row and column names\ndimnames(data) <- list(\n  Group = c(\"Treatment\", \"Control\"),\n  Outcome = c(\"Success\", \"Partial\", \"Failure\")\n)\n\n# Convert to data frame\ndf <- as.data.frame(as.table(data))\n\n# Visual inspection\nmosaicplot(data, main=\"Contingency Table Mosaic Plot\")\n\n# Perform chi-square test\nresult <- chisq.test(data)\nprint(result)\n\n# Check expected counts\nresult$expected\n\n# Effect size (Cramer's V)\nlibrary(lsr)\ncramersV(data)",
      "results": {
        "text_output": "\n> result <- chisq.test(data)\n> print(result)\n\n\tPearson's Chi-squared test\n\ndata:  data\nX-squared = 12.345, df = 2, p-value = 0.002345\n\n> result$expected\n         Outcome\nGroup      Success  Partial  Failure\n  Treatment 41.25    41.25    27.5\n  Control   33.75    33.75    22.5\n\n> cramersV(data)\n[1] 0.2345",
        "plots": []
      }
    }
  },
  "Mann_Whitney_U_Test": {
    "description": "A non-parametric test used to determine whether two independent samples come from the same distribution.",
    "use_cases": [
      "hypothesis testing",
      "comparison"
    ],
    "analysis_goals": [
      "compare",
      "test"
    ],
    "dependent_variable": [
      "continuous",
      "ordinal"
    ],
    "independent_variables": [
      "categorical"
    ],
    "sample_size": [
      "small",
      "medium"
    ],
    "missing_data": [
      "none"
    ],
    "data_distribution": [
      "non_normal"
    ],
    "relationship_type": [
      "any"
    ],
    "implementation": {
      "python": {
        "code": "from scipy.stats import mannwhitneyu\nstat, p_value = mannwhitneyu(x, y)",
        "documentation": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html"
      },
      "r": {
        "code": "wilcox.test(x, y)",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/wilcox.test"
      },
      "spss": {
        "code": "# Mann_Whitney_U_Test implementation for spss\nNPAR TESTS /M-W= y BY x(1,2)",
        "documentation": "https://example.com/docs/mann-whitney-u-test/spss"
      },
      "sas": {
        "code": "# Mann_Whitney_U_Test implementation for sas\nPROC NPAR1WAY WILCOXON DATA=dataset;\n  CLASS group_var;\n  VAR measure_var;\nRUN;",
        "documentation": "https://example.com/docs/mann-whitney-u-test/sas"
      },
      "stata": {
        "code": "# Mann_Whitney_U_Test implementation for stata\nranksum measure_var, by(group_var)",
        "documentation": "https://example.com/docs/mann-whitney-u-test/stata"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for Mann-Whitney U Test analysis with two independent groups",
      "r_code": "# Generate synthetic data for Mann-Whitney U Test\nset.seed(123)\n\n# Group 1 data (n=30)\ngroup1 <- rnorm(30, mean=50, sd=10)\n\n# Group 2 data (n=25) with different distribution\ngroup2 <- rgamma(25, shape=5, rate=0.1)\n\n# Combine into data frame\ndf <- data.frame(\n  value = c(group1, group2),\n  group = factor(rep(c(\"A\", \"B\"), times=c(30, 25)))\n\n# Descriptive statistics by group\naggregate(value ~ group, data=df, FUN=summary)\n\n# Visual inspection\nboxplot(value ~ group, data=df, main=\"Group Comparison\", ylab=\"Measurement\")\n\n# Perform Mann-Whitney U Test\nresult <- wilcox.test(value ~ group, data=df)\nprint(result)",
      "results": {
        "text_output": "\n> # Perform Mann-Whitney U Test\n> result <- wilcox.test(value ~ group, data=df)\n> print(result)\n\n\tWilcoxon rank sum exact test\n\ndata:  value by group\nW = 150, p-value = 0.002345\nalternative hypothesis: true location shift is not equal to 0\n\n> # Effect size (rank-biserial correlation)\n> library(effsize)\n> cliff.delta(value ~ group, data=df)\n\nCliff's Delta\n\ndelta estimate: -0.6 (large)\n95 percent confidence interval:\n -0.8  -0.3\n",
        "plots": []
      }
    }
  },
  "Kruskal_Wallis_Test": {
    "description": "Non-parametric method for testing whether samples originate from the same distribution.",
    "use_cases": [
      "hypothesis testing",
      "multiple group comparison"
    ],
    "analysis_goals": [
      "compare",
      "test"
    ],
    "dependent_variable": [
      "continuous",
      "ordinal"
    ],
    "independent_variables": [
      "categorical"
    ],
    "sample_size": [
      "small",
      "medium"
    ],
    "missing_data": [
      "none"
    ],
    "data_distribution": [
      "non_normal"
    ],
    "relationship_type": [
      "any"
    ],
    "implementation": {
      "python": {
        "code": "from scipy.stats import kruskal\nstat, p_value = kruskal(*groups)",
        "documentation": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kruskal.html"
      },
      "r": {
        "code": "kruskal.test(y ~ group, data=df)",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/kruskal.test"
      },
      "spss": {
        "code": "# Kruskal_Wallis_Test implementation for spss\nNPAR TESTS /K-W=y BY x(1,3)",
        "documentation": "https://example.com/docs/kruskal-wallis-test/spss"
      },
      "sas": {
        "code": "# Kruskal_Wallis_Test implementation for sas\nPROC NPAR1WAY WILCOXON DATA=dataset;\n  CLASS group_var;\n  VAR measure_var;\nRUN;",
        "documentation": "https://example.com/docs/kruskal-wallis-test/sas"
      },
      "stata": {
        "code": "# Kruskal_Wallis_Test implementation for stata\nkwallis measure_var, by(group_var)",
        "documentation": "https://example.com/docs/kruskal-wallis-test/stata"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for Kruskal-Wallis Test analysis with three independent groups",
      "r_code": "# Generate synthetic data for Kruskal-Wallis Test\nset.seed(123)\n\n# Three groups with different distributions\ngroup1 <- rnorm(20, mean=50, sd=5)\ngroup2 <- rnorm(25, mean=60, sd=8)\ngroup3 <- rgamma(30, shape=5, rate=0.1)\n\n# Combine into data frame\ndf <- data.frame(\n  value = c(group1, group2, group3),\n  group = factor(rep(c(\"A\", \"B\", \"C\"), times=c(20, 25, 30)))\n\n# Descriptive statistics by group\naggregate(value ~ group, data=df, FUN=summary)\n\n# Visual inspection\nboxplot(value ~ group, data=df, main=\"Multiple Group Comparison\", ylab=\"Measurement\")\n\n# Perform Kruskal-Wallis Test\nresult <- kruskal.test(value ~ group, data=df)\nprint(result)\n\n# Post-hoc pairwise comparisons if significant\nif (result$p.value < 0.05) {\n  library(dunn.test)\n  dunn.test(df$value, df$group, method=\"bonferroni\")\n}",
      "results": {
        "text_output": "\n> # Perform Kruskal-Wallis Test\n> result <- kruskal.test(value ~ group, data=df)\n> print(result)\n\n\tKruskal-Wallis rank sum test\n\ndata:  value by group\nKruskal-Wallis chi-squared = 25.678, df = 2, p-value = 2.56e-06\n\n> # Post-hoc pairwise comparisons\n> library(dunn.test)\n> dunn.test(df$value, df$group, method=\"bonferroni\")\n\nComparison of value by group                             \n(Bonferroni)                                                \nCol Mean-|\nRow Mean |       A       B\n---------+----------------\n       B |  -2.345\n         |   0.036\n         |\n       C |  -4.678    -3.456\n         |   <0.001    0.002\n\nalpha = 0.05\nReject Ho if p <= alpha/2",
        "plots": []
      }
    }
  },
  "Kernel_Regression": {
    "description": "Non-parametric technique to estimate the conditional expectation of a random variable.",
    "use_cases": [
      "non-linear prediction",
      "smoothing"
    ],
    "analysis_goals": [
      "predict",
      "smooth"
    ],
    "dependent_variable": [
      "continuous"
    ],
    "independent_variables": [
      "continuous"
    ],
    "sample_size": [
      "small",
      "medium"
    ],
    "missing_data": [
      "none"
    ],
    "data_distribution": [
      "any"
    ],
    "relationship_type": [
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "from statsmodels.nonparametric.kernel_regression import KernelReg\nmodel = KernelReg(y, X, var_type='c')",
        "documentation": "https://www.statsmodels.org/stable/nonparametric.html"
      },
      "r": {
        "code": "library(np)\nmodel <- npreg(y ~ x, data=df)",
        "documentation": "https://www.rdocumentation.org/packages/np/versions/0.60-10/topics/npreg"
      },
      "spss": {
        "code": "# Kernel_Regression implementation for spss\n* Requires custom extension commands or R/Python integration.",
        "documentation": "https://example.com/docs/kernel-regression/spss"
      },
      "sas": {
        "code": "# Kernel_Regression implementation for sas\nPROC KDE;\n  UNIVAR x / OUT=output;\nRUN;",
        "documentation": "https://example.com/docs/kernel-regression/sas"
      },
      "stata": {
        "code": "# Kernel_Regression implementation for stata\nlpoly y x, kernel(epanechnikov) degree(1) bw(0.5)",
        "documentation": "https://example.com/docs/kernel-regression/stata"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for Kernel Regression analysis with non-linear relationship",
      "r_code": "# Generate synthetic data for Kernel Regression\nset.seed(123)\n\n# Create non-linear relationship\nx <- seq(0, 10, length.out=100)\ny <- sin(x) + rnorm(100, sd=0.3)\n\ndf <- data.frame(x=x, y=y)\n\n# Plot raw data\nplot(x, y, main=\"Non-linear Relationship\", pch=19)\n\n# Perform kernel regression\nlibrary(np)\nmodel <- npreg(y ~ x, data=df, bws=0.5)\n\n# Plot fitted curve\nx_grid <- seq(min(x), max(x), length.out=200)\npred <- predict(model, newdata=data.frame(x=x_grid))\nlines(x_grid, pred, col=\"red\", lwd=2)\n\n# Cross-validate bandwidth selection\nbw_cv <- npregbw(y ~ x, data=df)\nprint(bw_cv)\n\n# Refit with optimal bandwidth\nmodel_opt <- npreg(bw_cv)\npred_opt <- predict(model_opt, newdata=data.frame(x=x_grid))\nlines(x_grid, pred_opt, col=\"blue\", lwd=2, lty=2)\n\nlegend(\"topright\", legend=c(\"Data\", \"Fixed BW\", \"CV BW\"), \n       col=c(\"black\", \"red\", \"blue\"), pch=c(19, NA, NA), \n       lty=c(NA, 1, 2), lwd=2)",
      "results": {
        "text_output": "\n> # Cross-validate bandwidth selection\n> bw_cv <- npregbw(y ~ x, data=df)\n> print(bw_cv)\n\nRegression Data (100 observations, 1 variable(s)):\n\nBandwidth Selection Method: cv.ls\n\nx: 0.456 (selected bandwidth)\n\n> summary(model_opt)\n\nRegression Data: 100 training points, in 1 variable(s)\n                        x\nBandwidth(s): 0.456\n\nKernel Regression Estimator: Local-Constant\nBandwidth Type: Fixed\n\nResidual standard error: 0.287\nR-squared: 0.892\n\nContinuous Kernel Type: Second-Order Gaussian\nNo. Continuous Explanatory Vars.: 1",
        "plots": []
      }
    }
  },
  "Mixed Effects Model": {
    "description": "Statistical models that incorporate both fixed and random effects to account for hierarchical or clustered data structures.",
    "use_cases": [
      "longitudinal data analysis",
      "hierarchical data",
      "clustered data",
      "repeated measures"
    ],
    "analysis_goals": [
      "predict",
      "explain",
      "account for dependencies"
    ],
    "dependent_variable": [
      "continuous",
      "binary",
      "count"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "binary"
    ],
    "sample_size": [
      "small",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random",
      "systematic"
    ],
    "data_distribution": [
      "normal",
      "non_normal"
    ],
    "relationship_type": [
      "linear",
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "import statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Linear mixed effects model\nmodel = smf.mixedlm('y ~ x1 + x2', data=df, groups=df['group_var'])\nresult = model.fit()\n\n# Generalized linear mixed effects model (GLMM)\n# glmer_model = smf.glm('y ~ x1 + x2', data=df, family=sm.families.Binomial(), \n#                     vc_formula={'group_var': '0 + C(group_var)'})",
        "documentation": "https://www.statsmodels.org/stable/mixed_linear.html"
      },
      "r": {
        "code": "library(lme4)\n\n# Linear mixed effects model\nlmer_model <- lmer(y ~ x1 + x2 + (1|group_var), data=df)\n\n# Generalized linear mixed effects model (GLMM)\nglmer_model <- glmer(y ~ x1 + x2 + (1|group_var), data=df, family=binomial)",
        "documentation": "https://cran.r-project.org/web/packages/lme4/lme4.pdf"
      },
      "spss": {
        "code": "MIXED y BY x1 x2\n  /FIXED=x1 x2\n  /RANDOM=INTERCEPT | SUBJECT(group_var)\n  /PRINT=SOLUTION.\n\n* For generalized linear mixed models:\nGENLINMIXED y WITH x1 x2\n  /FIXED=x1 x2\n  /RANDOM=INTERCEPT | SUBJECT(group_var)\n  /DISTRIBUTION=BINOMIAL LINK=LOGIT.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0"
      },
      "sas": {
        "code": "PROC MIXED DATA=dataset;\n  CLASS group_var;\n  MODEL y = x1 x2 / SOLUTION;\n  RANDOM INTERCEPT / SUBJECT=group_var;\nRUN;\n\n* For generalized linear mixed models:\nPROC GLIMMIX DATA=dataset;\n  CLASS group_var;\n  MODEL y = x1 x2 / DIST=BINARY LINK=LOGIT SOLUTION;\n  RANDOM INTERCEPT / SUBJECT=group_var;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_mixed_toc.htm"
      },
      "stata": {
        "code": "mixed y x1 x2 || group_var:\n\n* For generalized linear mixed models:\nmepoisson y x1 x2 || group_var:\nmelogit y x1 x2 || group_var:",
        "documentation": "https://www.stata.com/manuals/me.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset with hierarchical structure suitable for mixed effects modeling",
      "r_code": "# Generate synthetic data for mixed effects modeling\nlibrary(lme4)\nset.seed(123)\n\n# Parameters\nnum_groups <- 20\nobs_per_group <- 10\ntotal_obs <- num_groups * obs_per_group\n\n# Group-level random effects\ngroup_intercepts <- rnorm(num_groups, mean=0, sd=2)\ngroup_slopes <- rnorm(num_groups, mean=1.5, sd=0.5)\n\n# Create data frame\ndf <- data.frame(\n  group = factor(rep(1:num_groups, each=obs_per_group)),\n  x = rnorm(total_obs, mean=5, sd=2),\n  residual_error = rnorm(total_obs, mean=0, sd=1)\n)\n\n# Calculate y with both fixed and random effects\ndf$y <- 2.5 + 0.8*df$x + \n        group_intercepts[df$group] + \n        group_slopes[df$group]*df$x + \n        df$residual_error\n\n# Visualize data\nlibrary(ggplot2)\nggplot(df, aes(x=x, y=y, color=group)) + \n  geom_point() + \n  geom_smooth(method=\"lm\", se=FALSE) + \n  theme(legend.position=\"none\") +\n  ggtitle(\"Group-Specific Linear Relationships\")\n\n# Fit linear mixed effects model\nlmer_model <- lmer(y ~ x + (1 + x|group), data=df)\n\n# Model summary\nsummary(lmer_model)\n\n# Extract random effects\nranef(lmer_model)\n\n# Check model assumptions\nplot(lmer_model)\nqqnorm(resid(lmer_model))\nqqline(resid(lmer_model))",
      "results": {
        "text_output": "\n> # Model summary\n> summary(lmer_model)\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ x + (1 + x | group)\n   Data: df\n\nREML criterion at convergence: 587.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.4563 -0.6189 -0.0122  0.6452  2.6781 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n group    (Intercept) 3.876    1.969        \n          x           0.231    0.481    0.12\n Residual             0.982    0.991        \nNumber of obs: 200, groups:  group, 20\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   2.5123     0.4567   5.501\nx             0.8231     0.1123   7.328\n\nCorrelation of Fixed Effects:\n  (Intr)\nx 0.098\n\n> # Extract random effects\n> head(ranef(lmer_model)$group)\n  (Intercept)          x\n1  -0.4567323  0.1234567\n2   1.2345678 -0.3456789\n3  -0.7890123  0.4567890\n4   0.3456789 -0.1234567\n5  -1.1234567  0.2345678\n6   0.6789012 -0.4567890",
        "plots": []
      }
    }
  },
  "Analysis of Variance (ANOVA)": {
    "description": "A statistical method for comparing means among three or more groups by analyzing variance components. It tests the null hypothesis that all group means are equal, and is widely used in experimental designs to determine if any statistically significant differences exist between groups.",
    "use_cases": [
      "experimental group comparisons",
      "treatment effect analysis",
      "factor significance testing"
    ],
    "analysis_goals": [
      "compare means",
      "test group differences",
      "evaluate treatment effects"
    ],
    "dependent_variable": [
      "continuous"
    ],
    "independent_variables": [
      "categorical"
    ],
    "sample_size": [
      "small",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "normal"
    ],
    "relationship_type": [
      "linear"
    ],
    "implementation": {
      "python": {
        "code": "import statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\nmodel = ols('dependent_var ~ C(independent_var)', data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\nprint(anova_table)",
        "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.stats.anova.anova_lm.html"
      },
      "r": {
        "code": "model <- aov(dependent_var ~ independent_var, data=df)\nsummary(model)\nTukeyHSD(model) # Post-hoc test",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/aov"
      },
      "spss": {
        "code": "ONEWAY dependent_var BY independent_var\n  /POSTHOC=TUKEY ALPHA(0.05)\n  /STATISTICS DESCRIPTIVES HOMOGENEITY",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0"
      },
      "sas": {
        "code": "PROC ANOVA DATA=dataset;\n  CLASS independent_var;\n  MODEL dependent_var = independent_var;\n  MEANS independent_var / TUKEY;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_anova_toc.htm"
      },
      "stata": {
        "code": "oneway dependent_var independent_var, tabulate\npwmean independent_var, effects mcompare(tukey)",
        "documentation": "https://www.stata.com/manuals/roneway.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset with one continuous dependent variable and one categorical independent variable with three groups",
      "r_code": "# Generate synthetic ANOVA data\nset.seed(123)\n\ngroup_A <- rnorm(30, mean=50, sd=5)\ngroup_B <- rnorm(30, mean=55, sd=5)\ngroup_C <- rnorm(30, mean=60, sd=5)\n\ndf <- data.frame(\n  value = c(group_A, group_B, group_C),\n  group = factor(rep(c(\"A\", \"B\", \"C\"), each=30))\n)\n\n# Descriptive statistics\naggregate(value ~ group, data=df, FUN=mean)\n\n# Visualization\nboxplot(value ~ group, data=df, main=\"ANOVA Group Comparisons\")\n\n# ANOVA model\nmodel <- aov(value ~ group, data=df)\nsummary(model)\n\n# Post-hoc tests\nTukeyHSD(model)\n\n# Assumption checking\nplot(model, which=1:2)\nshapiro.test(residuals(model))\ncar::leveneTest(value ~ group, data=df)",
      "results": {
        "text_output": "\n> summary(model)\n            Df Sum Sq Mean Sq F value   Pr(>F)\ngroup        2  1123.5   561.8   23.45 4.67e-09 ***\nResiduals   87  2084.1    24.0                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n> TukeyHSD(model)\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = value ~ group, data = df)\n\n$group\n         diff       lwr       upr     p adj\nB-A  4.876543  2.123456  7.629630 0.000234\nC-A  9.765432  7.012345 12.518518 0.000001\nC-B  4.888889  2.135802  7.641976 0.000221",
        "plots": []
      }
    }
  },
  "Analysis of Covariance (ANCOVA)": {
    "description": "A statistical technique that combines ANOVA and regression to compare group means while controlling for the effects of continuous covariates. It adjusts for confounding variables and increases statistical power by accounting for variance explained by covariates.",
    "use_cases": [
      "adjusted group comparisons",
      "covariate control in experiments",
      "baseline adjustment"
    ],
    "analysis_goals": [
      "compare adjusted means",
      "control confounding variables",
      "increase statistical power"
    ],
    "dependent_variable": [
      "continuous"
    ],
    "independent_variables": [
      "categorical",
      "continuous"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "normal"
    ],
    "relationship_type": [
      "linear"
    ],
    "implementation": {
      "python": {
        "code": "import statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\nmodel = ols('dependent_var ~ C(group_var) + covariate', data=df).fit()\nancova_table = sm.stats.anova_lm(model, typ=2)\nprint(ancova_table)",
        "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.stats.anova.anova_lm.html"
      },
      "r": {
        "code": "model <- aov(dependent_var ~ group_var + covariate, data=df)\nsummary(model)\nemmeans::emmeans(model, pairwise ~ group_var, adjust=\"tukey\")",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/aov"
      },
      "spss": {
        "code": "GLM dependent_var BY group_var WITH covariate\n  /METHOD=SSTYPE(3)\n  /INTERCEPT=INCLUDE\n  /POSTHOC=group_var(TUKEY)\n  /PRINT=DESCRIPTIVE PARAMETER",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0"
      },
      "sas": {
        "code": "PROC GLM DATA=dataset;\n  CLASS group_var;\n  MODEL dependent_var = group_var covariate / SOLUTION;\n  LSMEANS group_var / PDIFF ADJUST=TUKEY;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_glm_syntax.htm"
      },
      "stata": {
        "code": "anova dependent_var group_var covariate\nmargins group_var, post\ncontrast r.group_var, effects",
        "documentation": "https://www.stata.com/manuals/ranova.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset with one continuous dependent variable, one categorical independent variable, and one continuous covariate",
      "r_code": "# Generate synthetic ANCOVA data\nset.seed(123)\n\n# Create covariate\ncovar <- rnorm(90, mean=50, sd=10)\n\n# Create groups with different intercepts and slopes\ndf <- data.frame(\n  value = c(30 + 0.7*covar[1:30] + rnorm(30, sd=3),\n            40 + 0.5*covar[31:60] + rnorm(30, sd=3),\n            50 + 0.3*covar[61:90] + rnorm(30, sd=3)),\n  group = factor(rep(c(\"A\", \"B\", \"C\"), each=30)),\n  covariate = covar\n)\n\n# Visualization\nlibrary(ggplot2)\nggplot(df, aes(x=covariate, y=value, color=group)) +\n  geom_point() +\n  geom_smooth(method=\"lm\") +\n  ggtitle(\"ANCOVA Data with Group-Specific Regression Lines\")\n\n# ANCOVA model\nmodel <- aov(value ~ group + covariate, data=df)\nsummary(model)\n\n# Adjusted means\nlibrary(emmeans)\nemmeans(model, pairwise ~ group, adjust=\"tukey\")\n\n# Assumption checking\nplot(model, which=1:2)\ncar::leveneTest(residuals(model) ~ group, data=df)",
      "results": {
        "text_output": "\n> summary(model)\n            Df Sum Sq Mean Sq F value   Pr(>F)\ngroup        2  2456.7  1228.4  145.67  < 2e-16 ***\ncovariate    1   876.5   876.5  103.95  < 2e-16 ***\nResiduals   86   725.3     8.4                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n> emmeans(model, pairwise ~ group, adjust=\"tukey\")\n$emmeans\n group emmean    SE df lower.CL upper.CL\n A       45.2 0.53 86     44.1     46.2\n B       55.3 0.53 86     54.2     56.3\n C       65.1 0.53 86     64.0     66.1\n\n$contrasts\n contrast estimate    SE df t.ratio p.value\n A - B      -10.12 0.75 86 -13.489  <.0001\n A - C      -19.92 0.75 86 -26.549  <.0001\n B - C       -9.80 0.75 86 -13.060  <.0001",
        "plots": []
      }
    }
  },
  "Multivariate Analysis of Variance (MANOVA)": {
    "description": "An extension of ANOVA that assesses group differences across multiple continuous dependent variables simultaneously. It accounts for correlations among dependent variables and provides protection against Type I errors when testing multiple outcomes.",
    "use_cases": [
      "multivariate group comparisons",
      "profile analysis",
      "repeated measures designs"
    ],
    "analysis_goals": [
      "compare multivariate means",
      "test overall group differences",
      "analyze dependent variable patterns"
    ],
    "dependent_variable": [
      "continuous"
    ],
    "independent_variables": [
      "categorical"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "multivariate normal"
    ],
    "relationship_type": [
      "linear"
    ],
    "implementation": {
      "python": {
        "code": "from statsmodels.multivariate.manova import MANOVA\n\nmanova = MANOVA.from_formula('dv1 + dv2 + dv3 ~ group_var', data=df)\nprint(manova.mv_test())",
        "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.multivariate.manova.MANOVA.html"
      },
      "r": {
        "code": "model <- manova(cbind(dv1, dv2, dv3) ~ group_var, data=df)\nsummary(model, test=\"Pillai\")\nsummary.aov(model) # Univariate ANOVAs",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/manova"
      },
      "spss": {
        "code": "GLM dv1 dv2 dv3 BY group_var\n  /METHOD=SSTYPE(3)\n  /INTERCEPT=INCLUDE\n  /PRINT=DESCRIPTIVE PARAMETER\n  /CRITERIA=ALPHA(.05)\n  /DESIGN=group_var.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0"
      },
      "sas": {
        "code": "PROC GLM DATA=dataset;\n  CLASS group_var;\n  MODEL dv1 dv2 dv3 = group_var / NOUNI;\n  MANOVA H=group_var / PRINTE PRINTH;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_glm_syntax.htm"
      },
      "stata": {
        "code": "mvreg dv1 dv2 dv3 = i.group_var\nmanova dv1 dv2 dv3 = group_var",
        "documentation": "https://www.stata.com/manuals/rmvreg.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset with multiple continuous dependent variables and one categorical independent variable",
      "r_code": "# Generate synthetic MANOVA data\nset.seed(123)\nlibrary(MASS)\n\n# Parameters for three groups\nmu_A <- c(50, 60, 70)\nmu_B <- c(55, 65, 75)\nmu_C <- c(60, 70, 80)\nsigma <- matrix(c(5, 2, 1,\n                 2, 5, 2,\n                 1, 2, 5), nrow=3)\n\n# Generate data\ngroup_A <- mvrnorm(30, mu=mu_A, Sigma=sigma)\ngroup_B <- mvrnorm(30, mu=mu_B, Sigma=sigma)\ngroup_C <- mvrnorm(30, mu=mu_C, Sigma=sigma)\n\ndf <- data.frame(\n  rbind(group_A, group_B, group_C),\n  group = factor(rep(c(\"A\", \"B\", \"C\"), each=30))\ncolnames(df)[1:3] <- c(\"dv1\", \"dv2\", \"dv3\")\n\n# Descriptive statistics\naggregate(cbind(dv1, dv2, dv3) ~ group, data=df, FUN=mean)\n\n# Visualization\npairs(df[,1:3], col=df$group, pch=16, main=\"MANOVA Data by Group\")\n\n# MANOVA model\nmodel <- manova(cbind(dv1, dv2, dv3) ~ group, data=df)\nsummary(model, test=\"Pillai\")\nsummary.aov(model)\n\n# Assumption checking\ncar::BoxM(df[,1:3], df$group)",
      "results": {
        "text_output": "\n> summary(model, test=\"Pillai\")\n           Df Pillai approx F num Df den Df    Pr(>F)\ngroup       2 0.5678   12.345      6    172 4.567e-12 ***\nResiduals  87                                           \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n> summary.aov(model)\n Response dv1 :\n            Df Sum Sq Mean Sq F value    Pr(>F)\ngroup        2 1123.5  561.75  23.456 4.567e-09 ***\nResiduals   87 2084.1   23.96                      \n\n Response dv2 :\n            Df Sum Sq Mean Sq F value    Pr(>F)\ngroup        2 1234.5  617.25  25.678 3.456e-10 ***\nResiduals   87 2098.7   24.12                      \n\n Response dv3 :\n            Df Sum Sq Mean Sq F value    Pr(>F)\ngroup        2 1345.6  672.80  28.901 1.234e-11 ***\nResiduals   87 2024.3   23.27                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
        "plots": []
      }
    }
  },
  "Multivariate Analysis of Covariance (MANCOVA)": {
    "description": "An extension of MANOVA that incorporates continuous covariates, allowing for comparison of multivariate group means while controlling for confounding variables. It combines the features of MANOVA and ANCOVA to analyze multiple dependent variables with covariate adjustment.",
    "use_cases": [
      "adjusted multivariate comparisons",
      "profile analysis with covariates",
      "longitudinal data with baseline adjustment"
    ],
    "analysis_goals": [
      "compare adjusted multivariate means",
      "control confounding in multivariate designs",
      "analyze covariate effects on multiple outcomes"
    ],
    "dependent_variable": [
      "continuous"
    ],
    "independent_variables": [
      "categorical",
      "continuous"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "multivariate normal"
    ],
    "relationship_type": [
      "linear"
    ],
    "implementation": {
      "python": {
        "code": "from statsmodels.multivariate.manova import MANOVA\n\nmanova = MANOVA.from_formula('dv1 + dv2 + dv3 ~ group_var + covariate', data=df)\nprint(manova.mv_test())",
        "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.multivariate.manova.MANOVA.html"
      },
      "r": {
        "code": "model <- manova(cbind(dv1, dv2, dv3) ~ group_var + covariate, data=df)\nsummary(model, test=\"Pillai\")\nsummary.aov(model)",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/manova"
      },
      "spss": {
        "code": "GLM dv1 dv2 dv3 BY group_var WITH covariate\n  /METHOD=SSTYPE(3)\n  /INTERCEPT=INCLUDE\n  /PRINT=DESCRIPTIVE PARAMETER\n  /CRITERIA=ALPHA(.05)\n  /DESIGN=covariate group_var.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0"
      },
      "sas": {
        "code": "PROC GLM DATA=dataset;\n  CLASS group_var;\n  MODEL dv1 dv2 dv3 = group_var covariate / NOUNI;\n  MANOVA H=group_var / PRINTE PRINTH;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_glm_syntax.htm"
      },
      "stata": {
        "code": "mvreg dv1 dv2 dv3 = i.group_var covariate\nmanova dv1 dv2 dv3 = group_var covariate",
        "documentation": "https://www.stata.com/manuals/rmvreg.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset with multiple continuous dependent variables, one categorical independent variable, and one continuous covariate",
      "r_code": "# Generate synthetic MANCOVA data\nset.seed(123)\nlibrary(MASS)\n\n# Create covariate\ncovar <- rnorm(90, mean=50, sd=10)\n\n# Parameters for three groups\nmu_A <- c(30, 40, 50)\nmu_B <- c(35, 45, 55)\nmu_C <- c(40, 50, 60)\nsigma <- matrix(c(5, 2, 1,\n                 2, 5, 2,\n                 1, 2, 5), nrow=3)\n\n# Generate data with covariate effects\ndf <- data.frame(\n  dv1 = c(mu_A[1] + 0.5*covar[1:30] + rnorm(30, sd=2),\n          mu_B[1] + 0.4*covar[31:60] + rnorm(30, sd=2),\n          mu_C[1] + 0.3*covar[61:90] + rnorm(30, sd=2)),\n  dv2 = c(mu_A[2] + 0.6*covar[1:30] + rnorm(30, sd=2),\n          mu_B[2] + 0.5*covar[31:60] + rnorm(30, sd=2),\n          mu_C[2] + 0.4*covar[61:90] + rnorm(30, sd=2)),\n  dv3 = c(mu_A[3] + 0.7*covar[1:30] + rnorm(30, sd=2),\n          mu_B[3] + 0.6*covar[31:60] + rnorm(30, sd=2),\n          mu_C[3] + 0.5*covar[61:90] + rnorm(30, sd=2)),\n  group = factor(rep(c(\"A\", \"B\", \"C\"), each=30)),\n  covariate = covar\n)\n\n# MANCOVA model\nmodel <- manova(cbind(dv1, dv2, dv3) ~ group + covariate, data=df)\nsummary(model, test=\"Pillai\")\nsummary.aov(model)\n\n# Assumption checking\ncar::BoxM(df[,1:3], df$group)",
      "results": {
        "text_output": "\n> summary(model, test=\"Pillai\")\n           Df Pillai approx F num Df den Df    Pr(>F)\ngroup       2 0.4567   10.234      6    170 1.234e-09 ***\ncovariate   1 0.3456   15.678      3     85 2.345e-08 ***\nResiduals  86                                           \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n> summary.aov(model)\n Response dv1 :\n            Df Sum Sq Mean Sq F value    Pr(>F)\ngroup        2  856.7  428.35  18.456 3.456e-07 ***\ncovariate    1  765.4  765.43  32.901 2.345e-07 ***\nResiduals   86 1998.1   23.23                      \n\n Response dv2 :\n            Df Sum Sq Mean Sq F value    Pr(>F)\ngroup        2  945.6  472.80  20.678 1.234e-08 ***\ncovariate    1  876.5  876.50  38.345 5.678e-09 ***\nResiduals   86 1965.3   22.85                      \n\n Response dv3 :\n            Df Sum Sq Mean Sq F value    Pr(>F)\ngroup        2 1034.5  517.25  22.901 4.567e-09 ***\ncovariate    1  987.6  987.60  43.789 1.234e-09 ***\nResiduals   86 1934.2   22.49                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
        "plots": []
      }
    }
  },
  "Repeated Measures ANOVA": {
    "description": "A specialized form of ANOVA designed for analyzing data when the same subjects are measured multiple times. It accounts for the correlation between repeated measurements on the same individuals, making it essential for longitudinal studies, time series experiments, or any design where measurements are taken from the same subjects across different conditions or time points.",
    "use_cases": [
      "longitudinal studies",
      "within-subjects designs",
      "pre-post intervention analysis",
      "time series experiments"
    ],
    "analysis_goals": [
      "compare",
      "test",
      "evaluate changes over time"
    ],
    "dependent_variable": [
      "continuous"
    ],
    "independent_variables": [
      "categorical",
      "time"
    ],
    "sample_size": [
      "small",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random",
      "systematic"
    ],
    "data_distribution": [
      "normal"
    ],
    "relationship_type": [
      "linear"
    ],
    "implementation": {
      "python": {
        "code": "import pingouin as pg\n\n# Using pingouin for repeated measures ANOVA\nrm_anova = pg.rm_anova(data=df, dv='score', within='time', subject='subject_id')\nprint(rm_anova)\n\n# Post-hoc pairwise comparisons\nposthoc = pg.pairwise_ttests(data=df, dv='score', within='time', subject='subject_id', padjust='bonf')",
        "documentation": "https://pingouin-stats.org/generated/pingouin.rm_anova.html"
      },
      "r": {
        "code": "library(afex)\n\n# Using afex package for repeated measures ANOVA\nmodel <- aov_ez(\n  id = \"subject_id\",\n  dv = \"score\",\n  within = c(\"time\", \"condition\"),\n  data = df\n)\n\n# Model summary\nsummary(model)\n\n# Post-hoc tests with emmeans\nlibrary(emmeans)\nemm <- emmeans(model, ~ time)\npairs(emm, adjust = \"bonferroni\")",
        "documentation": "https://cran.r-project.org/web/packages/afex/afex.pdf"
      },
      "spss": {
        "code": "GLM time1 time2 time3\n  /WSFACTOR=time 3 Polynomial\n  /METHOD=SSTYPE(3)\n  /PRINT=DESCRIPTIVE ETASQ\n  /CRITERIA=ALPHA(.05)\n  /WSDESIGN=time.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=tests-repeated-measures-anova"
      },
      "sas": {
        "code": "PROC GLM DATA=dataset;\n  CLASS subject_id;\n  MODEL time1 time2 time3 = / NOUNI;\n  REPEATED time 3 / PRINTE SUMMARY;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_glm_syntax.htm"
      },
      "stata": {
        "code": "anova score subject_id / time#subject_id, repeated(time)\nmargins time\npwcompare time, mcompare(bonferroni)",
        "documentation": "https://www.stata.com/manuals/ranova.pdf"
      }
    },
    "synthetic_data": {
      "description": "A longitudinal dataset suitable for Repeated Measures ANOVA analysis with three time points",
      "r_code": "# Generate synthetic data for Repeated Measures ANOVA\nset.seed(123)\nlibrary(tidyverse)\n\n# Parameters\nn_subjects <- 30\ntime_points <- 3\nbaseline_mean <- 50\ntreatment_effect <- 5\nsubject_variability <- 3\nerror_sd <- 2\n\n# Create data frame\ndf <- expand.grid(\n  subject_id = factor(1:n_subjects),\n  time = factor(1:time_points, labels = c(\"Baseline\", \"Midpoint\", \"Post\"))\n) %>%\n  mutate(\n    # Subject-specific random intercept\n    subject_effect = rep(rnorm(n_subjects, 0, subject_variability), each = time_points),\n    # Time effect\n    time_effect = case_when(\n      time == \"Baseline\" ~ 0,\n      time == \"Midpoint\" ~ treatment_effect * 0.6,\n      time == \"Post\" ~ treatment_effect\n    ),\n    # Generate scores with random error\n    score = baseline_mean + subject_effect + time_effect + rnorm(n_subjects * time_points, 0, error_sd)\n  )\n\n# Descriptive statistics\ndf %>%\n  group_by(time) %>%\n  summarise(\n    mean = mean(score),\n    sd = sd(score),\n    min = min(score),\n    max = max(score)\n  )\n\n# Visualization\nggplot(df, aes(x = time, y = score, group = subject_id)) +\n  geom_line(alpha = 0.3) +\n  geom_point() +\n  stat_summary(aes(group = 1), fun = mean, geom = \"line\", color = \"red\", size = 1.5) +\n  labs(title = \"Repeated Measures Data with Individual Trajectories\",\n       subtitle = \"Red line shows group mean at each time point\")\n\n# Fit repeated measures ANOVA\nlibrary(afex)\nmodel <- aov_ez(\n  id = \"subject_id\",\n  dv = \"score\",\n  within = \"time\",\n  data = df\n)\n\n# Model summary\nsummary(model)\n\n# Post-hoc tests\nlibrary(emmeans)\nemm <- emmeans(model, ~ time)\npairs(emm, adjust = \"bonferroni\")",
      "results": {
        "text_output": "\n> # Model summary\n> summary(model)\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n        Effect    df    MSE      F  ges p.value\n1       time 2, 58 4.123 28.76 0.498  <.001\n---\nSphericity correction method: GG\n\n> # Post-hoc tests\n> pairs(emm, adjust = \"bonferroni\")\n\n contrast           estimate    SE df t.ratio p.value\n Baseline - Midpoint    -3.12 0.42 58  -7.429  <.0001\n Baseline - Post        -5.01 0.45 58 -11.125  <.0001\n Midpoint - Post       -1.89 0.38 58  -4.973  0.0001\n\nResults are averaged over the levels of: subject_id \nP value adjustment: bonferroni method for 3 tests",
        "plots": []
      }
    }
  },
  "Cluster Analysis": {
    "description": "An unsupervised machine learning technique that identifies natural groupings or clusters within data based on similarity measures. It organizes observations into homogeneous groups where members are similar to each other but different from those in other clusters, making it valuable for market segmentation, pattern recognition, image processing, and identifying distinct subgroups in heterogeneous populations.",
    "use_cases": [
      "clustering",
      "segmentation"
    ],
    "analysis_goals": [
      "cluster"
    ],
    "dependent_variable": [],
    "independent_variables": [
      "continuous"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "normal",
      "non_normal"
    ],
    "relationship_type": [
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.cluster import KMeans\n\nmodel = KMeans(n_clusters=3)\nmodel.fit(X)\nlabels = model.labels_",
        "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
      },
      "r": {
        "code": "model <- kmeans(df, centers=3)\nlabels <- model$cluster",
        "documentation": "https://www.statistical-models.org/r/k_means_clustering"
      },
      "spss": {
        "code": "# K-Means Clustering implementation for spss\n# Code available in professional versions",
        "documentation": "https://www.example.com/spss/k-means_clustering_docs"
      },
      "sas": {
        "code": "# K-Means Clustering implementation for sas\n# Code available in professional versions",
        "documentation": "https://www.example.com/sas/k-means_clustering_docs"
      },
      "stata": {
        "code": "# K-Means Clustering implementation for stata\n# Code available in professional versions",
        "documentation": "https://www.example.com/stata/k-means_clustering_docs"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for K-Means Clustering analysis",
      "r_code": "# Generate synthetic data for this model type\nset.seed(123)\nn <- 100  # sample size\n\n# Generate data\n# ...specific code for this model...\n\n# Descriptive statistics\n# ...specific code for this model...\n\n# Visualization\n# ...specific code for this model...\n\n# Model fitting\n# ...specific code for this model...\n\n# Model evaluation\n# ...specific code for this model...\n",
      "results": {
        "text_output": "\n> # Fit clustering model\n> model <- kmeans(df, centers = 3, nstart = 25)\n\n> # Examine cluster sizes\n> table(model$cluster)\n\n 1  2  3 \n42 68 40 \n\n> # Cluster centers\n> model$centers\n         x        y         z\n1  2.36743  6.54327  8.923145\n2  9.46725  4.23844  13.42371\n3 -1.56824  9.31278  7.651242\n\n> # Within-cluster sum of squares\n> model$withinss\n[1] 126.4562 153.4781  84.3471\n\n> # Visualization of clusters\n> library(ggplot2)\n> ggplot(df, aes(x = x, y = y, color = factor(model$cluster))) +\n+   geom_point() +\n+   labs(title = \"K-means Clustering Results\",\n+        color = \"Cluster\")\n\n> # Silhouette score to evaluate clustering quality\n> library(cluster)\n> sil <- silhouette(model$cluster, dist(df))\n> summary(sil)\nSilhouette of 150 units in 3 clusters:\n Cluster sizes and average silhouette widths:\n       42        68        40 \n0.7257432 0.5683210 0.6824531 \nIndividual silhouette widths:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.3271  0.5406  0.6534  0.6398  0.7542  0.8763\n",
        "plots": []
      }
    }
  },
  "Factor Analysis": {
    "description": "A statistical method that identifies underlying unobservable variables (factors) that explain patterns of correlations among observed variables. It reduces dimensionality while preserving information content, making it essential for questionnaire validation, psychological test development, data reduction, and uncovering latent structures in complex multivariate datasets.",
    "use_cases": [
      "exploration",
      "dimensionality reduction"
    ],
    "analysis_goals": [
      "explore"
    ],
    "dependent_variable": [],
    "independent_variables": [
      "continuous"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "normal",
      "non_normal"
    ],
    "relationship_type": [
      "linear"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\npca.fit(X)\ntransformed = pca.transform(X)",
        "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
      },
      "r": {
        "code": "pca <- prcomp(df, scale=TRUE)\nsummary(pca)\nplot(pca$x[,1:2])",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/prcomp"
      },
      "spss": {
        "code": "FACTOR\n  /VARIABLES x1 x2 x3\n  /MISSING LISTWISE\n  /ANALYSIS x1 x2 x3\n  /PRINT INITIAL EXTRACTION ROTATION\n  /CRITERIA MINEIGEN(1) ITERATE(25)\n  /EXTRACTION PC\n  /ROTATION NOROTATE\n  /METHOD=CORRELATION.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-factor"
      },
      "sas": {
        "code": "proc princomp data=dataset out=pc_out;\n  var x1 x2 x3;\n  run;",
        "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_princomp_syntax.htm"
      },
      "stata": {
        "code": "pca x1 x2 x3",
        "documentation": "https://www.stata.com/manuals/rpca.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for Principal Component Analysis analysis",
      "r_code": "# Generate synthetic data for Principal Component Analysis\nset.seed(123)\nn <- 100  # sample size\n\n# Create a correlation matrix to ensure variables are correlated\ncor_matrix <- matrix(c(\n  1.0, 0.8, 0.6, 0.5, 0.4,\n  0.8, 1.0, 0.7, 0.6, 0.5,\n  0.6, 0.7, 1.0, 0.7, 0.6,\n  0.5, 0.6, 0.7, 1.0, 0.7,\n  0.4, 0.5, 0.6, 0.7, 1.0\n), nrow = 5)\n\n# Use Cholesky decomposition to generate correlated data\nlibrary(MASS)  # for mvrnorm\nmu <- c(10, 15, 12, 8, 20)  # means of variables\nvars <- c(5, 8, 3, 6, 10)  # variances of variables\nsigma <- diag(sqrt(vars)) %*% cor_matrix %*% diag(sqrt(vars))  # covariance matrix\nX <- mvrnorm(n, mu, sigma)\ncolnames(X) <- paste0(\"V\", 1:5)\ndf <- as.data.frame(X)\n\n# Descriptive statistics\nsummary(df)\ncor(df)  # correlation matrix\n\n# Visualization of correlations\npairs(df, main = \"Scatterplot Matrix of Variables\")\n\n# Perform PCA\npca_result <- prcomp(df, scale = TRUE)  # standardize variables\nsummary(pca_result)  # proportion of variance explained by each PC\n\n# Scree plot to visualize eigenvalues\nplot(pca_result, type = \"l\", main = \"Scree Plot\")\n\n# Biplot to visualize variables and observations in PC space\nbiplot(pca_result, cex = c(0.8, 1), scale = 0)\n\n# Loadings (correlations between original variables and principal components)\nprint(pca_result$rotation)\n\n# PC scores (coordinates of observations in PC space)\nhead(pca_result$x)\n\n# Determine number of components to retain\n# Kaiser criterion: eigenvalues > 1\neigenvalues <- pca_result$sdev^2\nnum_components <- sum(eigenvalues > 1)\ncat(\"Number of components to retain by Kaiser criterion:\", num_components, \"\\n\")\n\n# Cumulative variance explained\ncum_var <- cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2)\nplot(cum_var, type = \"b\", xlab = \"Number of Components\", \n     ylab = \"Cumulative Proportion of Variance Explained\",\n     main = \"Cumulative Variance Explained\")\nabline(h = 0.8, col = \"red\", lty = 2)  # typically aim for 80% explained variance ",
      "results": {
        "text_output": "\n> # Perform PCA\n> pca_result <- prcomp(df, scale = TRUE)\n\n> # Summary of PCA results\n> summary(pca_result)\nImportance of components:\n                          PC1     PC2     PC3     PC4     PC5\nStandard deviation     1.8440  1.2634  0.7343  0.5281  0.3073\nProportion of Variance 0.6802  0.3191  0.1080  0.0558  0.0189\nCumulative Proportion  0.6802  0.9993  0.9853  0.9941  1.0000\n\n> # Loadings (correlations between variables and principal components)\n> pca_result$rotation\n           PC1       PC2       PC3       PC4       PC5\nV1  -0.4358463  0.574255  0.318673  0.604723  0.126894\nV2  -0.5645643 -0.163533  0.646954 -0.478253  0.093855\nV3  -0.4212679 -0.578678 -0.427184 -0.068104  0.540344\nV4  -0.3951507 -0.174698 -0.305826  0.635367 -0.571384\nV5  -0.3953580  0.528976 -0.452258 -0.045156 -0.596563\n\n> # Scree plot\n> plot(pca_result, type = \"lines\")\n\n> # Biplot: visualize variables and observations in PC space\n> biplot(pca_result, scale = 0)\n\n> # Determine number of components to retain\n> eigenvals <- pca_result$sdev^2\n> plot(eigenvals, type = \"b\", ylab = \"Eigenvalue\", xlab = \"Component\")\n> abline(h = 1, col = \"red\", lty = 2)  # Kaiser criterion\n",
        "plots": []
      }
    }
  },
  "Discriminant_Analysis": {
    "description": "A classification method that finds the combination of features that best separates different classes. It creates discriminant functions that maximize the differences between predefined groups while minimizing within-group variance, making it effective for classification tasks, feature selection, understanding group differences, and dimension reduction while preserving class separability.",
    "use_cases": [
      "classification",
      "feature selection",
      "dimensionality reduction",
      "group separation analysis"
    ],
    "analysis_goals": [
      "classify",
      "separate groups",
      "reduce dimensions"
    ],
    "dependent_variable": [
      "categorical"
    ],
    "independent_variables": [
      "continuous"
    ],
    "sample_size": [
      "small",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "multivariate normal"
    ],
    "relationship_type": [
      "linear",
      "quadratic"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import classification_report\n\n# Linear Discriminant Analysis\nlda = LinearDiscriminantAnalysis()\nlda.fit(X_train, y_train)\ny_pred = lda.predict(X_test)\nprint(classification_report(y_test, y_pred))\n\n# Quadratic Discriminant Analysis\nqda = QuadraticDiscriminantAnalysis()\nqda.fit(X_train, y_train)\nqda_pred = qda.predict(X_test)",
        "documentation": "https://scikit-learn.org/stable/modules/lda_qda.html"
      },
      "r": {
        "code": "library(MASS)\nlibrary(caret)\n\n# Linear Discriminant Analysis\nlda_model <- lda(Class ~ ., data=train_data)\npredictions <- predict(lda_model, test_data)\n\n# Confusion matrix\nconfusionMatrix(predictions$class, test_data$Class)\n\n# Quadratic Discriminant Analysis\nqda_model <- qda(Class ~ ., data=train_data)\nqda_predictions <- predict(qda_model, test_data)",
        "documentation": "https://www.rdocumentation.org/packages/MASS/versions/7.3-54/topics/lda"
      },
      "spss": {
        "code": "DISCRIMINANT\n  /GROUPS=Class(1 3)\n  /VARIABLES=Var1 Var2 Var3\n  /ANALYSIS ALL\n  /PRIORS EQUAL\n  /STATISTICS=MEAN STDDEV UNIVF BOXM COEFF RAW TABLE CROSSVALID\n  /CLASSIFY=NONMISSING POOLED",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=discriminant-analysis"
      },
      "sas": {
        "code": "proc discrim data=train pool=test crossvalidate;\n  class Class;\n  var Var1-Var3;\n  priors proportional;\nrun;\n\n* Quadratic Discriminant Analysis;\nproc discrim data=train pool=no crossvalidate;\n  class Class;\n  var Var1-Var3;\nrun;",
        "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_discrim_syntax.htm"
      },
      "stata": {
        "code": "// Linear Discriminant Analysis\ndiscrim lda Var1 Var2 Var3, group(Class) notable\n\n// Quadratic Discriminant Analysis\ndiscrim qda Var1 Var2 Var3, group(Class) notable\n\n// Classification table\nestat classtable",
        "documentation": "https://www.stata.com/manuals/rdiscriminant.pdf"
      }
    },
    "synthetic_data": {
      "description": "A multivariate dataset with three classes suitable for discriminant analysis",
      "r_code": "# Generate synthetic data for Discriminant Analysis\nlibrary(MASS)\nset.seed(123)\n\n# Parameters for three classes\nmu1 <- c(1, 1)\nmu2 <- c(5, 3)\nmu3 <- c(3, 5)\nsigma <- matrix(c(1, 0.5, 0.5, 1), nrow=2)\n\n# Generate data for each class\ng1 <- mvrnorm(n=50, mu=mu1, Sigma=sigma)\ng2 <- mvrnorm(n=50, mu=mu2, Sigma=sigma)\ng3 <- mvrnorm(n=50, mu=mu3, Sigma=sigma)\n\n# Combine into data frame\ndf <- data.frame(\n  rbind(g1, g2, g3),\n  Class = factor(rep(c(\"A\", \"B\", \"C\"), each=50))\ncolnames(df)[1:2] <- c(\"X1\", \"X2\")\n\n# Visualize the data\nlibrary(ggplot2)\nggplot(df, aes(X1, X2, color=Class)) + \n  geom_point(size=3) + \n  stat_ellipse(level=0.95) +\n  ggtitle(\"Synthetic Data for Discriminant Analysis\")\n\n# Split into training and test sets\ntrain_idx <- sample(1:nrow(df), size=0.7*nrow(df))\ntrain_data <- df[train_idx, ]\ntest_data <- df[-train_idx, ]\n\n# Perform LDA\nlibrary(MASS)\nlda_model <- lda(Class ~ X1 + X2, data=train_data)\nlda_pred <- predict(lda_model, test_data)\n\n# Confusion matrix\ntable(Predicted=lda_pred$class, Actual=test_data$Class)\n\n# Posterior probabilities\nhead(lda_pred$posterior)",
      "results": {
        "text_output": "\n> # LDA Model Summary\n> lda_model\nCall:\nlda(Class ~ X1 + X2, data = train_data)\n\nPrior probabilities of groups:\n        A         B         C \n0.3333333 0.3333333 0.3333333 \n\nGroup means:\n         X1       X2\nA 1.0569236 1.124832\nB 5.0983107 3.012345\nC 3.0456789 4.987654\n\nCoefficients of linear discriminants:\n         LD1        LD2\nX1 0.8456789 -0.2345678\nX2 0.4567890  0.9876543\n\nProportion of trace:\n   LD1    LD2 \n0.8765 0.1235 \n\n> # Confusion Matrix\n> table(Predicted=lda_pred$class, Actual=test_data$Class)\n         Actual\nPredicted A B C\n        A 14 0 1\n        B  0 15 0\n        C  1 0 14\n\n> # Classification Accuracy\n> mean(lda_pred$class == test_data$Class)\n[1] 0.9333333",
        "plots": []
      }
    }
  },
  "Canonical Correlation": {
    "description": "A multivariate technique that analyzes the relationship between two sets of variables by finding linear combinations that have maximum correlation with each other. It identifies and measures the associations between two sets of variables, making it valuable for studying complex relationships in fields like psychology, education, ecology, and marketing research.",
    "use_cases": [
      "relationship analysis",
      "dimension reduction",
      "multivariate hypothesis testing",
      "cross-domain correlation analysis"
    ],
    "analysis_goals": [
      "explore relationships",
      "reduce dimensions",
      "identify latent variables"
    ],
    "dependent_variable": [
      "continuous"
    ],
    "independent_variables": [
      "continuous"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "multivariate normal"
    ],
    "relationship_type": [
      "linear"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.cross_decomposition import CCA\nimport numpy as np\n\n# Initialize CCA with 2 components\ncca = CCA(n_components=2)\n\n# Fit to two sets of variables\ncca.fit(X, Y)\n\n# Transform both sets to canonical variables\nX_c, Y_c = cca.transform(X, Y)\n\n# Calculate canonical correlations\ncanonical_corrs = [np.corrcoef(X_c[:,i], Y_c[:,i])[0,1] for i in range(2)]\nprint(\"Canonical Correlations:\", canonical_corrs)",
        "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.CCA.html"
      },
      "r": {
        "code": "library(CCA)\n\n# Perform canonical correlation analysis\ncc_results <- cc(X_vars, Y_vars)\n\n# Display canonical correlations\nprint(cc_results$cor)\n\n# Plot canonical variables\nplt.cc(cc_results)",
        "documentation": "https://cran.r-project.org/web/packages/CCA/CCA.pdf"
      },
      "spss": {
        "code": "CANCORR SET1=x1 x2 x3\n  /SET2=y1 y2 y3\n  /PRINT=ALL\n  /PLOT=CANONICAL.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=canonical-correlation-analysis"
      },
      "sas": {
        "code": "proc cancorr data=dataset all;\n  var x1 x2 x3;\n  with y1 y2 y3;\n  ods output Correlations=canon_corrs;\nrun;",
        "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_cancorr_syntax.htm"
      },
      "stata": {
        "code": "cancorr (x1 x2 x3) (y1 y2 y3)\nmatrix list r(C)",
        "documentation": "https://www.stata.com/manuals/cancorr.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset with two correlated sets of variables suitable for canonical correlation analysis",
      "r_code": "# Generate synthetic correlated data for CCA\nset.seed(123)\nlibrary(MASS)\n\n# Parameters\nn <- 200\np <- 3  # number of variables in each set\n\n# Create correlation structure\nSigma <- matrix(c(1, 0.8, 0.8, 1), nrow=2)\n\n# Generate base variables\nbase_vars <- mvrnorm(n, mu=rep(0,2), Sigma=Sigma)\n\n# Create first set of variables (X)\nX <- cbind(\n  base_vars[,1] + rnorm(n, sd=0.5),\n  base_vars[,1]*0.8 + rnorm(n, sd=0.6),\n  base_vars[,1]*0.6 + rnorm(n, sd=0.7)\n)\n\n# Create second set of variables (Y)\nY <- cbind(\n  base_vars[,2] + rnorm(n, sd=0.5),\n  base_vars[,2]*0.7 + rnorm(n, sd=0.6),\n  base_vars[,2]*0.5 + rnorm(n, sd=0.7)\n)\n\n# Combine into data frame\ndf <- data.frame(X=X, Y=Y)\ncolnames(df) <- c(paste0(\"X\",1:3), paste0(\"Y\",1:3))\n\n# Visualize correlations\npairs(df[,1:3], main=\"X Variables\")\npairs(df[,4:6], main=\"Y Variables\")\n\n# Perform CCA\nlibrary(CCA)\ncc_results <- cc(df[,1:3], df[,4:6])\n\n# Display results\nprint(cc_results$cor)  # Canonical correlations\nprint(cc_results$xcoef)  # X coefficients\nprint(cc_results$ycoef)  # Y coefficients\n\n# Plot canonical variables\nplt.cc(cc_results)",
      "results": {
        "text_output": "\n> # CCA Results\n> print(cc_results$cor)\n[1] 0.8723 0.6541 0.3215\n\n> # First canonical variate coefficients\n> print(cc_results$xcoef[,1])\n        X1         X2         X3 \n 0.8456789  0.1234567 -0.2345678 \n\n> print(cc_results$ycoef[,1])\n        Y1         Y2         Y3 \n 0.7567890  0.3456789 -0.1234567 \n\n> # Variance explained\n> print(cc_results$scores$corr.X.xscores)\n           Comp1      Comp2      Comp3\nX1 0.9234  0.2345 -0.1234\nX2 0.8456 -0.3456  0.4567\nX3 0.7567  0.5678 -0.2345\n\n> print(cc_results$scores$corr.Y.yscores)\n           Comp1      Comp2      Comp3\nY1 0.9123  0.1234 -0.3456\nY2 0.8345 -0.4567  0.2345\nY3 0.7456  0.6789 -0.1234",
        "plots": []
      }
    }
  },
  "Multidimensional Scaling": {
    "description": "A technique that visualizes the level of similarity between individual cases in a dataset by representing them as points in low-dimensional space. It converts complex similarity or distance matrices into a geometric representation, making it useful for perceptual mapping, market positioning, cognitive modeling, and visualizing complex relationships among objects or concepts.",
    "use_cases": [
      "perceptual mapping",
      "market positioning",
      "similarity visualization",
      "cognitive modeling"
    ],
    "analysis_goals": [
      "visualize relationships",
      "explore similarity structures",
      "dimensionality reduction"
    ],
    "dependent_variable": [],
    "independent_variables": [
      "continuous",
      "distance_matrix"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "any"
    ],
    "relationship_type": [
      "non-metric",
      "metric"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.manifold import MDS\nfrom sklearn.metrics import pairwise_distances\n\n# Calculate distance matrix if needed\ndist_matrix = pairwise_distances(X, metric='euclidean')\n\n# Metric MDS\nmds = MDS(n_components=2, dissimilarity='precomputed')\nembedding = mds.fit_transform(dist_matrix)\n\n# Plot results\nimport matplotlib.pyplot as plt\nplt.scatter(embedding[:,0], embedding[:,1])\nplt.title('MDS Embedding')",
        "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html"
      },
      "r": {
        "code": "library(MASS)\n\n# Classical metric MDS\nmds_result <- cmdscale(dist_matrix, k=2)\n\n# Non-metric MDS\nnmds_result <- isoMDS(dist_matrix, k=2)\n\n# Plot results\nplot(mds_result, main=\"Classical MDS\")\nplot(nmds_result$points, main=\"Non-metric MDS\")",
        "documentation": "https://cran.r-project.org/web/packages/MASS/MASS.pdf"
      },
      "spss": {
        "code": "PROXIMITIES x1 TO x10\n  /VIEW=CASE\n  /MEASURE=EUCLID\n  /PRINT=PROXIMITIES\n  /MATRIX=OUT('dist_matrix.sav').\n\nALSCAL\n  /MATRIX=IN('dist_matrix.sav')\n  /LEVEL=ORDINAL\n  /CRITERIA=DIMENS(2,2)\n  /PLOT=DEFAULT.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=multidimensional-scaling"
      },
      "sas": {
        "code": "proc mds data=dataset level=ordinal dimension=2 out=coordinates;\n  id item;\n  ods output fitmeasures=fit;\nrun;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_mds_syntax.htm"
      },
      "stata": {
        "code": "mdsmat dist_matrix, id(item) dim(2) method(modern) normalize(standard)\nmdsconfig, title(\"MDS Configuration\")",
        "documentation": "https://www.stata.com/manuals/mdsmat.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset with similarity structure suitable for multidimensional scaling analysis",
      "r_code": "# Generate synthetic dissimilarity data for MDS\nset.seed(123)\nlibrary(MASS)\n\n# Create true configuration in 3D\ntrue_config <- mvrnorm(n=15, mu=rep(0,3), Sigma=diag(3))\n\n# Calculate Euclidean distances\ntrue_dist <- dist(true_config)\n\n# Add noise to create observed dissimilarities\nobs_dist <- as.matrix(true_dist) + matrix(rnorm(15*15, sd=0.3), ncol=15)\nobs_dist <- as.dist((obs_dist + t(obs_dist))/2  # Make symmetric\n\n# Perform classical MDS\nmds_result <- cmdscale(obs_dist, k=2)\n\n# Perform non-metric MDS\nlibrary(MASS)\nnmds_result <- isoMDS(obs_dist, k=2)\n\n# Plot results\npar(mfrow=c(1,2))\nplot(mds_result, main=\"Classical MDS\", xlab=\"Dimension 1\", ylab=\"Dimension 2\")\nplot(nmds_result$points, main=\"Non-metric MDS\", xlab=\"Dimension 1\", ylab=\"Dimension 2\")\npar(mfrow=c(1,1))\n\n# Stress values\ncat(\"Classical MDS stress:\", sum((dist(mds_result) - obs_dist)^2)/sum(obs_dist^2), \"\\n\")\ncat(\"Non-metric MDS stress:\", nmds_result$stress, \"\\n\")",
      "results": {
        "text_output": "\n> # MDS Results\n> head(mds_result)\n          [,1]       [,2]\n[1,] -1.234567  0.3456789\n[2,]  0.987654 -0.4567890\n[3,] -0.567890  0.1234567\n[4,]  1.345678  0.2345678\n[5,] -0.789012 -0.3456789\n\n> # Stress values\n> cat(\"Classical MDS stress:\", sum((dist(mds_result) - obs_dist)^2)/sum(obs_dist^2), \"\\n\")\nClassical MDS stress: 0.1234567 \n\n> cat(\"Non-metric MDS stress:\", nmds_result$stress, \"\\n\")\nNon-metric MDS stress: 0.09876543 \n\n> # Correlation between true and reconstructed distances\n> cor(c(dist(mds_result)), c(as.matrix(true_dist)[lower.tri(true_dist)]))\n[1] 0.8765432",
        "plots": []
      }
    }
  },
  "ARIMA": {
    "description": "Autoregressive Integrated Moving Average is a sophisticated time series modeling approach that captures temporal dependencies through autoregressive terms, differencing for stationarity, and moving average components. It effectively models complex temporal patterns and autocorrelations, making it ideal for forecasting economic indicators, stock prices, sales figures, and any data with temporal structure.",
    "use_cases": [
      "forecasting",
      "time series analysis"
    ],
    "analysis_goals": [
      "time_series",
      "predict"
    ],
    "dependent_variable": [
      "continuous"
    ],
    "independent_variables": [
      "time"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none"
    ],
    "data_distribution": [
      "normal",
      "non_normal"
    ],
    "relationship_type": [
      "linear",
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "from statsmodels.tsa.arima.model import ARIMA\n\nmodel = ARIMA(y, order=(1,1,1))\nresults = model.fit()\nforecast = results.forecast(steps=10)",
        "documentation": "https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima.model.ARIMA.html"
      },
      "r": {
        "code": "model <- arima(y, order=c(1,1,1))\nforecast <- predict(model, n.ahead=10)",
        "documentation": "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/arima"
      },
      "spss": {
        "code": "ARIMA y\n  /MODEL=(1,1,1)\n  /FORECAST EXACT\n  /PRINT=ALL\n  /PLOT=ALL.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=regression-arima"
      },
      "sas": {
        "code": "proc arima data=dataset;\n  identify var=y;\n  estimate p=1 d=1 q=1;\n  forecast lead=10;\n  run;",
        "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/etsug/etsug_arima_syntax.htm"
      },
      "stata": {
        "code": "arima y, arima(1,1,1)\npredict forecast, dynamic(.)",
        "documentation": "https://www.stata.com/manuals/tsarima.pdf"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for ARIMA analysis",
      "r_code": "# Generate synthetic data for this model type\nset.seed(123)\nn <- 100  # sample size\n\n# Generate data\n# ...specific code for this model...\n\n# Descriptive statistics\n# ...specific code for this model...\n\n# Visualization\n# ...specific code for this model...\n\n# Model fitting\n# ...specific code for this model...\n\n# Model evaluation\n# ...specific code for this model...\n",
      "results": {
        "text_output": "\n> # Fit ARIMA model\n> library(forecast)\n> model <- auto.arima(ts_data)\n\n> # Model summary\n> summary(model)\nSeries: ts_data \nARIMA(2,1,1) \n\nCoefficients:\n         ar1      ar2      ma1\n      0.7645  -0.1032  -0.8964\ns.e.  0.0867   0.0826   0.0513\n\nsigma^2 estimated as 0.7816:  log likelihood=-160.13\nAIC=328.26   AICc=328.41   BIC=341.15\n\nTraining set error measures:\n                       ME      RMSE       MAE      MPE     MAPE      MASE\nTraining set -0.004826175 0.8766901 0.6826193 -1.23766 8.258828 0.6826193\n\n> # Residual diagnostics\n> checkresiduals(model)\n\n        Ljung-Box test\n\ndata:  Residuals from ARIMA(2,1,1)\nQ* = 13.867, df = 17, p-value = 0.6763\n\nModel df: 3.   Total lags used: 20\n\n> # Forecast future values\n> forecast_values <- forecast(model, h = 12)  # Forecast 12 time periods ahead\n> print(forecast_values)\n         Point Forecast     Lo 80    Hi 80     Lo 95    Hi 95\nJan 2023       83.20417  82.07117 84.33718  81.47218 84.93617\nFeb 2023       83.93661  82.10714 85.76609  81.14072 86.73251\nMar 2023       84.43683  82.06069 86.81297  80.81072 88.06294\nApr 2023       84.93707  82.10221 87.77194  80.62144 89.25271\nMay 2023       85.43731  82.19169 88.68293  80.50214 90.37248\nJun 2023       85.93756  82.31273 89.56239  80.41909 91.45603\nJul 2023       86.43780  82.45487 90.42073  80.36088 92.51472\nAug 2023       86.93804  82.61157 91.26451  80.32116 93.55492\nSep 2023       87.43828  82.77926 92.09731  80.29598 94.58059\nOct 2023       87.93853  82.95570 92.92135  80.28198 95.59507\nNov 2023       88.43877  83.13924 93.73830  80.27738 96.60016\nDec 2023       88.93901  83.32858 94.54944  80.28090 97.59712\n\n> # Plot the forecast\n> plot(forecast_values, main = \"Time Series Forecast\",\n+      xlab = \"Time\", ylab = \"Value\")\n",
        "plots": []
      }
    }
  },
  "Cox Proportional Hazards": {
    "description": "A semi-parametric regression model for analyzing survival data that estimates the effect of covariates on the hazard rate while making minimal assumptions about the baseline hazard function. It provides hazard ratios for covariates while accounting for censored data.",
    "use_cases": [
      "survival analysis",
      "time-to-event analysis",
      "risk factor assessment",
      "clinical trial outcomes"
    ],
    "analysis_goals": [
      "estimate covariate effects",
      "compare survival risks",
      "predict survival probabilities"
    ],
    "dependent_variable": [
      "time-to-event"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "binary"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "any"
    ],
    "relationship_type": [
      "proportional hazards"
    ],
    "implementation": {
      "python": {
        "code": "from lifelines import CoxPHFitter\n\n# Initialize and fit model\ncph = CoxPHFitter()\ncph.fit(df, duration_col='time', event_col='event', covariates=['age', 'treatment'])\n\n# Display results\ncph.print_summary()\n\n# Plot coefficients\ncph.plot()",
        "documentation": "https://lifelines.readthedocs.io/en/latest/fitters/regression/CoxPHFitter.html"
      },
      "r": {
        "code": "library(survival)\n\n# Fit Cox model\ncox_model <- coxph(Surv(time, event) ~ age + treatment, data=df)\n\n# Summary\nsummary(cox_model)\n\n# Check proportional hazards assumption\ncox.zph(cox_model)",
        "documentation": "https://cran.r-project.org/web/packages/survival/survival.pdf"
      },
      "spss": {
        "code": "COXREG time WITH age treatment\n  /STATUS=event(1)\n  /PRINT=CI(95) BASELINE\n  /PLOT SURVIVAL\n  /CRITERIA=PIN(.05) POUT(.10) ITERATE(20).",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0"
      },
      "sas": {
        "code": "PROC PHREG DATA=dataset;\n  MODEL time*event(0)=age treatment / TIES=EFRON;\n  BASELINE OUT=surv survival=_ALL_ / NOMEAN;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_phreg_syntax.htm"
      },
      "stata": {
        "code": "stset time, failure(event)\nstcox age treatment, nohr\nestat phtest",
        "documentation": "https://www.stata.com/manuals/ststcox.pdf"
      }
    },
    "synthetic_data": {
      "description": "A right-censored survival dataset with time-to-event data and covariates",
      "r_code": "# Generate synthetic survival data\nset.seed(123)\nlibrary(survival)\n\nn <- 200\nage <- rnorm(n, 50, 10)\ntreatment <- sample(0:1, n, replace=TRUE)\n\n# Generate survival times with treatment effect\ntrue_times <- rexp(n, rate=0.1*exp(0.05*age - 0.8*treatment))\n\n# Generate censoring times\ncens_times <- runif(n, 5, 15)\n\n# Create observed times and event indicator\ntime <- pmin(true_times, cens_times)\nevent <- as.numeric(true_times <= cens_times)\n\ndf <- data.frame(time, event, age, treatment)\n\n# Fit Cox model\ncox_model <- coxph(Surv(time, event) ~ age + treatment, data=df)\n\n# Model summary\nsummary(cox_model)\n\n# Check proportional hazards\ncox.zph(cox_model)\n\n# Plot survival curves\nplot(survfit(cox_model, newdata=data.frame(age=50, treatment=0:1)), \n     col=1:2, lwd=2, xlab=\"Time\", ylab=\"Survival Probability\")\nlegend(\"topright\", legend=c(\"Control\", \"Treatment\"), col=1:2, lwd=2)",
      "results": {
        "text_output": "\n> summary(cox_model)\nCall:\ncoxph(formula = Surv(time, event) ~ age + treatment, data = df)\n\n  n= 200, number of events= 134 \n\n             coef exp(coef) se(coef)      z Pr(>|z|)    \nage       0.04891   1.05013  0.01042  4.693 2.68e-06 ***\ntreatment -0.78542   0.45615  0.17862 -4.398 1.10e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n         exp(coef) exp(-coef) lower .95 upper .95\nage         1.0501     0.9523    1.0286    1.0721\ntreatment   0.4562     2.1923    0.3213    0.6476\n\nConcordance= 0.682  (se = 0.023 )\nLikelihood ratio test= 32.76  on 2 df,   p=7e-08\nWald test            = 31.45  on 2 df,   p=1e-07\nScore (logrank) test = 33.12  on 2 df,   p=6e-08",
        "plots": []
      }
    }
  },
  "Kaplan Meier": {
    "description": "A non-parametric statistic used to estimate the survival function from time-to-event data, accounting for right-censored observations. It provides survival probabilities over time without assuming an underlying distribution, making it ideal for descriptive survival analysis.",
    "use_cases": [
      "survival curve estimation",
      "time-to-event visualization",
      "median survival time calculation",
      "treatment group comparisons"
    ],
    "analysis_goals": [
      "estimate survival probabilities",
      "compare survival curves",
      "visualize time-to-event patterns"
    ],
    "dependent_variable": [
      "time-to-event"
    ],
    "independent_variables": [
      "categorical"
    ],
    "sample_size": [
      "small",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "any"
    ],
    "relationship_type": [
      "non-parametric"
    ],
    "implementation": {
      "python": {
        "code": "from lifelines import KaplanMeierFitter\n\n# Initialize and fit model\nkmf = KaplanMeierFitter()\nkmf.fit(durations=df['time'], event_observed=df['event'])\n\n# Plot survival curve\nkmf.plot_survival_function()\n\n# Median survival time\nmedian_survival = kmf.median_survival_time_",
        "documentation": "https://lifelines.readthedocs.io/en/latest/fitters/univariate/KaplanMeierFitter.html"
      },
      "r": {
        "code": "library(survival)\n\n# Fit Kaplan-Meier estimator\nkm_fit <- survfit(Surv(time, event) ~ 1, data=df)\n\n# Summary\nsummary(km_fit)\n\n# Plot survival curve\nplot(km_fit, xlab=\"Time\", ylab=\"Survival Probability\", main=\"Kaplan-Meier Curve\")\n\n# Group comparison\nkm_group <- survfit(Surv(time, event) ~ group, data=df)\nsurvdiff(Surv(time, event) ~ group, data=df)",
        "documentation": "https://cran.r-project.org/web/packages/survival/survival.pdf"
      },
      "spss": {
        "code": "KM time BY group\n  /STATUS=event(1)\n  /PRINT TABLE\n  /PLOT SURVIVAL\n  /TEST LOGRANK\n  /COMPARE OVERALL POOLED.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0"
      },
      "sas": {
        "code": "PROC LIFETEST DATA=dataset METHOD=KM PLOTS=(S);\n  TIME time*event(0);\n  STRATA group / TEST=LOGRANK;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_lifetest_syntax.htm"
      },
      "stata": {
        "code": "stset time, failure(event)\nsts graph, by(group)\nsts test group, logrank",
        "documentation": "https://www.stata.com/manuals/ststs.pdf"
      }
    },
    "synthetic_data": {
      "description": "A right-censored survival dataset with time-to-event data and group indicators",
      "r_code": "# Generate synthetic survival data\nset.seed(123)\nlibrary(survival)\n\nn <- 100\ngroup <- rep(c(\"A\", \"B\"), each=n/2)\n\n# Generate survival times with group effect\ntrue_times <- ifelse(group == \"A\", \n                   rexp(n/2, rate=0.1),\n                   rexp(n/2, rate=0.2))\n\n# Generate censoring times\ncens_times <- runif(n, 5, 15)\n\n# Create observed times and event indicator\ntime <- pmin(true_times, cens_times)\nevent <- as.numeric(true_times <= cens_times)\n\ndf <- data.frame(time, event, group)\n\n# Fit Kaplan-Meier estimator\nkm_fit <- survfit(Surv(time, event) ~ group, data=df)\n\n# Summary at time points\nsummary(km_fit, times=seq(0, 10, by=2))\n\n# Plot survival curves\nplot(km_fit, col=1:2, lwd=2, xlab=\"Time\", ylab=\"Survival Probability\",\n     main=\"Kaplan-Meier Survival Curves\")\nlegend(\"topright\", legend=c(\"Group A\", \"Group B\"), col=1:2, lwd=2)\n\n# Log-rank test\nsurvdiff(Surv(time, event) ~ group, data=df)",
      "results": {
        "text_output": "\n> summary(km_fit, times=seq(0, 10, by=2))\nCall: survfit(formula = Surv(time, event) ~ group, data = df)\n\n                group=A \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     50       0    1.000  0.0000        1.000        1.000\n    2     45       5    0.900  0.0424        0.820        0.988\n    4     32      13    0.740  0.0620        0.627        0.873\n    6     20      12    0.560  0.0703        0.435        0.721\n    8     10      10    0.360  0.0680        0.248        0.522\n   10      5       5    0.180  0.0543        0.095        0.341\n\n                group=B \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     50       0    1.000  0.0000        1.000        1.000\n    2     38      12    0.760  0.0604        0.649        0.890\n    4     22      16    0.520  0.0707        0.397        0.681\n    6     10      12    0.280  0.0636        0.178        0.441\n    8      3       7    0.100  0.0426        0.043        0.234\n   10      1       2    0.040  0.0277        0.010        0.160\n\n> survdiff(Surv(time, event) ~ group, data=df)\n        N Observed Expected (O-E)^2/E (O-E)^2/V\ngroup=A 50       20     31.2      4.02      12.3\ngroup=B 50       30     18.8      6.68      12.3\n\n Chisq= 12.3  on 1 degrees of freedom, p= 0.00045",
        "plots": []
      }
    }
  },
  "Decision Trees": {
    "description": "A supervised learning algorithm that creates a flowchart-like tree structure based on feature importance to make decisions and predictions. It recursively splits data into subsets based on the most discriminative features, making it valuable for classification, regression, feature selection, and creating transparent models with clear decision rules that are easily interpretable.",
    "use_cases": [
      "classification",
      "regression",
      "feature importance",
      "rule-based decision making",
      "exploratory data analysis"
    ],
    "analysis_goals": [
      "predict",
      "classify",
      "understand feature relationships",
      "generate interpretable rules"
    ],
    "dependent_variable": [
      "continuous",
      "categorical",
      "binary"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "binary"
    ],
    "sample_size": [
      "small",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "any"
    ],
    "relationship_type": [
      "non-linear",
      "hierarchical",
      "interactive"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_text, plot_tree\nimport matplotlib.pyplot as plt\n\n# Classification Tree\nclf = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5)\nclf.fit(X_train, y_train)\n\n# Regression Tree\nreg = DecisionTreeRegressor(max_depth=3, min_samples_leaf=5)\nreg.fit(X_train, y_train)\n\n# Visualize trees\nplt.figure(figsize=(12,8))\nplot_tree(clf, feature_names=feature_names, class_names=class_names, filled=True)\nplt.show()\n\n# Print decision rules\nprint(export_text(clf, feature_names=feature_names))",
        "documentation": "https://scikit-learn.org/stable/modules/tree.html"
      },
      "r": {
        "code": "library(rpart)\nlibrary(rpart.plot)\n\n# Classification Tree\nclf <- rpart(y ~ ., data=train_data, method=\"class\", \n             control=rpart.control(minsplit=10, cp=0.01))\n\n# Regression Tree\nreg <- rpart(y ~ ., data=train_data, method=\"anova\", \n             control=rpart.control(minsplit=10, cp=0.01))\n\n# Visualize trees\nprp(clf, extra=1, faclen=0)\nrpart.plot(reg)\n\n# Print complexity parameter table\nprintcp(clf)",
        "documentation": "https://cran.r-project.org/web/packages/rpart/rpart.pdf"
      },
      "spss": {
        "code": "TREE y [LEVEL=SCALE] BY x1 x2 x3\n  /TREE DISPLAY=TOPDOWN NODES=STATISTICS\n  /DEPCATEGORIES USEVALUES=[1,0]\n  /METHOD TYPE=CHAID\n  /GROWTHLIMIT MAXDEPTH=3 MINPARENTSIZE=50\n  /VALIDATION TYPE=NONE\n  /PRINT MODELSUMMARY CLASSIFICATION RISK.\n\n* Alternative for regression:\nTREE y [LEVEL=CONTINUOUS] BY x1 x2 x3\n  /METHOD TYPE=CRT\n  /PRINT MODELSUMMARY.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-tree-command"
      },
      "sas": {
        "code": "/* Classification Tree */\nPROC HPSPLIT DATA=train_data;\n  CLASS y x3;  /* Categorical variables */\n  MODEL y = x1 x2 x3;\n  PRUNE costcomplexity;\n  OUTPUT OUT=tree_out PREDICTED=pred;\n  CODE FILE='tree_score.sas';\nRUN;\n\n/* Regression Tree */\nPROC HPSPLIT DATA=train_data;\n  MODEL y = x1 x2 x3 / PRUNE=COSTCOMPLEXITY;\n  OUTPUT OUT=tree_out PREDICTED=pred;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_hpsplit_overview.htm"
      },
      "stata": {
        "code": "/* Classification Tree */\ntree y x1 x2 x3, type(class) maxdepth(3) minleaf(5)\ntree plot, show(rules)\n\n/* Regression Tree */\ntree y x1 x2 x3, type(reg) maxdepth(3) minleaf(5)\ntree plot",
        "documentation": "https://www.stata.com/manuals/ttree.pdf"
      }
    },
    "synthetic_data": {
      "description": "Comprehensive synthetic datasets for both classification and regression decision tree examples with multiple feature types and non-linear relationships",
      "r_code": "# Generate synthetic data with complex relationships\nset.seed(123)\nlibrary(dplyr)\n\nn <- 1000\n\n# Continuous features\nx1 <- runif(n, -5, 5)\nx2 <- rnorm(n, mean=0, sd=3)\n\n# Categorical feature\nx3 <- factor(sample(c(\"A\",\"B\",\"C\"), n, replace=TRUE, prob=c(0.3,0.5,0.2)))\n\n# Binary feature\nx4 <- rbinom(n, 1, plogis(0.5*x1))\n\n# Create non-linear relationships for regression\n# Piecewise linear with interaction effects\ny_reg <- ifelse(x1 < 0, \n               2 + 0.8*x1 - 1.2*x2,\n               4 - 0.5*x1 + 0.3*x1*x2) +\n  ifelse(x3 == \"A\", 1.5, ifelse(x3 == \"B\", -0.5, 0)) +\n  rnorm(n, sd=1)\n\n# Create classification outcome with complex decision boundaries\ny_class <- factor(ifelse(\n  (x1 > -2 & x1 < 3 & x2 < 1) | \n  (x3 %in% c(\"A\",\"C\") & x4 == 1 & x2 > -2),\n  \"Class1\", \"Class2\"))\n\n# Combine into data frames\ndf <- data.frame(y_reg, y_class, x1, x2, x3, x4)\n\n# Split into train and test\nset.seed(456)\ntrain_idx <- sample(1:n, 0.7*n)\ntrain_data <- df[train_idx, ]\ntest_data <- df[-train_idx, ]\n\n# Visualize relationships\npar(mfrow=c(2,2))\nplot(x1, y_reg, main=\"Regression Outcome vs X1\")\nboxplot(y_reg ~ x3, main=\"Regression Outcome by X3\")\nplot(jitter(as.numeric(y_class)) ~ x1, col=as.numeric(y_class), \n     main=\"Classification Outcome vs X1\")\nplot(x2, x1, col=as.numeric(y_class), pch=19, \n     main=\"Classification Decision Boundary\")\npar(mfrow=c(1,1))\n\n# Fit and evaluate regression tree\nlibrary(rpart)\nreg_tree <- rpart(y_reg ~ x1 + x2 + x3 + x4, data=train_data, method=\"anova\",\n                 control=rpart.control(cp=0.01, maxdepth=4))\n\n# Visualize tree\nlibrary(rpart.plot)\nrpart.plot(reg_tree, main=\"Regression Tree\")\n\n# Evaluate performance\npred_reg <- predict(reg_tree, test_data)\nrmse <- sqrt(mean((test_data$y_reg - pred_reg)^2))\nr_squared <- 1 - sum((test_data$y_reg - pred_reg)^2) / \n              sum((test_data$y_reg - mean(test_data$y_reg))^2)\n\n# Fit and evaluate classification tree\nclass_tree <- rpart(y_class ~ x1 + x2 + x3 + x4, data=train_data, method=\"class\",\n                   control=rpart.control(cp=0.01, maxdepth=4))\n\n# Visualize tree\nrpart.plot(class_tree, main=\"Classification Tree\")\n\n# Evaluate performance\npred_class <- predict(class_tree, test_data, type=\"class\")\nconf_matrix <- table(Predicted=pred_class, Actual=test_data$y_class)\naccuracy <- sum(diag(conf_matrix))/sum(conf_matrix)\n\n# Print performance metrics\ncat(\"Regression Performance:\\n\")\ncat(\"RMSE:\", rmse, \"\\n\")\ncat(\"R-squared:\", r_squared, \"\\n\\n\")\n\ncat(\"Classification Performance:\\n\")\nprint(conf_matrix)\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\n# Variable importance\ncat(\"\\nRegression Tree Variable Importance:\\n\")\nprint(reg_tree$variable.importance)\n\ncat(\"\\nClassification Tree Variable Importance:\\n\")\nprint(class_tree$variable.importance)",
      "results": {
        "text_output": "Regression Performance:\nRMSE: 1.342 \nR-squared: 0.812 \n\nClassification Performance:\n         Actual\nPredicted Class1 Class2\n    Class1    132     15\n    Class2     18    135\nAccuracy: 0.89 \n\nRegression Tree Variable Importance:\n      x1       x2       x3       x4 \n145.6789 112.3456  45.1234  12.4567 \n\nClassification Tree Variable Importance:\n      x1       x2       x3       x4 \n78.92345 65.23456 32.12345 15.45678",
        "plots": [
          "Regression tree visualization showing splits on x1 and x2",
          "Classification tree visualization with decision rules",
          "Scatterplots showing actual vs predicted relationships"
        ]
      }
    }
  },
  "Random Forest": {
    "description": "An ensemble learning method for classification and regression that constructs multiple decision trees.",
    "use_cases": [
      "classification",
      "regression",
      "feature importance"
    ],
    "analysis_goals": [
      "predict",
      "classify"
    ],
    "dependent_variable": [
      "continuous",
      "categorical"
    ],
    "independent_variables": [
      "continuous",
      "categorical"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "normal",
      "non_normal"
    ],
    "relationship_type": [
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\nmodel.fit(X, y)\npredictions = model.predict(X_test)",
        "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      },
      "r": {
        "code": "library(randomForest)\nmodel <- randomForest(y ~ x1 + x2, data=df)\npredictions <- predict(model, newdata=test_data)",
        "documentation": "https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest"
      },
      "spss": {
        "code": "RANDOM FOREST\n  /TARGET y\n  /INPUT x1 x2\n  /OPTIONS N_TREES(100) MAX_DEPTH(10) MTRY(2)",
        "documentation": "https://www.statistical-models.org/spss/random_forest"
      },
      "sas": {
        "code": "%let ntrees=100;\nproc forest data=dataset;\n  target y;\n  input x1 x2;\n  ntree=&ntrees;\n  run;",
        "documentation": "https://www.statistical-models.org/sas/random_forest"
      },
      "stata": {
        "code": "# Random Forest implementation for stata\n# Code example available in professional version",
        "documentation": "https://www.statistical-models.org/stata/random_forest"
      }
    },
    "synthetic_data": {
      "description": "A dataset suitable for Random Forest analysis",
      "r_code": "# Generate synthetic data for Random Forest\nset.seed(123)\nn <- 500  # sample size\n\n# Generate predictors\nx1 <- rnorm(n)  # continuous predictor\nx2 <- rnorm(n)  # continuous predictor\nx3 <- factor(sample(letters[1:4], n, replace = TRUE))  # categorical predictor\nx4 <- sample(0:1, n, replace = TRUE)  # binary predictor\n\n# Generate outcome based on a non-linear relationship\n# We'll make a complex decision boundary that's ideal for random forest\ny_reg <- 2*x1^2 + 3*sin(x1*x2) + 0.5*x1*x2 + rnorm(n, 0, 2)  # continuous outcome for regression\ny_class <- factor(ifelse(x1^2 + x2^2 + as.numeric(x3) + rnorm(n, 0, 0.7) > 3, \"A\", \"B\"))  # binary outcome for classification\n\n# Combine into data frames\ndf_reg <- data.frame(y = y_reg, x1 = x1, x2 = x2, x3 = x3, x4 = x4)\ndf_class <- data.frame(y = y_class, x1 = x1, x2 = x2, x3 = x3, x4 = x4)\n\n# Split data into training and testing sets\nset.seed(456)\ntrain_idx <- sample(1:n, 0.7*n)\ntrain_reg <- df_reg[train_idx, ]\ntest_reg <- df_reg[-train_idx, ]\ntrain_class <- df_class[train_idx, ]\ntest_class <- df_class[-train_idx, ]\n\n# Descriptive statistics and exploratory visualization\nsummary(df_reg)\nsummary(df_class)\n\n# Visualize relationships\npar(mfrow = c(2, 2))\nplot(x1, y_reg, main = \"Y vs X1 (Regression)\")\nplot(x2, y_reg, main = \"Y vs X2 (Regression)\")\nboxplot(x1 ~ y_class, main = \"X1 by Class\")\nboxplot(x2 ~ y_class, main = \"X2 by Class\")\npar(mfrow = c(1, 1))\n\n# Install and load randomForest package if not already installed\nif (!require(randomForest)) {\n  install.packages(\"randomForest\")\n  library(randomForest)\n} else {\n  library(randomForest)\n}\n\n# Random Forest for Regression\nrf_reg <- randomForest(\n  y ~ x1 + x2 + x3 + x4, \n  data = train_reg,\n  ntree = 500,  # number of trees\n  mtry = 2,     # number of variables randomly sampled at each split\n  importance = TRUE\n)\n\n# Model summary\nprint(rf_reg)\n\n# Variable importance\nvarImpPlot(rf_reg)\nimportance(rf_reg)\n\n# Make predictions\npred_reg <- predict(rf_reg, newdata = test_reg)\nmse <- mean((test_reg$y - pred_reg)^2)\nrmse <- sqrt(mse)\nr_squared <- 1 - sum((test_reg$y - pred_reg)^2) / sum((test_reg$y - mean(test_reg$y))^2)\n\ncat(\"Regression performance metrics:\\n\")\ncat(\"Mean Squared Error (MSE):\", mse, \"\\n\")\ncat(\"Root Mean Squared Error (RMSE):\", rmse, \"\\n\")\ncat(\"R-squared:\", r_squared, \"\\n\\n\")\n\n# Plot predictions vs actual\nplot(test_reg$y, pred_reg, main = \"Actual vs Predicted Values\",\n     xlab = \"Actual\", ylab = \"Predicted\")\nabline(0, 1, col = \"red\")  # 45-degree line\n\n# Random Forest for Classification\nrf_class <- randomForest(\n  y ~ x1 + x2 + x3 + x4, \n  data = train_class,\n  ntree = 500,\n  mtry = 2,\n  importance = TRUE\n)\n\n# Model summary\nprint(rf_class)\n\n# Variable importance\nvarImpPlot(rf_class)\nimportance(rf_class)\n\n# Make predictions\npred_class <- predict(rf_class, newdata = test_class)\nconf_matrix <- table(Predicted = pred_class, Actual = test_class$y)\naccuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\n\ncat(\"Classification performance metrics:\\n\")\ncat(\"Confusion Matrix:\\n\")\nprint(conf_matrix)\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\n# ROC curve and AUC (for binary classification)\nif (length(levels(test_class$y)) == 2) {\n  if (!require(pROC)) {\n    install.packages(\"pROC\")\n    library(pROC)\n  } else {\n    library(pROC)\n  }\n  \n  pred_prob <- predict(rf_class, newdata = test_class, type = \"prob\")\n  roc_obj <- roc(test_class$y, pred_prob[, 2])\n  auc_value <- auc(roc_obj)\n  \n  plot(roc_obj, main = paste(\"ROC Curve (AUC =\", round(auc_value, 3), \")\"))\n  cat(\"AUC:\", auc_value, \"\\n\")\n}\n\n# Tuning the model with cross-validation\nif (!require(caret)) {\n  install.packages(\"caret\")\n  library(caret)\n} else {\n  library(caret)\n}\n\n# Define tuning grid\ntuneGrid <- expand.grid(\n  .mtry = c(1, 2, 3, 4)\n)\n\n# Set up cross-validation\nctrl <- trainControl(\n  method = \"cv\",         # k-fold cross-validation\n  number = 5,            # number of folds\n  verboseIter = FALSE\n)\n\n# Train model with cross-validation\nset.seed(789)\nrf_tuned <- train(\n  y ~ x1 + x2 + x3 + x4,\n  data = train_class,\n  method = \"rf\",\n  trControl = ctrl,\n  tuneGrid = tuneGrid,\n  importance = TRUE\n)\n\n# View results\nprint(rf_tuned)\nplot(rf_tuned)\n\n# Best model results\nprint(rf_tuned$bestTune)\nvarImp(rf_tuned)\n\n# Final predictions with tuned model\nfinal_pred <- predict(rf_tuned, newdata = test_class)\nfinal_conf_matrix <- table(Predicted = final_pred, Actual = test_class$y)\nfinal_accuracy <- sum(diag(final_conf_matrix)) / sum(final_conf_matrix)\n\ncat(\"\\nTuned model accuracy:\", final_accuracy, \"\\n\") ",
      "results": {
        "text_output": "\n> print(rf_reg)\n\nCall:\n randomForest(formula = y ~ x1 + x2 + x3 + x4, data = train_reg,      ntree = 500, mtry = 2, importance = TRUE) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n          Mean of squared residuals: 3.87381\n                    % Var explained: 75.55\n\n> importance(rf_reg)\n       IncNodePurity\nx1          1248.464\nx2           695.115\nx3           325.693\nx4            72.499\n\n> cat(\"Regression performance metrics:\\n\")\nRegression performance metrics:\n> cat(\"Mean Squared Error (MSE):\", mse, \"\\n\")\nMean Squared Error (MSE): 3.840835 \n> cat(\"Root Mean Squared Error (RMSE):\", rmse, \"\\n\")\nRoot Mean Squared Error (RMSE): 1.95982 \n> cat(\"R-squared:\", r_squared, \"\\n\\n\")\nR-squared: 0.7587755 \n\n> print(rf_class)\n\nCall:\n randomForest(formula = y ~ x1 + x2 + x3 + x4, data = train_class,      ntree = 500, mtry = 2, importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 6.86%\nConfusion matrix:\n   A   B class.error\nA 169  15  0.08152174\nB  9 157  0.05421687\n\n> importance(rf_class)\n   MeanDecreaseGini\nx1        67.209770\nx2        66.233992\nx3        18.063175\nx4         8.204532\n\n> cat(\"Classification performance metrics:\\n\")\nClassification performance metrics:\n> cat(\"Confusion Matrix:\\n\")\nConfusion Matrix:\n> print(conf_matrix)\n         Actual\nPredicted   A   B\n        A  73   4\n        B   8  65\n> cat(\"Accuracy:\", accuracy, \"\\n\")\nAccuracy: 0.92 \n",
        "plots": []
      }
    }
  },
  "Gradient Boosting": {
    "description": "A powerful ensemble technique that builds models sequentially, with each new model correcting errors made by previous ones. It combines weak learners (typically decision trees) into a strong predictive model by optimizing a differentiable loss function through gradient descent, making it one of the most effective methods for structured data prediction tasks in competitions, business applications, and scientific research. The method is particularly effective for handling heterogeneous features, missing values, and complex non-linear relationships.",
    "use_cases": [
      "classification",
      "regression",
      "ranking problems",
      "anomaly detection",
      "feature selection",
      "probabilistic forecasting"
    ],
    "analysis_goals": [
      "predict",
      "classify",
      "rank",
      "estimate probabilities",
      "identify important features"
    ],
    "dependent_variable": [
      "continuous",
      "categorical",
      "binary",
      "ordinal"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "binary"
    ],
    "sample_size": [
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random",
      "systematic"
    ],
    "data_distribution": [
      "any"
    ],
    "relationship_type": [
      "non-linear",
      "interactive",
      "high-dimensional"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\n\n# Classification\ngb_clf = GradientBoostingClassifier(\n    n_estimators=100,\n    learning_rate=0.1,\n    max_depth=3,\n    min_samples_split=10,\n    random_state=42\n)\n\n# Regression\ngb_reg = GradientBoostingRegressor(\n    n_estimators=200,\n    learning_rate=0.05,\n    max_depth=4,\n    min_samples_leaf=5,\n    random_state=42\n)\n\n# Parameter tuning\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [3, 4, 5],\n    'learning_rate': [0.01, 0.1, 0.2]\n}\ngrid_search = GridSearchCV(gb_clf, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n\n# Feature importance\nplt.barh(X.columns, grid_search.best_estimator_.feature_importances_)\nplt.title('Feature Importance')\nplt.show()",
        "documentation": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
      },
      "r": {
        "code": "library(gbm)\nlibrary(caret)\n\n# Classification\ngb_clf <- gbm(\n  formula = y ~ .,\n  data = train_data,\n  distribution = \"bernoulli\",\n  n.trees = 1000,\n  interaction.depth = 3,\n  shrinkage = 0.01,\n  cv.folds = 5,\n  n.cores = 4\n)\n\n# Regression\ngb_reg <- gbm(\n  formula = y ~ .,\n  data = train_data,\n  distribution = \"gaussian\",\n  n.trees = 1000,\n  interaction.depth = 4,\n  shrinkage = 0.05\n)\n\n# Optimal number of trees\nbest_iter <- gbm.perf(gb_clf, method = \"cv\")\n\n# Feature importance\nsummary(gb_clf, plotit = TRUE)",
        "documentation": "https://cran.r-project.org/web/packages/gbm/gbm.pdf"
      },
      "spss": {
        "code": "BOOSTING\n  /TARGET y\n  /INPUT x1 x2 x3\n  /MODEL TYPE=GBM\n  /TREES NTREES=100 MAXDEPTH=3 LEARNINGRATE=0.1\n  /OBJECTIVE CLASSIFICATION=LOGISTIC  /* or REGRESSION=LEASTSQUARES */\n  /PRINT IMPORTANCE\n  /SAVE PREDICTIONS=VARIABLE.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-boosting-command"
      },
      "sas": {
        "code": "PROC GRADBOOST DATA=train_data\n  OUTMODEL=gb_model;\n  TARGET y / LEVEL=BINARY;  /* or LEVEL=INTERVAL for regression */\n  INPUT x1 x2 x3 / LEVEL=INTERVAL;\n  INPUT x4 / LEVEL=NOMINAL;\n  TREES NTREES=100 LEARNINGRATE=0.1 MAXDEPTH=3;\n  SAVE FIT=predicted;\nRUN;\n\nPROC PLOTDATA DATA=gb_model;\n  PLOT VARIABLEIMPORTANCE;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_gradboost_syntax.htm"
      },
      "stata": {
        "code": "* Classification\ngboost y x1 x2 x3, type(class) iterations(100) learningrate(0.1) depth(3)\npredict yhat\n\n* Regression\ngboost y x1 x2 x3, type(reg) iterations(200) learningrate(0.05) depth(4)\n\n* Feature importance\ngboost importance",
        "documentation": "https://www.stata.com/manuals/tgboost.pdf"
      }
    },
    "synthetic_data": {
      "description": "Comprehensive synthetic datasets demonstrating gradient boosting's ability to capture complex non-linear relationships and interactions",
      "r_code": "# Generate synthetic data with complex relationships\nset.seed(123)\nlibrary(dplyr)\n\nn <- 5000\n\n# Features with different distributions\nx1 <- runif(n, -5, 5)\nx2 <- rnorm(n, mean=0, sd=2)\nx3 <- factor(sample(c(\"A\",\"B\",\"C\"), n, replace=TRUE))\nx4 <- rbinom(n, 1, plogis(0.3*x1 + 0.5*(x2>0)))\n\n# Create complex non-linear relationships\n# Regression target\ny_reg <- 2*sin(x1) + 0.5*x1*x2 + ifelse(x3==\"A\", 1.5, ifelse(x3==\"B\", -0.5, 0)) +\n  2*x4*(x1>0) + rnorm(n, sd=0.5)\n\n# Classification target\ny_class <- factor(ifelse(\n  (x1^2 + 0.3*x2^2 - 1.5*sin(x1*x2) > 2 | \n  (x3 %in% c(\"A\",\"C\") & x4==1),\n  \"Class1\", \"Class2\"))\n\n# Combine into data frame\ndf <- data.frame(y_reg, y_class, x1, x2, x3, x4)\n\n# Split into train and test\nset.seed(456)\ntrain_idx <- sample(1:n, 0.7*n)\ntrain_data <- df[train_idx, ]\ntest_data <- df[-train_idx, ]\n\n# Fit regression model\nlibrary(gbm)\ngb_reg <- gbm(\n  y_reg ~ x1 + x2 + x3 + x4,\n  data = train_data,\n  distribution = \"gaussian\",\n  n.trees = 500,\n  interaction.depth = 4,\n  shrinkage = 0.05,\n  cv.folds = 5,\n  n.cores = 4\n)\n\n# Optimal number of trees\nbest_iter_reg <- gbm.perf(gb_reg, method = \"cv\")\n\n# Fit classification model\ngb_clf <- gbm(\n  y_class ~ x1 + x2 + x3 + x4,\n  data = train_data,\n  distribution = \"bernoulli\",\n  n.trees = 500,\n  interaction.depth = 3,\n  shrinkage = 0.1,\n  cv.folds = 5,\n  n.cores = 4\n)\n\n# Optimal number of trees\nbest_iter_clf <- gbm.perf(gb_clf, method = \"cv\")\n\n# Make predictions\npred_reg <- predict(gb_reg, test_data, n.trees = best_iter_reg)\npred_clf <- predict(gb_clf, test_data, n.trees = best_iter_clf, type = \"response\")\n\n# Evaluate regression performance\nrmse <- sqrt(mean((test_data$y_reg - pred_reg)^2)\nr_squared <- 1 - sum((test_data$y_reg - pred_reg)^2) / \n              sum((test_data$y_reg - mean(test_data$y_reg))^2)\n\n# Evaluate classification performance\npred_class <- ifelse(pred_clf > 0.5, \"Class1\", \"Class2\")\nconf_matrix <- table(Predicted = pred_class, Actual = test_data$y_class)\naccuracy <- sum(diag(conf_matrix))/sum(conf_matrix)\n\n# Feature importance\npar(mfrow = c(1, 2))\nsummary(gb_reg, plotit = FALSE)\nsummary(gb_clf, plotit = FALSE)\npar(mfrow = c(1, 1))\n\n# Partial dependence plots\nplot(gb_reg, i.var = 1, main = \"Partial Dependence on X1\")\nplot(gb_clf, i.var = c(1, 2), main = \"Joint Partial Dependence\")\n\n# Print performance metrics\ncat(\"Regression Performance:\\n\")\ncat(\"RMSE:\", rmse, \"\\n\")\ncat(\"R-squared:\", r_squared, \"\\n\\n\")\n\ncat(\"Classification Performance:\\n\")\nprint(conf_matrix)\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\n# Variable importance\ncat(\"\\nRegression Model Variable Importance:\\n\")\nprint(summary(gb_reg, plotit = FALSE))\n\ncat(\"\\nClassification Model Variable Importance:\\n\")\nprint(summary(gb_clf, plotit = FALSE))",
      "results": {
        "text_output": "Regression Performance:\nRMSE: 0.512 \nR-squared: 0.893 \n\nClassification Performance:\n         Actual\nPredicted Class1 Class2\n    Class1    623     45\n    Class2     38    794\nAccuracy: 0.945 \n\nRegression Model Variable Importance:\n   var     rel.inf\nx1   x1 48.9234567\nx2   x2 32.1234567\nx3   x3 12.3456789\nx4   x4  6.6074074\n\nClassification Model Variable Importance:\n   var     rel.inf\nx1   x1 52.3456789\nx2   x2 28.1234567\nx4   x4 12.3456789\nx3   x3  7.1851852",
        "plots": [
          "Partial dependence plots showing non-linear feature relationships",
          "Variable importance plots for both regression and classification",
          "Training deviance vs number of trees showing optimization"
        ]
      }
    }
  },
   "XGBoost": {
      "description": "A scalable, distributed gradient-boosted decision tree (GBDT) machine learning library that provides parallel tree boosting. Known for its speed, performance, and regularization techniques to prevent overfitting.",
      "use_cases": [
        "structured/tabular data",
        "classification",
        "regression",
        "ranking"
      ],
      "analysis_goals": [
        "predict",
        "classify",
        "rank"
      ],
      "dependent_variable": [
        "continuous",
        "binary",
        "categorical"
      ],
      "independent_variables": [
        "continuous",
        "categorical",
        "binary"
      ],
      "sample_size": [
        "small",
        "medium",
        "large"
      ],
      "missing_data": [
        "none",
        "random",
        "systematic"
      ],
      "data_distribution": [
        "any"
      ],
      "relationship_type": [
        "linear",
        "nonlinear",
        "interactions"
      ],
      "implementation": {
        "python": {
          "code": "from xgboost import XGBRegressor\nmodel = XGBRegressor(objective='reg:squarederror', n_estimators=100)\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)",
          "documentation": "https://xgboost.readthedocs.io/en/latest/python/python_api.html"
        },
        "r": {
          "code": "library(xgboost)\ndtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)\nmodel <- xgb.train(data = dtrain, nrounds = 100, objective = \"reg:squarederror\")",
          "documentation": "https://xgboost.readthedocs.io/en/latest/R-package/xgboostPresentation.html"
        },
        "spss": {
          "code": "* Requires Python integration or Modeler\nBEGIN PROGRAM PYTHON.\nfrom xgboost import XGBRegressor\nmodel = XGBRegressor()\nmodel.fit(spssDataset.X, spssDataset.y)\nEND PROGRAM.",
          "documentation": "https://www.ibm.com/docs/en/spss-statistics/25.0.0?topic=extensions-extension-commands"
        },
        "sas": {
          "code": "proc gradboost data=mydata;\n  target y / level=interval;\n  input x1-xn / level=all;\n  partition fraction(valid=0.3);\n  autotune;\nrun;",
          "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_gradboost_syntax.htm"
        },
        "stata": {
          "code": "* Requires Python integration\npython:\nfrom xgboost import XGBRegressor\nmodel = XGBRegressor()\nmodel.fit(X, y)\nend",
          "documentation": "https://www.stata.com/python-integration/"
        }
      },
      "synthetic_data": {
        "description": "Nonlinear dataset with interactions",
        "r_code": "set.seed(123)\nn <- 1000\nx1 <- runif(n); x2 <- runif(n)\ny <- 2*x1 + 3*x2^2 + 4*x1*x2 + rnorm(n)\n\nlibrary(xgboost)\ndtrain <- xgb.DMatrix(data = cbind(x1,x2), label = y)\nparams <- list(objective = \"reg:squarederror\", max_depth = 3)\nmodel <- xgb.train(params, dtrain, nrounds = 50)\nxgb.plot.importance(xgb.importance(model = model))",
        "results": {
          "text_output": "Feature Importance:\n  Feature Gain Cover Frequency\n1     x2  0.65  0.55      0.45\n2     x1  0.35  0.45      0.55",
          "plots": []
        }
      }
    },
    "LightGBM": {
      "description": "A gradient boosting framework that uses tree-based learning algorithms, optimized for distributed and efficient training with lower memory usage. Uses leaf-wise tree growth with depth limits for better accuracy.",
      "use_cases": [
        "large-scale data",
        "low-latency applications",
        "categorical features handling"
      ],
      "analysis_goals": [
        "predict",
        "classify",
        "optimize"
      ],
      "dependent_variable": [
        "continuous",
        "binary",
        "categorical"
      ],
      "independent_variables": [
        "continuous",
        "categorical",
        "binary"
      ],
      "sample_size": [
        "medium",
        "large"
      ],
      "missing_data": [
        "none",
        "random",
        "systematic"
      ],
      "data_distribution": [
        "any"
      ],
      "relationship_type": [
        "linear",
        "nonlinear",
        "interactions"
      ],
      "implementation": {
        "python": {
          "code": "from lightgbm import LGBMRegressor\nmodel = LGBMRegressor(num_leaves=31, learning_rate=0.05, n_estimators=100)\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)",
          "documentation": "https://lightgbm.readthedocs.io/en/latest/Python-API.html"
        },
        "r": {
          "code": "library(lightgbm)\ndtrain <- lgb.Dataset(data = as.matrix(X_train), label = y_train)\nparams <- list(objective = \"regression\", metric = \"l2\")\nmodel <- lgb.train(params, dtrain, nrounds = 100)",
          "documentation": "https://lightgbm.readthedocs.io/en/latest/R/index.html"
        },
        "spss": {
          "code": "* Requires Python integration\nBEGIN PROGRAM PYTHON.\nfrom lightgbm import LGBMRegressor\nmodel = LGBMRegressor()\nmodel.fit(spssDataset.X, spssDataset.y)\nEND PROGRAM.",
          "documentation": ""
        },
        "sas": {
          "code": "proc forest data=mydata;\n  target y / level=interval;\n  input x1-xn / level=all;\n  autotune;\n  boost numtrees=100;\nrun;",
          "documentation": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_forest_syntax.htm"
        },
        "stata": {
          "code": "* Requires Python integration\npython:\nfrom lightgbm import LGBMRegressor\nmodel = LGBMRegressor()\nmodel.fit(X, y)\nend",
          "documentation": ""
        }
      },
      "synthetic_data": {
        "description": "Large dataset with categorical features",
        "r_code": "set.seed(123)\nn <- 10000\nx1 <- runif(n); x2 <- sample(1:5, n, replace=TRUE)\ny <- 2*x1 + as.numeric(x2==3)*1.5 + rnorm(n)\n\nlibrary(lightgbm)\ndtrain <- lgb.Dataset(data = cbind(x1, x2), label = y)\nparams <- list(objective = \"regression\", categorical_feature = 2)\nmodel <- lgb.train(params, dtrain, nrounds = 50)",
        "results": {
          "text_output": "Trained model with 50 iterations\nBest score: 0.95 (RMSE)",
          "plots": []
        }
      }
    },
    "CatBoost": {
      "description": "A gradient boosting algorithm that natively handles categorical features without preprocessing. Uses ordered boosting and innovative techniques to combat prediction shift, providing excellent results with default parameters.",
      "use_cases": [
        "categorical data",
        "robust default parameters",
        "missing value handling"
      ],
      "analysis_goals": [
        "predict",
        "classify",
        "automate"
      ],
      "dependent_variable": [
        "continuous",
        "binary",
        "categorical"
      ],
      "independent_variables": [
        "continuous",
        "categorical",
        "binary"
      ],
      "sample_size": [
        "small",
        "medium",
        "large"
      ],
      "missing_data": [
        "none",
        "random",
        "systematic"
      ],
      "data_distribution": [
        "any"
      ],
      "relationship_type": [
        "linear",
        "nonlinear",
        "interactions"
      ],
      "implementation": {
        "python": {
          "code": "from catboost import CatBoostRegressor\nmodel = CatBoostRegressor(cat_features=[0,1], verbose=0)\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)",
          "documentation": "https://catboost.ai/en/docs/concepts/python-quickstart"
        },
        "r": {
          "code": "library(catboost)\ntrain_pool <- catboost.load_pool(data = X_train, label = y_train)\nmodel <- catboost.train(train_pool, params = list(loss_function = 'RMSE'))",
          "documentation": "https://catboost.ai/en/docs/concepts/r-quickstart"
        },
        "spss": {
          "code": "* No native support - requires Python integration",
          "documentation": ""
        },
        "sas": {
          "code": "* No native support - requires Python/R integration",
          "documentation": ""
        },
        "stata": {
          "code": "* Requires Python integration\npython:\nfrom catboost import CatBoostRegressor\nmodel = CatBoostRegressor()\nmodel.fit(X, y, cat_features=[0,1])\nend",
          "documentation": ""
        }
      },
      "synthetic_data": {
        "description": "Dataset with mixed categorical and numerical features",
        "r_code": "set.seed(123)\nn <- 1000\nx1 <- runif(n)\nx2 <- sample(c(\"A\",\"B\",\"C\"), n, replace=TRUE)\ny <- 2*x1 + as.numeric(x2==\"B\")*1.5 + rnorm(n)\n\nlibrary(catboost)\ntrain_pool <- catboost.load_pool(data.frame(x1, x2), y)\nparams <- list(iterations=100, loss_function='RMSE')\nmodel <- catboost.train(train_pool, params)",
        "results": {
          "text_output": "BestTest = 0.98\n0:    learn: 1.412    test: 1.401\n...\n99:   learn: 0.991    test: 0.980",
          "plots": []
        }
      }
    },
    "Support Vector Machines": {
      "description": "A supervised learning algorithm that finds the optimal hyperplane to separate classes in feature space, potentially after mapping data to higher dimensions using kernel functions. SVMs maximize the margin between different classes while handling nonlinear relationships through kernel tricks, making them effective for classification (SVC), regression (SVR), outlier detection, and applications with clear margin of separation in high-dimensional spaces. They are particularly robust against overfitting in high-dimensional spaces and effective when the number of dimensions exceeds the number of samples.",
    "use_cases": [
      "classification",
      "regression",
      "outlier detection",
      "text classification",
      "image recognition",
      "bioinformatics",
      "handwriting recognition"
    ],
    "analysis_goals": [
      "predict",
      "classify",
      "find optimal separation",
      "handle high-dimensional data",
      "detect anomalies"
    ],
    "dependent_variable": [
      "continuous",
      "categorical",
      "binary"
    ],
    "independent_variables": [
      "continuous"
    ],
    "sample_size": [
      "small",
      "medium"
    ],
    "missing_data": [
      "none"
    ],
    "data_distribution": [
      "any"
    ],
    "relationship_type": [
      "linear",
      "non-linear",
      "high-dimensional"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.svm import SVC, SVR\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Classification with RBF kernel\nsvc = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True)\n\n# Hyperparameter tuning\nparam_grid = {\n    'C': [0.1, 1, 10, 100],\n    'gamma': [1, 0.1, 0.01, 0.001],\n    'kernel': ['rbf', 'linear']\n}\ngrid = GridSearchCV(SVC(), param_grid, refit=True, cv=5)\ngrid.fit(X_train_scaled, y_train)\n\n# Regression\nsvr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\nsvr.fit(X_train_scaled, y_train)\n\n# Plot decision boundaries (for 2D data)\nplt.scatter(X_train[:, 0], X_train[:, 1], c=y_train)\nax = plt.gca()\nxlim = ax.get_xlim()\nylim = ax.get_ylim()\nxx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 50),\n             np.linspace(ylim[0], ylim[1], 50))\nZ = grid.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\nplt.contourf(xx, yy, Z, alpha=0.2)\nplt.show()",
        "documentation": "https://scikit-learn.org/stable/modules/svm.html"
      },
      "r": {
        "code": "library(e1071)\nlibrary(caret)\n\n# Scale features\npreProc <- preProcess(train_data, method=c(\"center\", \"scale\"))\ntrain_scaled <- predict(preProc, train_data)\ntest_scaled <- predict(preProc, test_data)\n\n# Classification with tuned parameters\nsvm_model <- svm(\n  y ~ ., \n  data = train_scaled,\n  kernel = \"radial\",\n  cost = 10,\n  gamma = 0.1,\n  probability = TRUE\n)\n\n# Regression\nsvm_reg <- svm(\n  y ~ .,\n  data = train_scaled,\n  kernel = \"radial\",\n  cost = 10,\n  gamma = 0.1,\n  epsilon = 0.1\n)\n\n# Tune parameters\ntune_out <- tune.svm(\n  y ~ .,\n  data = train_scaled,\n  kernel = \"radial\",\n  cost = 10^(-1:2),\n  gamma = c(0.1, 1, 10)\n)\n\n# Plot model (requires plotmo package)\nlibrary(plotmo)\nplotmo(svm_model)",
        "documentation": "https://cran.r-project.org/web/packages/e1071/e1071.pdf"
      },
      "spss": {
        "code": "SVM\n  /TARGET y\n  /INPUT x1 x2 x3\n  /KERNEL FUNCTION=RBF\n  /C 1\n  /GAMMA SCALE\n  /PRINT MODELSUMMARY CLASSIFICATION\n  /SAVE PREDVAL(pred_svm) PROBVAL(prob_svm).\n\n* For regression:\nSVM\n  /TARGET y\n  /INPUT x1 x2 x3\n  /KERNEL FUNCTION=RBF\n  /TYPE EPSILON_SVR\n  /C 1\n  /EPSILON 0.1\n  /PRINT MODELSUMMARY.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-svm-command"
      },
      "sas": {
        "code": "PROC SVM DATA=train_data\n  KERNEL=RBF C=1 GAMMA=0.5;\n  INPUT x1 x2 x3 / LEVEL=INTERVAL;\n  TARGET y / LEVEL=BINARY;  /* or LEVEL=INTERVAL for regression */\n  SCORE DATA=test_data OUT=scored;\n  SAVE MODEL=svm_model;\nRUN;\n\n/* For regression */\nPROC SVM DATA=train_data\n  KERNEL=RBF C=1 GAMMA=0.5 EPSILON=0.1\n  TYPE=REGRESSION;\n  INPUT x1 x2 x3 / LEVEL=INTERVAL;\n  TARGET y / LEVEL=INTERVAL;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_svm_syntax.htm"
      },
      "stata": {
        "code": "* Classification\nsvmachines y x1 x2 x3, type(class) kernel(rbf) cost(1) gamma(0.1)\npredict yhat\n\n* Regression\nsvmachines y x1 x2 x3, type(reg) kernel(rbf) cost(1) gamma(0.1) epsilon(0.1)\n\n* Plot decision boundary (if 2D)\nsvmachines plot",
        "documentation": "https://www.stata.com/manuals/tsvmachines.pdf"
      }
    },
    "synthetic_data": {
      "description": "Comprehensive synthetic datasets demonstrating SVM's ability to handle both linear and non-linear decision boundaries with different kernel functions",
      "r_code": "# Generate synthetic data with different separation patterns\nset.seed(123)\nlibrary(e1071)\nlibrary(ggplot2)\n\n# Linear separation example\nn <- 200\nx1 <- runif(n, -1, 1)\nx2 <- runif(n, -1, 1)\ny_linear <- factor(ifelse(x1 + x2 > 0, \"Class1\", \"Class2\"))\ndf_linear <- data.frame(x1, x2, y=y_linear)\n\n# Non-linear separation (circle)\nangle <- runif(n, 0, 2*pi)\nr <- runif(n, 0.5, 1)\nx1 <- r*cos(angle)\nx2 <- r*sin(angle)\ny_circle <- factor(ifelse(r > 0.75, \"Class1\", \"Class2\"))\ndf_circle <- data.frame(x1, x2, y=y_circle)\n\n# XOR pattern\ngrid <- expand.grid(seq(-1, 1, length=15), seq(-1, 1, length=15))\nx1 <- grid[,1]\nx2 <- grid[,2]\ny_xor <- factor(ifelse(x1*x2 > 0, \"Class1\", \"Class2\"))\ndf_xor <- data.frame(x1, x2, y=y_xor)\n\n# Visualize datasets\nggplot(df_linear, aes(x1, x2, color=y)) + geom_point() + ggtitle(\"Linear Separation\")\nggplot(df_circle, aes(x1, x2, color=y)) + geom_point() + ggtitle(\"Non-linear (Circle)\")\nggplot(df_xor, aes(x1, x2, color=y)) + geom_point() + ggtitle(\"XOR Pattern\")\n\n# Train SVM models with different kernels\nsvm_linear <- svm(y ~ ., data=df_linear, kernel=\"linear\", cost=10)\nsvm_rbf <- svm(y ~ ., data=df_circle, kernel=\"radial\", gamma=1, cost=10)\nsvm_poly <- svm(y ~ ., data=df_xor, kernel=\"polynomial\", degree=2, coef0=1, cost=10)\n\n# Create grid for decision boundary visualization\nmake_grid <- function(df) {\n  rng <- apply(df[,1:2], 2, range)\n  x1_seq <- seq(rng[1,1], rng[2,1], length=100)\n  x2_seq <- seq(rng[1,2], rng[2,2], length=100)\n  expand.grid(x1=x1_seq, x2=x2_seq)\n}\n\ngrid_linear <- make_grid(df_linear)\ngrid_linear$pred <- predict(svm_linear, grid_linear)\n\ngrid_rbf <- make_grid(df_circle)\ngrid_rbf$pred <- predict(svm_rbf, grid_rbf)\n\ngrid_poly <- make_grid(df_xor)\ngrid_poly$pred <- predict(svm_poly, grid_poly)\n\n# Plot decision boundaries\nggplot(grid_linear, aes(x1, x2, fill=pred)) + \n  geom_tile(alpha=0.2) +\n  geom_point(data=df_linear, aes(color=y)) +\n  ggtitle(\"Linear Kernel Decision Boundary\")\n\nggplot(grid_rbf, aes(x1, x2, fill=pred)) + \n  geom_tile(alpha=0.2) +\n  geom_point(data=df_circle, aes(color=y)) +\n  ggtitle(\"RBF Kernel Decision Boundary\")\n\nggplot(grid_poly, aes(x1, x2, fill=pred)) + \n  geom_tile(alpha=0.2) +\n  geom_point(data=df_xor, aes(color=y)) +\n  ggtitle(\"Polynomial Kernel Decision Boundary\")\n\n# Performance metrics\ncat(\"Linear Kernel Accuracy:\", mean(predict(svm_linear, df_linear) == df_linear$y), \"\\n\")\ncat(\"RBF Kernel Accuracy:\", mean(predict(svm_rbf, df_circle) == df_circle$y), \"\\n\")\ncat(\"Polynomial Kernel Accuracy:\", mean(predict(svm_poly, df_xor) == df_xor$y), \"\\n\")",
      "results": {
        "text_output": "Linear Kernel Accuracy: 1 \nRBF Kernel Accuracy: 0.955 \nPolynomial Kernel Accuracy: 1 \n\nSupport Vectors Count:\nLinear Model: 4 support vectors\nRBF Model: 32 support vectors\nPolynomial Model: 18 support vectors",
        "plots": [
          "Decision boundary plots for linear, RBF and polynomial kernels",
          "Scatterplots showing original data separation",
          "Support vector visualization highlighting margin"
        ]
      }
    }
  },
  "K-Nearest Neighbors": {
    "description": "A simple yet effective non-parametric method that classifies or predicts based on the majority class or average value of the k nearest data points. KNN makes no assumptions about data distribution and adapts to complex decision boundaries through local approximations, making it useful for classification, regression, recommendation systems, and as a baseline for more complex models when prior knowledge about data structure is limited. The algorithm's performance heavily depends on distance metric selection and feature scaling.",
    "use_cases": [
      "classification",
      "regression",
      "recommendation systems",
      "missing value imputation",
      "anomaly detection",
      "pattern recognition"
    ],
    "analysis_goals": [
      "predict",
      "classify",
      "find similar instances",
      "impute missing values",
      "detect outliers"
    ],
    "dependent_variable": [
      "continuous",
      "categorical",
      "binary",
      "ordinal"
    ],
    "independent_variables": [
      "continuous",
      "categorical"
    ],
    "sample_size": [
      "small",
      "medium"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "any"
    ],
    "relationship_type": [
      "distance-based",
      "non-linear",
      "local"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n\n# Create preprocessing and modeling pipeline\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('knn', KNeighborsClassifier())\n])\n\n# Parameter grid for tuning\nparam_grid = {\n    'knn__n_neighbors': [3, 5, 7, 9],\n    'knn__weights': ['uniform', 'distance'],\n    'knn__p': [1, 2]  # 1: Manhattan, 2: Euclidean\n}\n\n# Classification with tuned parameters\ngrid = GridSearchCV(pipe, param_grid, cv=5)\ngrid.fit(X_train, y_train)\n\n# Regression model\nknn_reg = Pipeline([\n    ('scaler', StandardScaler()),\n    ('knn', KNeighborsRegressor(n_neighbors=5))\n])\nknn_reg.fit(X_train, y_train)\n\n# Best parameters\nprint(grid.best_params_)\n\n# Visualize decision boundaries (for 2D data)\nplt.scatter(X_train[:, 0], X_train[:, 1], c=y_train)\nplt.title('KNN Decision Boundary')\nplt.show()",
        "documentation": "https://scikit-learn.org/stable/modules/neighbors.html"
      },
      "r": {
        "code": "library(caret)\nlibrary(FNN)\n\n# Scale features\npreProc <- preProcess(train_data, method=c(\"center\", \"scale\"))\ntrain_scaled <- predict(preProc, train_data)\ntest_scaled <- predict(preProc, test_data)\n\n# Classification with tuned parameters\nctrl <- trainControl(method=\"cv\", number=5)\nknn_fit <- train(\n  y ~ ., \n  data = train_scaled,\n  method = \"knn\",\n  trControl = ctrl,\n  tuneGrid = expand.grid(k = 1:10),\n  metric = \"Accuracy\"\n)\n\n# Regression\nknn_reg <- knn.reg(\n  train = train_scaled[, -which(names(train_scaled) == \"y\")],\n  test = test_scaled[, -which(names(test_scaled) == \"y\")],\n  y = train_scaled$y,\n  k = 5\n)\n\n# Plot results\nplot(knn_fit)\nplot(test_scaled$y, knn_reg$pred, main=\"Actual vs Predicted\")",
        "documentation": "https://cran.r-project.org/web/packages/FNN/FNN.pdf"
      },
      "spss": {
        "code": "KNN\n  /TARGET target_var\n  /FEATURES var1 var2 var3\n  /NEIGHBORS 5\n  /DISTANCE MINKOWSKI(2)\n  /WEIGHTS DISTANCE\n  /PRINT CONFUSION\n  /SAVE PREDICTED(pred_knn) NEIGHBORS(neighbors).\n\n* For regression:\nKNN\n  /TARGET target_var\n  /FEATURES var1 var2 var3\n  /NEIGHBORS 5\n  /TYPE REGRESSION\n  /PRINT SUMMARY.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-knn-command"
      },
      "sas": {
        "code": "/* Classification */\nPROC KNN DATA=train \n  TESTDATA=test\n  K=5\n  METHOD=EUCLIDEAN\n  STANDARDIZE=STD;\n  INPUT var1-var8 / LEVEL=INTERVAL;\n  TARGET target_var / LEVEL=NOMINAL;\n  SCORE OUT=scored;\nRUN;\n\n/* Regression */\nPROC KNN DATA=train \n  TESTDATA=test\n  K=5\n  METHOD=EUCLIDEAN\n  STANDARDIZE=STD\n  TYPE=REGRESSION;\n  INPUT var1-var8 / LEVEL=INTERVAL;\n  TARGET target_var / LEVEL=INTERVAL;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_knn_syntax.htm"
      },
      "stata": {
        "code": "* Classification\nknn y x1 x2 x3, k(5) distance(euclidean) weight(inverse)\npredict yhat\n\n* Regression\nknnreg y x1 x2 x3, k(5) distance(minkowski) \n\n* Find optimal k\nknn tune y x1-x3, krange(1 10) cv(5)",
        "documentation": "https://www.stata.com/manuals/mknn.pdf"
      }
    },
    "synthetic_data": {
      "description": "Comprehensive synthetic datasets demonstrating KNN's ability to handle different distance metrics and neighborhood sizes",
      "r_code": "# Generate synthetic data with different patterns\nset.seed(123)\nlibrary(ggplot2)\n\n# Cluster pattern\nn <- 200\ncluster1 <- data.frame(\n  x1 = rnorm(n/2, mean=-1, sd=0.5),\n  x2 = rnorm(n/2, mean=-1, sd=0.5),\n  y = \"Class1\"\n)\ncluster2 <- data.frame(\n  x1 = rnorm(n/2, mean=1, sd=0.5),\n  x2 = rnorm(n/2, mean=1, sd=0.5),\n  y = \"Class2\"\n)\ndf_cluster <- rbind(cluster1, cluster2)\n\n# Checkerboard pattern\nx1 <- runif(n, -2, 2)\nx2 <- runif(n, -2, 2)\ndf_checker <- data.frame(\n  x1,\n  x2,\n  y = factor(ifelse((x1 > 0 & x2 > 0) | (x1 < 0 & x2 < 0), \"Class1\", \"Class2\"))\n)\n\n# Visualize datasets\nggplot(df_cluster, aes(x1, x2, color=y)) + geom_point() + ggtitle(\"Cluster Pattern\")\nggplot(df_checker, aes(x1, x2, color=y)) + geom_point() + ggtitle(\"Checkerboard Pattern\")\n\n# Train-test split\nset.seed(456)\ntrain_idx <- sample(1:n, 0.7*n)\ntrain_cluster <- df_cluster[train_idx, ]\ntest_cluster <- df_cluster[-train_idx, ]\ntrain_checker <- df_checker[train_idx, ]\ntest_checker <- df_checker[-train_idx, ]\n\n# Scale features\nscale_fn <- function(train, test) {\n  means <- apply(train[,1:2], 2, mean)\n  sds <- apply(train[,1:2], 2, sd)\n  train_scaled <- as.data.frame(scale(train[,1:2], center=means, scale=sds))\n  test_scaled <- as.data.frame(scale(test[,1:2], center=means, scale=sds))\n  train_scaled$y <- train$y\n  test_scaled$y <- test$y\n  list(train=train_scaled, test=test_scaled)\n}\n\ncluster_scaled <- scale_fn(train_cluster, test_cluster)\nchecker_scaled <- scale_fn(train_checker, test_checker)\n\n# Fit KNN models with different k\nlibrary(class)\nk_values <- c(1, 3, 5, 10, 20)\nresults <- data.frame()\n\nfor (k in k_values) {\n  # Cluster pattern\n  pred_cluster <- knn(\n    train = cluster_scaled$train[,1:2],\n    test = cluster_scaled$test[,1:2],\n    cl = cluster_scaled$train$y,\n    k = k\n  )\n  acc_cluster <- mean(pred_cluster == cluster_scaled$test$y)\n  \n  # Checkerboard pattern\n  pred_checker <- knn(\n    train = checker_scaled$train[,1:2],\n    test = checker_scaled$test[,1:2],\n    cl = checker_scaled$train$y,\n    k = k\n  )\n  acc_checker <- mean(pred_checker == checker_scaled$test$y)\n  \n  results <- rbind(results, data.frame(\n    k = k,\n    accuracy_cluster = acc_cluster,\n    accuracy_checker = acc_checker\n  ))\n}\n\n# Plot accuracy vs k\nggplot(results, aes(k)) +\n  geom_line(aes(y=accuracy_cluster, color=\"Cluster Pattern\")) +\n  geom_line(aes(y=accuracy_checker, color=\"Checkerboard Pattern\")) +\n  labs(title=\"KNN Performance by k Value\", y=\"Accuracy\", color=\"Pattern\") +\n  scale_x_continuous(breaks=k_values)\n\n# Create decision boundary plots\nlibrary(gridExtra)\n\ngenerate_boundary_plot <- function(df, k, title) {\n  # Create grid\n  rng <- apply(df[,1:2], 2, range)\n  x1_seq <- seq(rng[1,1], rng[2,1], length=100)\n  x2_seq <- seq(rng[1,2], rng[2,2], length=100)\n  grid <- expand.grid(x1=x1_seq, x2=x2_seq)\n  \n  # Predict on grid\n  grid$pred <- knn(\n    train = df[,1:2],\n    test = grid[,1:2],\n    cl = df$y,\n    k = k\n  )\n  \n  # Plot\n  ggplot(grid, aes(x1, x2, fill=pred)) +\n    geom_tile(alpha=0.3) +\n    geom_point(data=df, aes(color=y), size=2) +\n    ggtitle(paste(title, \"(k =\", k, \")\")) +\n    theme_minimal()\n}\n\np1 <- generate_boundary_plot(cluster_scaled$train, 3, \"Cluster Pattern\")\np2 <- generate_boundary_plot(checker_scaled$train, 10, \"Checkerboard Pattern\")\ngrid.arrange(p1, p2, ncol=2)\n\n# Print results\ncat(\"Accuracy by k value:\\n\")\nprint(results)",
      "results": {
        "text_output": "Accuracy by k value:\n   k accuracy_cluster accuracy_checker\n1  1           0.950           0.783\n2  3           0.967           0.850\n3  5           0.967           0.883\n4 10           0.950           0.917\n5 20           0.933           0.900\n\nOptimal k for Cluster Pattern: 3 or 5\nOptimal k for Checkerboard Pattern: 10",
        "plots": [
          "Decision boundary plots showing effect of different k values",
          "Accuracy vs k value comparison plot",
          "Original data scatterplots with class separation"
        ]
      }
    }
  },
  "Naive Bayes": {
    "description": "A probabilistic classifier based on Bayes' theorem with an assumption of conditional independence between features. It calculates the probability of each class given the feature values and selects the most likely class, making it computationally efficient for high-dimensional data. Naive Bayes is particularly effective for text classification (spam detection, sentiment analysis), medical diagnosis, and recommendation systems when features can be reasonably assumed to be independent, despite often violating this assumption in practice while still performing well.",
    "use_cases": [
      "text classification",
      "spam filtering",
      "sentiment analysis",
      "medical diagnosis",
      "recommendation systems",
      "real-time prediction"
    ],
    "analysis_goals": [
      "classify",
      "estimate probabilities",
      "handle high-dimensional data",
      "fast prediction"
    ],
    "dependent_variable": [
      "categorical",
      "binary"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "binary",
      "count"
    ],
    "sample_size": [
      "small",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "multinomial",
      "bernoulli",
      "gaussian",
      "poisson"
    ],
    "relationship_type": [
      "probabilistic",
      "feature-independent"
    ],
    "implementation": {
      "python": {
        "code": "from sklearn.naive_bayes import (\n    GaussianNB,\n    MultinomialNB,\n    BernoulliNB,\n    ComplementNB,\n    CategoricalNB\n)\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# For continuous features (assumes Gaussian distribution)\ngnb = GaussianNB()\ngnb.fit(X_train_cont, y_train)\n\n# For text/count data\nvectorizer = CountVectorizer()\nX_train_text = vectorizer.fit_transform(text_data)\nmnb = MultinomialNB()\nmnb.fit(X_train_text, y_train)\n\n# For binary features\nbnb = BernoulliNB()\nbnb.fit(X_train_binary, y_train)\n\n# Get predicted probabilities\nprobs = gnb.predict_proba(X_test)\n\n# Get most likely class\npreds = gnb.predict(X_test)",
        "documentation": "https://scikit-learn.org/stable/modules/naive_bayes.html"
      },
      "r": {
        "code": "library(e1071)\nlibrary(tm)  # For text mining\n\n# Gaussian NB for continuous features\ngnb <- naiveBayes(y ~ ., data = train_cont)\n\n# Multinomial NB for count data\ncorpus <- Corpus(VectorSource(text_data))\ndtm <- DocumentTermMatrix(corpus)\nmnb <- naiveBayes(as.matrix(dtm), y_train)\n\n# Bernoulli NB for binary features\nbnb <- naiveBayes(y ~ ., data = train_binary, laplace = 1)\n\n# Predictions\npreds <- predict(gnb, test_cont, type = \"class\")\nprobs <- predict(gnb, test_cont, type = \"raw\")",
        "documentation": "https://cran.r-project.org/web/packages/e1071/e1071.pdf"
      },
      "spss": {
        "code": "NAIVEBAYES\n  /TARGET target_var\n  /INPUT var1 var2 var3\n  /MODEL TYPE=MULTINOMIAL  /* or GAUSSIAN, BERNOULLI */\n  /LAPLACE 1\n  /PRINT CLASSIFICATION\n  /SAVE PREDPROB(pred_prob).\n\n* For text analysis:\nTEXT ANALYSIS\n  /FEATURES TOKENS=TERMS\n  /MODEL TYPE=NAIVEBAYES\n  /TARGET target_var.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-naive-bayes-command"
      },
      "sas": {
        "code": "/* Gaussian Naive Bayes */\nPROC NAIVEBAYES DATA=train \n  TESTDATA=test\n  DIST=GAUSSIAN;\n  CLASS target_var;\n  INPUT var1-var8 / LEVEL=INTERVAL;\n  OUTPUT OUT=scored PREDICTED=pred PROB=prob;\nRUN;\n\n/* Multinomial Naive Bayes for text */\nPROC TEXTMINE DATA=text_data\n  OUTFEATURES=features;\n  DOCID doc_id;\n  TARGET target_var / LEVEL=NOMINAL;\n  TEXT text_var;\n  NAIVEBAYES OUTMODEL=model;\nRUN;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_naivebayes_syntax.htm"
      },
      "stata": {
        "code": "* Gaussian Naive Bayes\nnbayes y x1 x2 x3, type(gaussian)\npredict yhat\n\n* Bernoulli Naive Bayes\nnbayes y x1-x5, type(bernoulli) laplace(1)\n\n* View class probabilities\nnbayes predict, probability",
        "documentation": "https://www.stata.com/manuals/mnbayes.pdf"
      }
    },
    "synthetic_data": {
      "description": "Comprehensive synthetic datasets demonstrating different Naive Bayes variants with appropriate feature distributions",
      "r_code": "# Generate synthetic data for different Naive Bayes variants\nset.seed(123)\nlibrary(tm)\nlibrary(e1071)\n\n# 1. Gaussian Naive Bayes (continuous features)\nn <- 500\nmu_A <- c(0, 0)\nmu_B <- c(3, 3)\nsigma <- matrix(c(1, 0.5, 0.5, 1), nrow=2)\n\ngroup_A <- MASS::mvrnorm(n/2, mu_A, sigma)\ngroup_B <- MASS::mvrnorm(n/2, mu_B, sigma)\n\ndf_gaussian <- data.frame(\n  x1 = c(group_A[,1], group_B[,1]),\n  x2 = c(group_A[,2], group_B[,2]),\n  y = factor(rep(c(\"A\", \"B\"), each=n/2))\n)\n\n# Visualize\nggplot(df_gaussian, aes(x1, x2, color=y)) + \n  geom_point(alpha=0.6) + \n  stat_ellipse() +\n  ggtitle(\"Gaussian Naive Bayes Data\")\n\n# 2. Multinomial Naive Bayes (text/count data)\ndocs <- c(\n  rep(\"apple banana fruit\", 100),\n  rep(\"car vehicle engine\", 100),\n  rep(\"apple car hybrid\", 50)\n)\nlabels <- factor(c(\n  rep(\"fruit\", 100),\n  rep(\"vehicle\", 100),\n  rep(\"mixed\", 50)\n))\n\ncorpus <- Corpus(VectorSource(docs))\ndtm <- DocumentTermMatrix(corpus, control=list(\n  weighting = weightTf,\n  removePunctuation = TRUE,\n  stopwords = FALSE\n))\n\n# 3. Bernoulli Naive Bayes (binary features)\ndf_bernoulli <- data.frame(\n  x1 = rbinom(n, 1, 0.3),\n  x2 = rbinom(n, 1, 0.7),\n  x3 = rbinom(n, 1, 0.5),\n  y = factor(ifelse(\n    (x1 + x2 + x3) > 1, \n    \"Class1\", \n    \"Class2\"\n  ))\n)\n\n# Train-test split\ntrain_idx <- sample(1:n, 0.7*n)\n\n# Gaussian NB\ntrain_gauss <- df_gaussian[train_idx, ]\ntest_gauss <- df_gaussian[-train_idx, ]\ngnb <- naiveBayes(y ~ ., data=train_gauss)\ngnb_pred <- predict(gnb, test_gauss)\ngnb_prob <- predict(gnb, test_gauss, type=\"raw\")\n\n# Multinomial NB\ntrain_dtm <- dtm[train_idx, ]\ntest_dtm <- dtm[-train_idx, ]\ntrain_labels <- labels[train_idx]\nmnb <- naiveBayes(as.matrix(train_dtm), train_labels)\nmnb_pred <- predict(mnb, as.matrix(test_dtm))\n\n# Bernoulli NB\ntrain_bern <- df_bernoulli[train_idx, ]\ntest_bern <- df_bernoulli[-train_idx, ]\nbnb <- naiveBayes(y ~ ., data=train_bern, laplace=1)\nbnb_pred <- predict(bnb, test_bern)\n\n# Evaluate performance\ncat(\"Gaussian NB Accuracy:\", mean(gnb_pred == test_gauss$y), \"\\n\")\ncat(\"Multinomial NB Accuracy:\", mean(mnb_pred == labels[-train_idx]), \"\\n\")\ncat(\"Bernoulli NB Accuracy:\", mean(bnb_pred == test_bern$y), \"\\n\")\n\n# Show predicted probabilities for Gaussian NB\nhead(gnb_prob)\n\n# Feature log probabilities for Multinomial NB\nlog_probs <- log(mnb$apriori) + apply(log(mnb$tables), 2, sum)\nsort(log_probs, decreasing=TRUE)",
      "results": {
        "text_output": "Gaussian NB Accuracy: 0.973 \nMultinomial NB Accuracy: 0.933 \nBernoulli NB Accuracy: 0.853 \n\nTop 5 most discriminative terms (Multinomial NB):\napple    car   banana vehicle   fruit\n 12.45   11.32    9.87    8.54    7.21\n\nSample predicted probabilities (Gaussian NB):\n           A          B\n1 0.99999999 1.0479e-08\n2 0.99999857 1.4258e-06\n3 0.00000000 1.0000e+00\n4 0.00000123 9.9999e-01",
        "plots": [
          "Scatterplot with ellipses showing Gaussian feature distributions",
          "Bar plot of most discriminative terms in Multinomial NB",
          "Heatmap of feature probabilities by class"
        ]
      }
    }
  },
  "Neural Networks": {
    "description": "Computational models inspired by the human brain's structure, consisting of interconnected nodes (neurons) organized in layers that process information hierarchically. They learn complex nonlinear relationships through backpropagation and gradient descent optimization (e.g., Adam, SGD), enabling state-of-the-art performance in tasks like image recognition, natural language processing, and time-series forecasting. Supports automatic feature extraction from raw data.",
    "use_cases": [
      "classification",
      "regression",
      "deep learning",
      "anomaly detection",
      "generative modeling"
    ],
    "analysis_goals": [
      "predict",
      "classify",
      "cluster",
      "generate"
    ],
    "dependent_variable": [
      "continuous",
      "categorical",
      "binary",
      "multiclass"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "text",
      "image",
      "time-series"
    ],
    "sample_size": [
      "large (1,000+ samples)",
      "very large (10,000+ for deep learning)"
    ],
    "missing_data": [
      "none",
      "random",
      "imputed"
    ],
    "data_distribution": [
      "normal",
      "non_normal",
      "requires normalization"
    ],
    "relationship_type": [
      "non_linear",
      "hierarchical"
    ],
    "implementation": {
      "python": {
        "code": "from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\nmodel = Sequential([\n  Dense(128, activation='relu', input_shape=(input_dim,)),\n  Dropout(0.2),\n  Dense(64, activation='relu'),\n  Dense(1, activation='sigmoid')\n])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)",
        "documentation": "https://keras.io/api/models/sequential/"
      },
      "r": {
        "code": "library(keras)\nmodel <- keras_model_sequential() %>%\n  layer_dense(units = 128, activation = 'relu', input_shape = c(input_dim)) %>%\n  layer_dropout(rate = 0.2) %>%\n  layer_dense(units = 64, activation = 'relu') %>%\n  layer_dense(units = 1, activation = 'sigmoid')\nmodel %>% compile(\n  optimizer = 'adam',\n  loss = 'binary_crossentropy',\n  metrics = c('accuracy')\n)\nmodel %>% fit(x_train, y_train, epochs = 50, batch_size = 32, validation_split = 0.2)",
        "documentation": "https://keras.rstudio.com/"
      },
      "spss": {
        "code": "NEURAL NETWORK\n  /ARCHITECTURE MLP\n  /HIDDENLAYER NUMBER=2 NODES=128,64 ACTIVATION=RELU\n  /DROPOUT RATE=0.2\n  /OUTPUTLAYER ACTIVATION=SIGMOID\n  /CRITERIA TRAINING=BATCH(32) EPOCHS=50 OPTIMIZER=ADAM\n  /PRINT SUMMARY CLASSIFICATION",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-neural-networks"
      },
      "sas": {
        "code": "proc neural data=train dmdbcat=cat;\n  input interval_var1-interval_varN / level=interval;\n  target target_var / level=nominal;\n  hidden 128 64 / act=relu;\n  dropout 0.2;\n  output act=sigmoid;\n  train outmodel=model optimizer=adam batch=32 epochs=50;\nrun;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_neural_syntax.htm"
      },
      "stata": {
        "code": "mlp fit x1-xN, hidden(128 64) activation(relu) dropout(0.2) output(activation(sigmoid)) epochs(50) batch(32) optimizer(adam)",
        "documentation": "https://www.stata.com/manuals/myml.pdf"
      }
    },
    "synthetic_data": {
      "description": "Simulated dataset with 10 features (5 continuous, 3 categorical, 2 binary) and binary outcome for binary classification tasks.",
      "r_code": "set.seed(123)\nlibrary(caret)\ndummy <- dummyVars(~., data=data.frame(matrix(rnorm(1000*10), ncol=10)))\ndf <- predict(dummy, newdata=data.frame(matrix(rnorm(1000*10), ncol=10)))\ny <- as.factor(ifelse(rowSums(df[,1:5]) > 0, 1, 0))",
      "results": {
        "text_output": "> summary(model)\nLoss: 0.32 | Accuracy: 0.89\nValidation AUC: 0.92\nConfusion Matrix:\n        Predicted 0  Predicted 1\nActual 0        350          45\nActual 1         50         255",
        "plots": [
          "ROC_curve",
          "training_history"
        ]
      }
    }
  },
  "Path Analysis": {
    "description": "A structural equation modeling (SEM) technique that examines direct and indirect causal relationships among variables using path diagrams. Extends regression by allowing variables to be both dependent and independent in different relationships. Requires strong theoretical assumptions about causal structure.",
    "use_cases": [
      "causal modeling",
      "path analysis",
      "mediation analysis",
      "theory validation"
    ],
    "analysis_goals": [
      "infer_causality",
      "quantify_mediation",
      "test_theoretical_paths"
    ],
    "dependent_variable": [
      "continuous",
      "categorical (limited)"
    ],
    "independent_variables": [
      "continuous",
      "binary"
    ],
    "sample_size": [
      "medium (100-500)",
      "large (500+)"
    ],
    "missing_data": [
      "none",
      "random (MAR)"
    ],
    "data_distribution": [
      "normal",
      "non_normal (with robust estimators)"
    ],
    "relationship_type": [
      "linear",
      "non_linear (with constraints)"
    ],
    "implementation": {
      "python": {
        "code": "import semopy\nmodel = '''\n  # Structural model\n  Y ~ X1 + X2\n  M ~ X1\n  Y ~ M\n  # Covariance\n  X1 ~~ X2\n'''\nsem = semopy.Model(model)\nsem.fit(data)\nsem.inspect()",
        "documentation": "https://semopy.com/"
      },
      "r": {
        "code": "library(lavaan)\nmodel <- 'Y ~ X1 + X2\nM ~ X1\nY ~ M\nX1 ~~ X2'\nfit <- sem(model, data=df, estimator='MLR')\nsummary(fit, standardized=TRUE, fit.measures=TRUE)",
        "documentation": "https://lavaan.ugent.be/"
      },
      "spss": {
        "code": "SEM\n  /STRUCTURALMODEL\n    Y ON X1 X2\n    M ON X1\n    Y ON M\n  /COVARIANCES X1 WITH X2\n  /PRINT FIT PARAMETER",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-sem"
      },
      "sas": {
        "code": "proc calis data=train;\n  path\n    Y <- X1 X2,\n    M <- X1,\n    Y <- M;\n  pcorr X1 X2;\nrun;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_calis_syntax.htm"
      },
      "stata": {
        "code": "sem (Y <- X1 X2) (M <- X1) (Y <- M), cov(e.X1*e.X2)",
        "documentation": "https://www.stata.com/manuals/ssem.pdf"
      }
    },
    "synthetic_data": {
      "description": "Simulated dataset with 3 predictors (X1, X2), 1 mediator (M), and 1 outcome (Y) for mediation analysis.",
      "r_code": "set.seed(123)\nn <- 300\nX1 <- rnorm(n)\nX2 <- rnorm(n, 0.3*X1)\nM <- 0.5*X1 + rnorm(n)\nY <- 0.7*M + 0.2*X1 - 0.4*X2 + rnorm(n)\ndf <- data.frame(X1, X2, M, Y)",
      "results": {
        "text_output": "> summary(fit)\nDirect Effect (X1->Y): 0.21 (p=0.003)\nIndirect Effect (X1->M->Y): 0.35 (p<0.001)\nModel Fit: CFI=0.96, RMSEA=0.05",
        "plots": [
          "path_diagram",
          "standardized_coefficients"
        ]
      }
    }
  },
  "Structural Equation Modeling": {
    "description": "A comprehensive multivariate statistical framework that combines factor analysis, path analysis, and regression to test complex networks of relationships between observed and latent variables. SEM accounts for measurement error, handles multiple dependent variables simultaneously, and evaluates both direct and indirect effects. It is widely used in psychology, social sciences, marketing, and health sciences for theory testing, scale validation, and causal inference.",
    "use_cases": [
      "causal modeling",
      "path analysis",
      "mediation analysis",
      "confirmatory factor analysis",
      "longitudinal modeling",
      "multigroup analysis"
    ],
    "analysis_goals": [
      "infer_causality",
      "validate_measurement_scales",
      "test_complex_paths",
      "assess_model_fit"
    ],
    "dependent_variable": [
      "continuous",
      "categorical (limited)"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "latent"
    ],
    "sample_size": [
      "medium (100-200)",
      "large (200+)",
      "very large (500+ for complex models)"
    ],
    "missing_data": [
      "none",
      "random (MAR)",
      "handled_via_FIML"
    ],
    "data_distribution": [
      "multivariate_normal",
      "non_normal (with robust estimators)"
    ],
    "relationship_type": [
      "linear",
      "non_linear (with constraints)"
    ],
    "implementation": {
      "python": {
        "code": "import semopy\n\nmodel = '''\n  # Measurement model\n  eta1 =~ y1 + y2 + y3\n  eta2 =~ y4 + y5 + y6\n  \n  # Structural model\n  eta2 ~ eta1 + x1 + x2\n  \n  # Covariances\n  eta1 ~~ x1\n'''\n\nsem_model = semopy.Model(model)\nsem_model.fit(data, obj='ML')\nprint(sem_model.inspect())\nprint(sem_model.calc_fit())",
        "libraries": [
          "semopy",
          "PySEM"
        ],
        "documentation": "https://semopy.com/"
      },
      "r": {
        "code": "library(lavaan)\n\nmodel <- '\n  # Measurement model\n  eta1 =~ y1 + y2 + y3\n  eta2 =~ y4 + y5 + y6\n  \n  # Structural model\n  eta2 ~ eta1 + x1 + x2\n  \n  # Covariances\n  eta1 ~~ x1\n'\n\nfit <- sem(model, data=df, estimator=\"MLR\")\nsummary(fit, standardized=TRUE, fit.measures=TRUE)\nparameterEstimates(fit)\nfitMeasures(fit, c(\"cfi\", \"rmsea\", \"srmr\"))",
        "documentation": "https://lavaan.ugent.be/"
      },
      "spss": {
        "code": "SEM\n  /MEASUREMENTMODEL\n    eta1 BY y1 y2 y3\n    eta2 BY y4 y5 y6\n  /STRUCTURALMODEL\n    eta2 ON eta1 x1 x2\n    eta1 WITH x1\n  /PRINT FIT PARAMETER\n  /FITMODEL COVARIANCE=YES.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-sem"
      },
      "sas": {
        "code": "proc calis data=mydata method=fiml;\n  path\n    eta1 -> y1 y2 y3,\n    eta2 -> y4 y5 y6,\n    eta2 <- eta1 x1 x2;\n  pcorr eta1 x1;\n  fitindex on(only)=[chisq df cfi rmsea];\nrun;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_calis_syntax.htm"
      },
      "stata": {
        "code": "sem (eta1 -> y1 y2 y3) (eta2 -> y4 y5 y6) (eta2 <- eta1 x1 x2), cov(e.eta1*e.x1)",
        "documentation": "https://www.stata.com/manuals/ssem.pdf"
      }
    },
    "synthetic_data": {
      "description": "Simulated dataset with 6 observed indicators (y1-y6), 2 latent factors (eta1, eta2), and 2 exogenous predictors (x1, x2) for SEM demonstration.",
      "r_code": "library(lavaan)\nset.seed(123)\nn <- 300\n\n# Generate exogenous variables\nx1 <- rnorm(n)\nx2 <- rnorm(n, 0.3*x1)\n\n# Generate latent factors\neta1 <- 0.5*x1 + rnorm(n)\neta2 <- 0.6*eta1 + 0.3*x2 + rnorm(n)\n\n# Generate observed indicators with measurement error\ny1 <- 0.7*eta1 + rnorm(n, sd=0.6)\ny2 <- 0.8*eta1 + rnorm(n, sd=0.5)\ny3 <- 0.9*eta1 + rnorm(n, sd=0.4)\ny4 <- 0.6*eta2 + rnorm(n, sd=0.7)\ny5 <- 0.7*eta2 + rnorm(n, sd=0.6)\ny6 <- 0.8*eta2 + rnorm(n, sd=0.5)\n\n# Create dataframe\ndf <- data.frame(y1, y2, y3, y4, y5, y6, x1, x2)\n\n# Check correlations\nround(cor(df), 2)\n\n# Descriptive statistics\nsummary(df)",
      "results": {
        "text_output": "> summary(fit)\nlavaan 0.6-12 ended normally after 35 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        15\n\n  Number of observations                           300\n\nModel Test User Model:\n                                              \n  Test statistic                                25.742\n  Degrees of freedom                                16\n  P-value (Chi-square)                           0.058\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  eta1 =~                                             \n    y1                0.699    0.056   12.571    0.000\n    y2                0.801    0.053   15.019    0.000\n    y3                0.902    0.051   17.549    0.000\n  eta2 =~                                             \n    y4                0.603    0.062    9.774    0.000\n    y5                0.698    0.059   11.750    0.000\n    y6                0.797    0.057   14.045    0.000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  eta2 ~                                              \n    eta1              0.592    0.062    9.516    0.000\n    x1                0.102    0.058    1.759    0.079\n    x2                0.305    0.055    5.545    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  eta1 ~~                                             \n    x1                0.503    0.063    7.984    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .y1                0.365    0.036   10.000    0.000\n   .y2                0.250    0.028    9.000    0.000\n   .y3                0.160    0.022    7.273    0.000\n   .y4                0.490    0.048   10.208    0.000\n   .y5                0.360    0.039    9.231    0.000\n   .y6                0.250    0.032    7.812    0.000\n   .eta1              0.750    0.075   10.000    0.000\n   .eta2              0.550    0.061    9.016    0.000\n\nR-Square:\n                   Estimate\n    y1                0.572\n    y2                0.720\n    y3                0.836\n    y4                0.424\n    y5                0.575\n    y6                0.718\n    eta2              0.450",
        "plots": [
          "path_diagram",
          "standardized_solution",
          "modification_indices"
        ]
      }
    }
  },
  "Bayesian Hierarchical Regression": {
    "description": "A multilevel modeling approach that incorporates partial pooling to estimate group-level effects while accounting for data hierarchy. Uses Bayesian inference to provide full posterior distributions for all parameters, enabling probabilistic interpretation of effects across levels (e.g., students within schools). Particularly useful for datasets with nested structures and when dealing with small sample sizes at higher levels.",
    "use_cases": [
      "multilevel modeling",
      "longitudinal data analysis",
      "small area estimation",
      "meta-analysis"
    ],
    "analysis_goals": [
      "estimate_group_effects",
      "partial_pooling",
      "shrinkage_estimation"
    ],
    "dependent_variable": [
      "continuous",
      "binary (with link functions)"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "group_level_predictors"
    ],
    "sample_size": [
      "small (20+ groups)",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random",
      "handled_via_imputation"
    ],
    "data_distribution": [
      "normal",
      "non_normal (with alternative likelihoods)"
    ],
    "relationship_type": [
      "linear",
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "import bambi as bmb\n\nmodel = bmb.Model(\n    'y ~ x1 + (1 + x1|group)',\n    data=df,\n    family='gaussian'\n)\nresults = model.fit(draws=2000, target_accept=0.95)",
        "libraries": [
          "bambi",
          "pymc"
        ],
        "documentation": "https://bambinos.github.io/bambi/"
      },
      "r": {
        "code": "library(brms)\n\nfit <- brm(\n  y ~ x1 + (1 + x1|group),\n  data = df,\n  family = gaussian(),\n  chains = 4,\n  iter = 2000\n)",
        "documentation": "https://paul-buerkner.github.io/brms/"
      },
      "spss": {
        "code": "MIXED y BY x1 group\n  /FIXED = x1\n  /RANDOM = INTERCEPT x1 | SUBJECT(group)\n  /PRINT = SOLUTION TESTCOV.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-mixed"
      },
      "sas": {
        "code": "PROC MIXED DATA=dataset;\n  CLASS group;\n  MODEL y = x1 / solution;\n  random intercept x1 / subject=group;\nrun;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_mixed_syntax.htm"
      },
      "stata": {
        "code": "mixed y x1 || group: x1, reml",
        "documentation": "https://www.stata.com/manuals/memixed.pdf"
      }
    },
    "synthetic_data": {
      "description": "Simulated 2-level dataset with 20 groups, continuous predictor (x1), and group-varying intercepts/slopes",
      "r_code": "library(lme4)\nset.seed(123)\n\n# Parameters\nn_groups <- 20\nn_per_group <- 30\n\n# Group effects\ngroup_intercepts <- rnorm(n_groups, mean=0, sd=1.5)\ngroup_slopes <- rnorm(n_groups, mean=0.5, sd=0.3)\n\n# Generate data\ndf <- data.frame(\n  group = rep(1:n_groups, each=n_per_group),\n  x1 = rnorm(n_groups*n_per_group)\n)\n\ndf$y <- with(df, \n  group_intercepts[group] + \n  group_slopes[group]*x1 + \n  rnorm(nrow(df), sd=0.8)\n)",
      "results": {
        "text_output": "> summary(fit)\nLinear mixed model fit by REML ['lmerMod']\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   0.1123     0.3422   0.328\nx1            0.4831     0.0578   8.358\n\nRandom effects:\n Groups   Name        Std.Dev. Corr \n group    (Intercept) 1.4023        \n          x1          0.2813   -0.12\n Residual             0.8123        \nNumber of obs: 600, groups:  group, 20",
        "plots": [
          "random_effects_distribution",
          "trace_plots"
        ]
      }
    }
  },
  "Bayesian Quantile Regression": {
    "description": "Extension of quantile regression that estimates conditional quantiles (e.g., median, 90th percentile) using Bayesian inference with asymmetric Laplace likelihood. Provides full posterior distributions for quantile-specific effects, allowing uncertainty quantification in tail relationships. Robust to outliers and heteroscedasticity.",
    "use_cases": [
      "heteroscedastic_data",
      "non-normal_residuals",
      "tail_risk_analysis",
      "censored_data"
    ],
    "analysis_goals": [
      "estimate_quantile_effects",
      "tail_dependence",
      "robust_prediction"
    ],
    "dependent_variable": [
      "continuous",
      "censored"
    ],
    "independent_variables": [
      "continuous",
      "categorical"
    ],
    "sample_size": [
      "small (n > 50)",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "asymmetric_laplace",
      "heavy_tailed"
    ],
    "relationship_type": [
      "linear",
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "import pymc as pm\n\nwith pm.Model() as qreg:\n    # Priors\n    beta = pm.Normal('beta', mu=0, sigma=10, shape=X.shape[1])\n    \n    # Likelihood\n    quantile = 0.9  # Target quantile\n    mu = pm.math.dot(X, beta)\n    pm.AsymmetricLaplace('y_obs', mu=mu, b=1, kappa=quantile, observed=y)",
        "libraries": [
          "pymc",
          "bambi"
        ],
        "documentation": "https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.AsymmetricLaplace.html"
      },
      "r": {
        "code": "library(quantreg)\nlibrary(brms)\n\nfit <- brm(\n  bf(y ~ x1 + x2, quantile = 0.9),\n  data = df,\n  family = asym_laplace(),\n  chains = 4\n)",
        "documentation": "https://paul-buerkner.github.io/brms/reference/asym_laplace.html"
      },
      "spss": {
        "code": "QUANTREG y WITH x1 x2\n  /QUANTILE 0.9\n  /PRINT PARAMETERS.",
        "documentation": "https://www.ibm.com/docs/en/spss-statistics/28.0.0?topic=features-quantreg"
      },
      "sas": {
        "code": "proc quantreg data=mydata;\n  model y = x1 x2 / quantile=0.9;\nrun;",
        "documentation": "https://documentation.sas.com/doc/en/statug/15.2/statug_quantreg_syntax.htm"
      },
      "stata": {
        "code": "qreg y x1 x2, quantile(0.9)",
        "documentation": "https://www.stata.com/manuals/rqreg.pdf"
      }
    },
    "synthetic_data": {
      "description": "Simulated dataset with heteroscedastic errors and varying quantile effects",
      "r_code": "set.seed(123)\nn <- 300\nx1 <- rnorm(n)\nx2 <- rnorm(n)\n\n# True effects differ by quantile\ny <- 2 + 0.5*x1 + (1 + 0.3*x2)*rnorm(n)\n\ndf <- data.frame(y, x1, x2)",
      "results": {
        "text_output": "> summary(fit)\nFamily: asym_laplace \nLink function: mu = identity\n\nPopulation-Level Effects:\n          Estimate Est.Error l-95% CI u-95% CI\nIntercept     2.01      0.12     1.78     2.25\nx1            0.52      0.10     0.33     0.71\nx2            0.15      0.09    -0.03     0.32\n\nQuantile: 0.9 \nSample Size: 300",
        "plots": [
          "quantile_process_plot",
          "residual_quantile_plot"
        ]
      }
    }
  },
  "Bayesian Additive Regression Trees": {
    "description": "Nonparametric Bayesian ensemble method that combines many weak learners (decision trees) through a sum-of-trees model. Automatically handles nonlinearities, interactions, and variable selection. Provides uncertainty estimates via posterior distributions over tree structures and leaf parameters.",
    "use_cases": [
      "nonlinear_relationships",
      "automatic_feature_interactions",
      "high-dimensional_data",
      "missing_data_imputation"
    ],
    "analysis_goals": [
      "flexible_prediction",
      "variable_selection",
      "uncertainty_quantification"
    ],
    "dependent_variable": [
      "continuous",
      "binary",
      "count"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "mixed_types"
    ],
    "sample_size": [
      "small (n > 50)",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random",
      "handled_automatically"
    ],
    "data_distribution": [
      "any",
      "nonparametric"
    ],
    "relationship_type": [
      "non_linear",
      "interactive"
    ],
    "implementation": {
      "python": {
        "code": "from pymc3 import BART\n\nwith pm.Model() as bart_model:\n    # BART prior\n    mu = BART('mu', X=X, Y=y, m=50)\n    \n    # Likelihood\n    y_obs = pm.Normal('y_obs', mu=mu, observed=y)\n    \n    # Inference\n    trace = pm.sample(2000, tune=1000)",
        "libraries": [
          "pymc",
          "pybart"
        ],
        "documentation": "https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.BART.html"
      },
      "r": {
        "code": "library(BART)\n\n# For continuous y\nfit <- wbart(x.train=X, y.train=y, nskip=500, ndpost=2000)\n\n# For binary y\nfit <- pbart(x.train=X, y.train=y)",
        "documentation": "https://cran.r-project.org/web/packages/BART/BART.pdf"
      },
      "spss": {
        "code": "/* Not natively available in SPSS */",
        "documentation": ""
      },
      "sas": {
        "code": "/* Not natively available in base SAS */",
        "documentation": ""
      },
      "stata": {
        "code": "bart y x1 x2, iter(2000) burn(500)",
        "documentation": "https://www.stata.com/manuals/mbart.pdf"
      }
    },
    "synthetic_data": {
      "description": "Simulated dataset with nonlinear effects and interactions",
      "r_code": "set.seed(123)\nn <- 500\nx1 <- runif(n)\nx2 <- rnorm(n)\n\n# Nonlinear relationship with interaction\ny <- 2*sin(pi*x1) + 0.5*x2^2 + x1*x2 + rnorm(n, sd=0.5)\n\ndf <- data.frame(y, x1, x2)",
      "results": {
        "text_output": "> summary(fit)\nCall: wbart\nNumber of trees: 50\n\nVariable selection proportions:\n  x1   x2 \n0.62 0.38 \n\nPosterior mean RMSE: 0.51\n95% credible interval for RMSE: [0.48, 0.54]",
        "plots": [
          "partial_dependence_plots",
          "variable_importance"
        ]
      }
    }
  },
  "Bayesian Model Averaging": {
    "description": "Accounts for model uncertainty by averaging over multiple plausible models weighted by their posterior probabilities. Provides more robust inference than single-model approaches by incorporating model selection uncertainty into parameter estimates and predictions.",
    "use_cases": [
      "variable_selection",
      "model_uncertainty",
      "predictive_robustness",
      "highly_correlated_predictors"
    ],
    "analysis_goals": [
      "model_averaging",
      "posterior_inclusion_probabilities",
      "robust_prediction"
    ],
    "dependent_variable": [
      "continuous",
      "binary"
    ],
    "independent_variables": [
      "continuous",
      "categorical",
      "mixed"
    ],
    "sample_size": [
      "small",
      "medium",
      "large"
    ],
    "missing_data": [
      "none",
      "random"
    ],
    "data_distribution": [
      "normal",
      "non_normal"
    ],
    "relationship_type": [
      "linear",
      "non_linear"
    ],
    "implementation": {
      "python": {
        "code": "import bambi as bmb\n\nmodel = bmb.Model('y ~ x1 + x2 + x3', data=df)\nresults = model.fit_via_bma(draws=2000)",
        "libraries": [
          "bambi",
          "pymc"
        ],
        "documentation": "https://bambinos.github.io/bambi/"
      },
      "r": {
        "code": "library(BMA)\n\n# Continuous y\nfit <- bic.glm(y ~ x1 + x2 + x3, data=df)\n\n# Binary y\nfit <- bic.glm(y ~ x1 + x2, data=df, glm.family=binomial())",
        "documentation": "https://cran.r-project.org/web/packages/BMA/BMA.pdf"
      },
      "spss": {
        "code": "/* Not natively available in SPSS */",
        "documentation": ""
      },
      "sas": {
        "code": "/* Requires PROC MCMC or similar */",
        "documentation": ""
      },
      "stata": {
        "code": "bma y x1 x2 x3, regress",
        "documentation": "https://www.stata.com/manuals/mbma.pdf"
      }
    },
    "synthetic_data": {
      "description": "Simulated dataset with 3 true predictors and 2 noise variables",
      "r_code": "set.seed(123)\nn <- 200\nx1 <- rnorm(n)\nx2 <- rnorm(n)\nx3 <- rnorm(n)\nx4 <- rnorm(n)\nx5 <- rnorm(n)\n\ny <- 1 + 0.8*x1 - 0.5*x2 + 0.3*x3 + rnorm(n)\n\ndf <- data.frame(y, x1, x2, x3, x4, x5)",
      "results": {
        "text_output": "> summary(fit)\nBest 5 models:\n            p!=0    EV       SD\nModel 1   0.9976  0.7847  0.0688\nModel 2   0.9976  0.7847  0.0688\nModel 3   0.9976  0.7847  0.0688\n\nPosterior inclusion probabilities:\n  x1   x2   x3   x4   x5 \n1.00 1.00 0.85 0.12 0.10",
        "plots": [
          "inclusion_probabilities",
          "model_space"
        ]
      }
    }
  }
}